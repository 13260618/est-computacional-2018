<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Computacional</title>
  <meta name="description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Computacional" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  <meta name="github-repo" content="tereom/est-computacional-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Computacional" />
  
  <meta name="twitter:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  

<meta name="author" content="Teresa Ortiz">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="variacion-en-distribuciones-bootstrap.html">
<link rel="next" href="bootstrap-en-r.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/d3-3.5.6/d3.min.js"></script>
<link href="libs/profvis-0.3.5/profvis.css" rel="stylesheet" />
<script src="libs/profvis-0.3.5/profvis.js"></script>
<link href="libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="libs/highlight-6.2.0/highlight.js"></script>
<script src="libs/profvis-binding-0.3.5/profvis.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
<link rel="stylesheet" href="css/font-awesome.min.css" type="text/css" />
<link rel="stylesheet" href="css/cajas.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Computacional</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ligas"><i class="fa fa-check"></i>Ligas</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#temario"><i class="fa fa-check"></i>Temario</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#calificacion"><i class="fa fa-check"></i>Calificación</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#otros"><i class="fa fa-check"></i>Otros</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introducciona-a-visualizacion.html"><a href="introducciona-a-visualizacion.html"><i class="fa fa-check"></i><b>1</b> Introduccióna a visualización</a><ul>
<li class="chapter" data-level="" data-path="introducciona-a-visualizacion.html"><a href="introducciona-a-visualizacion.html#el-cuarteto-de-ascombe"><i class="fa fa-check"></i>El cuarteto de Ascombe</a></li>
<li class="chapter" data-level="1.1" data-path="introduccion.html"><a href="introduccion.html"><i class="fa fa-check"></i><b>1.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-de-datos-en-la-estadistica"><i class="fa fa-check"></i>Visualización de datos en la estadística</a></li>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><i class="fa fa-check"></i><b>1.2</b> Teoría de visualización de datos (Tufte, Cleveland, Tukey)</a><ul>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#principios-generales-del-diseno-analitico"><i class="fa fa-check"></i>Principios generales del diseño analítico</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#tecnicas-de-visualizacion"><i class="fa fa-check"></i>Técnicas de visualización</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#indicadores-de-calidad-grafica"><i class="fa fa-check"></i>Indicadores de calidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#factor-de-engano-chartjunk-y-pies"><i class="fa fa-check"></i>Factor de engaño, chartjunk y pies</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#series-de-tiempo-y-promedio-de-45"><i class="fa fa-check"></i>Series de tiempo y promedio de 45</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#pequenos-multiplos-y-densidad-grafica"><i class="fa fa-check"></i>Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#tinta-de-datos"><i class="fa fa-check"></i>Tinta de datos</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#percepcion-de-escala"><i class="fa fa-check"></i>Percepción de escala</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html"><a href="teoria-de-visualizacion-de-datos-tufte-cleveland-tukey.html#minard"><i class="fa fa-check"></i>Minard</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduccion-a-r-y-al-paquete-ggplot2.html"><a href="introduccion-a-r-y-al-paquete-ggplot2.html"><i class="fa fa-check"></i><b>2</b> Introducción a R y al paquete ggplot2</a><ul>
<li class="chapter" data-level="2.1" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html"><i class="fa fa-check"></i><b>2.1</b> R: primeros pasos</a><ul>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#r-en-analisis-de-datos"><i class="fa fa-check"></i>R en análisis de datos</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#paquetes-y-el-tidyverse"><i class="fa fa-check"></i>Paquetes y el Tidyverse</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#recursos"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html"><i class="fa fa-check"></i><b>2.2</b> Visualización con ggplot2</a><ul>
<li class="chapter" data-level="" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html#recursos-1"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-agrupacion-de-datos.html"><a href="manipulacion-y-agrupacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y agrupación de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html"><i class="fa fa-check"></i><b>3.1</b> Transformación de datos</a><ul>
<li><a href="transformacion-de-datos.html#separa-aplica-combina-split-apply-combine">Separa-aplica-combina (<em>split-apply-combine</em>)</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ejemplos-y-lectura-de-datos"><i class="fa fa-check"></i>Ejemplos y lectura de datos</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#filtrar"><i class="fa fa-check"></i>Filtrar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#seleccionar"><i class="fa fa-check"></i>Seleccionar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ordenar"><i class="fa fa-check"></i>Ordenar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#mutar"><i class="fa fa-check"></i>Mutar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#summarise-y-resumenes-por-grupo"><i class="fa fa-check"></i>Summarise y resúmenes por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#operador-pipeline"><i class="fa fa-check"></i>Operador pipeline</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#variables-por-grupo"><i class="fa fa-check"></i>Variables por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#verbos-de-dos-tablas"><i class="fa fa-check"></i>Verbos de dos tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="datos-limpios.html"><a href="datos-limpios.html"><i class="fa fa-check"></i><b>3.2</b> Datos limpios</a><ul>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#limpieza-bases-de-datos"><i class="fa fa-check"></i>Limpieza bases de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#los-encabezados-de-las-columanas-son-valores"><i class="fa fa-check"></i>Los encabezados de las columanas son valores</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-columna-asociada-a-mas-de-una-variable"><i class="fa fa-check"></i>Una columna asociada a más de una variable</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#variables-almacenadas-en-filas-y-columnas"><i class="fa fa-check"></i>Variables almacenadas en filas y columnas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#mas-de-un-tipo-de-observacion-en-una-misma-tabla"><i class="fa fa-check"></i>Mas de un tipo de observación en una misma tabla</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-misma-unidad-observacional-esta-almacenada-en-multiples-tablas"><i class="fa fa-check"></i>Una misma unidad observacional está almacenada en múltiples tablas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#otras-consideraciones"><i class="fa fa-check"></i>Otras consideraciones</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#recursos-adicionales"><i class="fa fa-check"></i>Recursos adicionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="temas-selectos-de-r.html"><a href="temas-selectos-de-r.html"><i class="fa fa-check"></i><b>4</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="4.1" data-path="funciones.html"><a href="funciones.html"><i class="fa fa-check"></i><b>4.1</b> Funciones</a><ul>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#estructura-de-una-funcion"><i class="fa fa-check"></i>Estructura de una función</a></li>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#observaciones-del-uso-de-funciones"><i class="fa fa-check"></i>Observaciones del uso de funciones</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="vectores.html"><a href="vectores.html"><i class="fa fa-check"></i><b>4.2</b> Vectores</a><ul>
<li class="chapter" data-level="" data-path="vectores.html"><a href="vectores.html#propiedades"><i class="fa fa-check"></i>Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="iteracion.html"><a href="iteracion.html"><i class="fa fa-check"></i><b>4.3</b> Iteración</a></li>
<li class="chapter" data-level="4.4" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html"><i class="fa fa-check"></i><b>4.4</b> Rendimiento en R</a><ul>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#diagnosticar"><i class="fa fa-check"></i>Diagnosticar</a></li>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#estrategias-para-mejorar-desempeno"><i class="fa fa-check"></i>Estrategias para mejorar desempeño</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduccion-a-probabilidad.html"><a href="introduccion-a-probabilidad.html"><i class="fa fa-check"></i><b>5</b> Introducción a probabilidad</a><ul>
<li class="chapter" data-level="5.1" data-path="interpretacion-frecuentista-de-probabilidad.html"><a href="interpretacion-frecuentista-de-probabilidad.html"><i class="fa fa-check"></i><b>5.1</b> Interpretación frecuentista de probabilidad</a></li>
<li class="chapter" data-level="5.2" data-path="simulacion-para-el-calculo-de-probabilidades.html"><a href="simulacion-para-el-calculo-de-probabilidades.html"><i class="fa fa-check"></i><b>5.2</b> Simulación para el cálculo de probabilidades</a></li>
<li class="chapter" data-level="5.3" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>5.3</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bootstrap-no-parametrico.html"><a href="bootstrap-no-parametrico.html"><i class="fa fa-check"></i><b>6</b> Bootstrap no paramétrico</a><ul>
<li class="chapter" data-level="6.1" data-path="muestras-aleatorias.html"><a href="muestras-aleatorias.html"><i class="fa fa-check"></i><b>6.1</b> Muestras aleatorias</a></li>
<li class="chapter" data-level="6.2" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html"><i class="fa fa-check"></i><b>6.2</b> El principio del <em>plug-in</em></a><ul>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#funcion-de-distribucion-empirica"><i class="fa fa-check"></i>Función de distribución empírica</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="distribuciones-muestrales-y-errores-estandar.html"><a href="distribuciones-muestrales-y-errores-estandar.html"><i class="fa fa-check"></i><b>6.3</b> Distribuciones muestrales y errores estándar</a></li>
<li class="chapter" data-level="6.4" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html"><i class="fa fa-check"></i><b>6.4</b> El estimador bootstrap del error estándar</a></li>
<li class="chapter" data-level="6.5" data-path="variacion-en-distribuciones-bootstrap.html"><a href="variacion-en-distribuciones-bootstrap.html"><i class="fa fa-check"></i><b>6.5</b> Variación en distribuciones bootstrap</a></li>
<li class="chapter" data-level="6.6" data-path="mas-alla-de-muestras-aleatorias-simples.html"><a href="mas-alla-de-muestras-aleatorias-simples.html"><i class="fa fa-check"></i><b>6.6</b> Más alla de muestras aleatorias simples</a><ul>
<li class="chapter" data-level="6.6.1" data-path="mas-alla-de-muestras-aleatorias-simples.html"><a href="mas-alla-de-muestras-aleatorias-simples.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>6.6.1</b> Intervalos de confianza</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="bootstrap-en-r.html"><a href="bootstrap-en-r.html"><i class="fa fa-check"></i><b>6.7</b> Bootstrap en R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a><ul>
<li class="chapter" data-level="" data-path="transformacion-de-datos-1.html"><a href="transformacion-de-datos-1.html"><i class="fa fa-check"></i>2-Transformación de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios-1.html"><a href="datos-limpios-1.html"><i class="fa fa-check"></i>3-Datos Limpios</a></li>
<li class="chapter" data-level="" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i>4-Probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mas-alla-de-muestras-aleatorias-simples" class="section level2">
<h2><span class="header-section-number">6.6</span> Más alla de muestras aleatorias simples</h2>
<p>Introdujimos el bootstrap en el contexto de muestras aleatorias, esto es,
suponiendo que las observaciones son independientes; en este escenario basta con
aproximar la distribución desconocida <span class="math inline">\(P\)</span> usando la dsitribución empírica <span class="math inline">\(P_n\)</span>,
y el cálculo de los estadísticos es inmediato. Hay casos en los que el mecanismo
que generó los datos es más complicado, por ejemplo, cuando tenemos dos
muestras, en diseños de encuestas complejas o en series de
tiempo.</p>
<div id="ejemplo-dos-muestras" class="section level4 unnumbered">
<h4>Ejemplo: Dos muestras</h4>
<p>En el ejemplo de experimentos clínicos de aspirina y ataques de de corazón,
podemos pensar el modelo probabilístico <span class="math inline">\(P\)</span> como
al grupo control y otra al grupo de tratamiento, entonces las observaciones de
cada grupo provienen de distribuciones distintas y el método bootstrap debe
tomar en cuenta esto al generar las muestras.</p>
</div>
<div id="ejemplo-bootstrap-en-muestreo-de-encuestas" class="section level4 unnumbered">
<h4>Ejemplo: Bootstrap en muestreo de encuestas</h4>
<p>La necesidad de estimaciones confiables junto con el uso eficiente de recursos
conllevan a diseños de muestras complejas. Estos diseños típicamente usan las
siguientes técnicas: muestreo sin reemplazo de una población finita, muestreo
sistemático, estratificación, conglomerados, ajustes a no-respuesta,
postestratificación. Como consecuencia, los valores de la muestra suelen no ser
independientes.</p>
<p>La complejidad de los diseños de encuestas conlleva a que el cálculo de errores
estándar sea muy complicado, para atacar este problema hay dos técnicas básicas:
1) un enfoque analítico usando linearización, 2) métodos de remuestreo como
bootstrap. El incremento en el poder de cómputo ha favorecido los métodos de
remuestreo pues la linearización requiere del desarrollo de una fórmula para
cada estimación y supuestos adicionales para simplificar.</p>
<p>En 1988 <span class="citation">Rao and Wu (<a href="#ref-RaoWu">1988</a>)</span> propusieron un método de bootstrap para diseños
estratificados multietápicos con reemplazo de UPMs que describimos a
continuación.</p>
<p><strong>ENIGH</strong>. Usaremos como ejemplo la Encuesta Nacional de Ingresos y
Gastos de los Hogares, ENIGH 2014 <span class="citation">(INEGI <a href="#ref-enigh">2014</a>)</span>, esta encuesta usa un diseño de
conglomerados estratificado.</p>
<p>Antes de proceder a bootstrap debemos entender como se seleccionaron los datos,
esto es, el <a href="http://www.inegi.org.mx/prod_serv/contenidos/espanol/bvinegi/productos/metodologias/ENIGH/ENIGH2012/702825050597.pdf">diseño de la muestra</a>:</p>
<ol style="list-style-type: decimal">
<li><p>Unidad primaria de muestreo (UPM). Las UPMs están constituidas por
agrupaciones de viviendas. Se les denomina unidades primarias pues corresponden
a la primera etapa de selección, las unidades secundarias (USMs) serían los
hogares.</p></li>
<li><p>Estratificación. Los estratos se construyen en base a estado, ámbito (urbano,
complemento urbano, rural), características sociodemográficas de los habitantes
de las viviendas, características físicas y equipamiento. El proceso de
estratificación resulta en 888 subestratos en todo el ámbito nacional.</p></li>
<li><p>La selección de la muestra es independiente para cada estrato, y una
vez que se obtiene la muestra se calculan los factores de expansión que
reflejan las distintas probabilidades de selección. Después se llevan a cabo
ajustes por no respuesta y por proyección (calibración), esta última
busca que distintos dominios de la muestra coincidan con la proyección de
población de INEGI.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">concentrado_hogar &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/concentradohogar.csv&quot;</span>)
concentrado_hogar
<span class="co">#&gt; # A tibble: 19,479 x 132</span>
<span class="co">#&gt;    folioviv foliohog ubica_geo ageb  tam_loc est_socio est_dis upm  </span>
<span class="co">#&gt;    &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt;     &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;</span>
<span class="co">#&gt;  1 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  2 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  3 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  4 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  5 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  6 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  7 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  8 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  9 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt; 10 0100018…        1 010010001 029-0       1         3 004     00570</span>
<span class="co">#&gt; # ... with 19,469 more rows, and 124 more variables: factor_hog &lt;int&gt;,</span>
<span class="co">#&gt; #   clase_hog &lt;int&gt;, sexo_jefe &lt;int&gt;, edad_jefe &lt;int&gt;, educa_jefe &lt;chr&gt;,</span>
<span class="co">#&gt; #   tot_integ &lt;int&gt;, hombres &lt;int&gt;, mujeres &lt;int&gt;, mayores &lt;int&gt;,</span>
<span class="co">#&gt; #   menores &lt;int&gt;, p12_64 &lt;int&gt;, p65mas &lt;int&gt;, ocupados &lt;int&gt;,</span>
<span class="co">#&gt; #   percep_ing &lt;int&gt;, perc_ocupa &lt;int&gt;, ing_total &lt;dbl&gt;, ing_cor &lt;dbl&gt;,</span>
<span class="co">#&gt; #   ing_mon &lt;dbl&gt;, trabajo &lt;dbl&gt;, sueldos &lt;dbl&gt;, horas_extr &lt;dbl&gt;,</span>
<span class="co">#&gt; #   comisiones &lt;dbl&gt;, otra_rem &lt;dbl&gt;, negocio &lt;dbl&gt;, noagrop &lt;dbl&gt;,</span>
<span class="co">#&gt; #   industria &lt;dbl&gt;, comercio &lt;dbl&gt;, servicios &lt;dbl&gt;, agrope &lt;dbl&gt;,</span>
<span class="co">#&gt; #   agricolas &lt;dbl&gt;, pecuarios &lt;dbl&gt;, reproducc &lt;int&gt;, pesca &lt;int&gt;,</span>
<span class="co">#&gt; #   otros_trab &lt;dbl&gt;, rentas &lt;dbl&gt;, utilidad &lt;dbl&gt;, arrenda &lt;dbl&gt;,</span>
<span class="co">#&gt; #   transfer &lt;dbl&gt;, jubilacion &lt;dbl&gt;, becas &lt;dbl&gt;, donativos &lt;dbl&gt;,</span>
<span class="co">#&gt; #   remesas &lt;dbl&gt;, bene_gob &lt;dbl&gt;, otros_ing &lt;dbl&gt;, gasto_nom &lt;dbl&gt;,</span>
<span class="co">#&gt; #   autoconsum &lt;dbl&gt;, remu_espec &lt;dbl&gt;, transf_esp &lt;dbl&gt;,</span>
<span class="co">#&gt; #   transf_hog &lt;dbl&gt;, trans_inst &lt;dbl&gt;, estim_alqu &lt;dbl&gt;,</span>
<span class="co">#&gt; #   percep_tot &lt;dbl&gt;, percep_mon &lt;dbl&gt;, retiro_inv &lt;dbl&gt;, prestamos &lt;dbl&gt;,</span>
<span class="co">#&gt; #   otras_perc &lt;dbl&gt;, erogac_nom &lt;dbl&gt;, gasto_tot &lt;dbl&gt;, gasto_cor &lt;dbl&gt;,</span>
<span class="co">#&gt; #   gasto_mon &lt;dbl&gt;, alimentos &lt;dbl&gt;, ali_dentro &lt;dbl&gt;, cereales &lt;dbl&gt;,</span>
<span class="co">#&gt; #   carnes &lt;dbl&gt;, pescado &lt;dbl&gt;, leche &lt;dbl&gt;, huevo &lt;dbl&gt;, aceites &lt;dbl&gt;,</span>
<span class="co">#&gt; #   tuberculo &lt;dbl&gt;, verduras &lt;dbl&gt;, frutas &lt;dbl&gt;, azucar &lt;dbl&gt;,</span>
<span class="co">#&gt; #   cafe &lt;dbl&gt;, especias &lt;dbl&gt;, otros_alim &lt;dbl&gt;, bebidas &lt;dbl&gt;,</span>
<span class="co">#&gt; #   ali_fuera &lt;dbl&gt;, tabaco &lt;dbl&gt;, vesti_calz &lt;dbl&gt;, vestido &lt;dbl&gt;,</span>
<span class="co">#&gt; #   calzado &lt;dbl&gt;, vivienda &lt;dbl&gt;, alquiler &lt;dbl&gt;, pred_cons &lt;dbl&gt;,</span>
<span class="co">#&gt; #   agua &lt;dbl&gt;, energia &lt;dbl&gt;, limpieza &lt;dbl&gt;, cuidados &lt;dbl&gt;,</span>
<span class="co">#&gt; #   utensilios &lt;dbl&gt;, enseres &lt;dbl&gt;, salud &lt;dbl&gt;, atenc_ambu &lt;dbl&gt;,</span>
<span class="co">#&gt; #   hospital &lt;dbl&gt;, medicinas &lt;dbl&gt;, transporte &lt;dbl&gt;, publico &lt;dbl&gt;,</span>
<span class="co">#&gt; #   foraneo &lt;dbl&gt;, adqui_vehi &lt;dbl&gt;, mantenim &lt;dbl&gt;, refaccion &lt;dbl&gt;, …</span>

<span class="co"># seleccionar variable de ingreso corriente</span>
hogar &lt;-<span class="st"> </span>concentrado_hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">jefe_hombre =</span> sexo_jefe <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(folioviv, foliohog, est_dis, upm, factor_hog, ing_cor, sexo_jefe, edad_jefe) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(est_dis) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(
        <span class="dt">n =</span> <span class="kw">n_distinct</span>(upm), <span class="co"># número de upms por estrato</span>
        <span class="dt">jefa_50 =</span> (sexo_jefe <span class="op">==</span><span class="st"> </span><span class="dv">2</span>) <span class="op">&amp;</span><span class="st"> </span>(edad_jefe <span class="op">&gt;</span><span class="st"> </span><span class="dv">50</span>)
      ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">ungroup</span>()

<span class="kw">head</span>(hogar)
<span class="co">#&gt; # A tibble: 6 x 10</span>
<span class="co">#&gt;   folioviv foliohog est_dis upm   factor_hog ing_cor sexo_jefe edad_jefe</span>
<span class="co">#&gt;   &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;   &lt;dbl&gt;     &lt;int&gt;     &lt;int&gt;</span>
<span class="co">#&gt; 1 0100008…        1 005     00670        694  39787.         2        77</span>
<span class="co">#&gt; 2 0100008…        1 005     00670        694  19524.         1        64</span>
<span class="co">#&gt; 3 0100008…        1 005     00670        694  99258.         1        60</span>
<span class="co">#&gt; 4 0100008…        1 005     00670        694  87884.         1        79</span>
<span class="co">#&gt; 5 0100010…        1 005     00600        660  84427.         1        72</span>
<span class="co">#&gt; 6 0100010…        1 005     00600        660 232014.         1        67</span>
<span class="co">#&gt; # ... with 2 more variables: n &lt;int&gt;, jefa_50 &lt;lgl&gt;</span></code></pre>
<p>Para el cálculo de estadísticos debemos usar los factores de expansión, por ejemplo
el ingreso trimestral total sería:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(hogar<span class="op">$</span>factor_hog <span class="op">*</span><span class="st"> </span>hogar<span class="op">$</span>ing_cor <span class="op">/</span><span class="st"> </span><span class="dv">1000</span>)
<span class="co">#&gt; [1] 1.26e+09</span></code></pre>
<p>y ingreso trimestral medio (miles pesos)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(hogar<span class="op">$</span>factor_hog <span class="op">*</span><span class="st"> </span>hogar<span class="op">$</span>ing_cor <span class="op">/</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(hogar<span class="op">$</span>factor_hog)
<span class="co">#&gt; [1] 39.7</span></code></pre>
<p>Veamos ahora como calcular el error estándar siguiendo el bootstrap de Rao y Wu:</p>
<ol style="list-style-type: decimal">
<li>En cada estrato se seleccionan con reemplazo <span class="math inline">\(m_h\)</span> UPMs de las <span class="math inline">\(n_h\)</span> de la
muestra original. Denotamos por <span class="math inline">\(m_{hi}^*\)</span> el número de veces que se seleccionó
la UPM <span class="math inline">\(i\)</span> en el estrato <span class="math inline">\(h\)</span> (de tal manera que <span class="math inline">\(\sum m_{hi}^*=m_h\)</span>). Creamos
una replicación del ponderador correspondiente a la <span class="math inline">\(k\)</span>-ésima unidad (USM) como:</li>
</ol>
<p><span class="math display">\[d_k^*=d_k \bigg[\bigg(1-\sqrt{\frac{m_h}{n_h - 1}}\bigg) + 
\bigg(\sqrt{\frac{m_h}{n_h - 1}}\frac{n_h}{m_h}m_{h}^*\bigg)\bigg]\]</span></p>
<p>donde <span class="math inline">\(d_k\)</span> es el inverso de la probabilidad de selección. Si <span class="math inline">\(m_h&lt;(n_h -1)\)</span>
todos los pesos definidos de esta manera serán no negativos. Calculamos el
peso final <span class="math inline">\(w_k^*\)</span> aplicando a <span class="math inline">\(d_k^*\)</span> los mismos ajustes que se hicieron a los
ponderadores originales.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Calculamos el estadístico de interés <span class="math inline">\(\hat{\theta}\)</span> usando los ponderadores
<span class="math inline">\(w_k^*\)</span> en lugar de los originales <span class="math inline">\(w_k\)</span>.</p></li>
<li><p>Repetimos los pasos 1 y 2 <span class="math inline">\(B\)</span> veces para obtener <span class="math inline">\(\hat{\theta}^{*1},\hat{\theta}^{*2},...,\hat{\theta}^{*B}\)</span>.</p></li>
<li><p>Calculamos el error estándar como:
<span class="math display">\[\hat{se}_B = \bigg\{\frac{\sum_{b=1}^B[\hat{\theta}^*(b)-\hat{\theta}^*(\cdot)]^2 }{B}\bigg\}^{1/2}\]</span></p></li>
</ol>
<p>Podemos elegir cualquier valor de <span class="math inline">\(m_h \geq 1\)</span>, el más sencillo es elegir
<span class="math inline">\(m_h=n_h-1\)</span>, en este caso:
<span class="math display">\[d_k^*=d_k \frac{n_h}{n_h-1}m_{hi}^*\]</span>
en este escenario las unidades que no se incluyen en la muestra tienen
un valor de cero como ponderador. Si elegimos <span class="math inline">\(n_h \ne n_h-1\)</span> las unidades que
no están en la muestra tienen ponderador distinto a cero, si <span class="math inline">\(m_h=n_h\)</span> el
ponderador podría tomar valores negativos.</p>
<p>Implementemos el bootstrap de Rao y Wu a la ENIGH, usaremos <span class="math inline">\(m_h=n_h-1\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># creamos una tabla con los estratos y upms</span>
est_upm &lt;-<span class="st"> </span>hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">distinct</span>(est_dis, upm, n)

hogar_factor &lt;-<span class="st"> </span>est_upm <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">split</span>(.<span class="op">$</span>est_dis) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># dentro de cada estrato tomamos muestra (n_h-1)</span>
<span class="st">    </span><span class="kw">map_df</span>(<span class="op">~</span><span class="kw">sample_n</span>(., <span class="dt">size =</span> <span class="kw">first</span>(.<span class="op">$</span>n) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">add_count</span>(upm) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># calculamos m_hi*</span>
<span class="st">    </span><span class="kw">left_join</span>(hogar, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;est_dis&quot;</span>, <span class="st">&quot;upm&quot;</span>, <span class="st">&quot;n&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">factor_b =</span> factor_hog <span class="op">*</span><span class="st"> </span>nn <span class="op">*</span><span class="st"> </span>n <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))

<span class="co"># unimos los pasos anteriores en una función para replicar en cada muestra bootstrap</span>
svy_boot &lt;-<span class="st"> </span><span class="cf">function</span>(est_upm, hogar){
    m_hi &lt;-<span class="st"> </span>est_upm <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">split</span>(.<span class="op">$</span>est_dis) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">map</span>(<span class="op">~</span><span class="kw">sample</span>(.<span class="op">$</span>upm, <span class="dt">size =</span> <span class="kw">first</span>(.<span class="op">$</span>n) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">flatten_chr</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>plyr<span class="op">::</span><span class="kw">count</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">select</span>(<span class="dt">upm =</span> x, <span class="dt">m_h =</span> freq)
    m_hi <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">upm =</span> <span class="kw">as.character</span>(upm)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">left_join</span>(hogar, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;upm&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">factor_b =</span> factor_hog <span class="op">*</span><span class="st"> </span>m_h <span class="op">*</span><span class="st"> </span>n <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
}
<span class="kw">set.seed</span>(<span class="dv">1038984</span>)
boot_rep &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">500</span>, <span class="kw">svy_boot</span>(est_upm, hogar))

<span class="co"># Aplicación a ingreso medio</span>
media &lt;-<span class="st"> </span><span class="cf">function</span>(w, x) <span class="kw">sum</span>(w <span class="op">*</span><span class="st"> </span>x) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(w)

<span class="co"># La media es:</span>
hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarise</span>(<span class="dt">media =</span> <span class="kw">media</span>(factor_hog, ing_cor))
<span class="co">#&gt; # A tibble: 1 x 1</span>
<span class="co">#&gt;    media</span>
<span class="co">#&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 39719.</span></code></pre>
<p>Y el error estándar:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">map_dbl</span>(boot_rep, <span class="op">~</span><span class="kw">media</span>(<span class="dt">w =</span> .<span class="op">$</span>factor_b, <span class="dt">x =</span> .<span class="op">$</span>ing_cor)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()
<span class="co">#&gt; [1] 946</span></code></pre>
<p>El método bootstrap está implementado en el paquete <code>survey</code> y más recientemente
en <code>srvyr</code> que es una versión <em>tidy</em> que utiliza las funciones en <code>survey</code>.</p>
<p>Podemos comparar nuestros resultados con la implementación en <code>survey</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1. Definimos el diseño de la encuesta</span>
<span class="kw">library</span>(survey)
<span class="kw">library</span>(srvyr)

enigh_design &lt;-<span class="st"> </span>hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as_survey_design</span>(<span class="dt">ids =</span> upm, <span class="dt">weights =</span> factor_hog, <span class="dt">strata =</span> est_dis)

<span class="co"># 2. Elegimos bootstrap como el método para el cálculo de errores estándar</span>
<span class="kw">set.seed</span>(<span class="dv">7398731</span>)
enigh_boot &lt;-<span class="st"> </span>enigh_design <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as_survey_rep</span>(<span class="dt">type =</span> <span class="st">&quot;subbootstrap&quot;</span>, <span class="dt">replicates =</span> <span class="dv">500</span>)

<span class="co"># 3. Así calculamos la media</span>
enigh_boot <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>srvyr<span class="op">::</span><span class="kw">summarise</span>(<span class="dt">mean_ingcor =</span> <span class="kw">survey_mean</span>(ing_cor))
<span class="co">#&gt; # A tibble: 1 x 2</span>
<span class="co">#&gt;   mean_ingcor mean_ingcor_se</span>
<span class="co">#&gt;         &lt;dbl&gt;          &lt;dbl&gt;</span>
<span class="co">#&gt; 1      39719.          1008.</span>
<span class="co"># cuantiles</span>
<span class="kw">svyquantile</span>(<span class="op">~</span>ing_cor, enigh_boot, <span class="dt">quantiles =</span> <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), <span class="dt">interval.type =</span> <span class="st">&quot;quantile&quot;</span>)
<span class="co">#&gt; Statistic:</span>
<span class="co">#&gt;      ing_cor</span>
<span class="co">#&gt; q0.1   10622</span>
<span class="co">#&gt; q0.2   14775</span>
<span class="co">#&gt; q0.3   18597</span>
<span class="co">#&gt; q0.4   22682</span>
<span class="co">#&gt; q0.5   27186</span>
<span class="co">#&gt; q0.6   32726</span>
<span class="co">#&gt; q0.7   40057</span>
<span class="co">#&gt; q0.8   51990</span>
<span class="co">#&gt; q0.9   76285</span>
<span class="co">#&gt; q1   4150377</span>
<span class="co">#&gt; SE:</span>
<span class="co">#&gt;      ing_cor</span>
<span class="co">#&gt; q0.1     144</span>
<span class="co">#&gt; q0.2     165</span>
<span class="co">#&gt; q0.3     193</span>
<span class="co">#&gt; q0.4     218</span>
<span class="co">#&gt; q0.5     239</span>
<span class="co">#&gt; q0.6     348</span>
<span class="co">#&gt; q0.7     484</span>
<span class="co">#&gt; q0.8     769</span>
<span class="co">#&gt; q0.9    1322</span>
<span class="co">#&gt; q1   1318629</span></code></pre>
<p>Supongamos que queremos calcular la media para los hogares con jefe de familia
mujer mayor a 50 años.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Creamos datos con filter y repetimos lo de arriba</span>
hogar_mujer &lt;-<span class="st"> </span><span class="kw">filter</span>(hogar, jefa_<span class="dv">50</span>)
est_upm_mujer &lt;-<span class="st"> </span>hogar_mujer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">distinct</span>(est_dis, upm, n)
<span class="co"># bootstrap</span>
boot_rep_mujer &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">500</span>, <span class="kw">svy_boot</span>(est_upm_mujer, hogar_mujer))
<span class="co"># media y error estándar</span>
hogar_mujer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarise</span>(<span class="dt">media =</span> <span class="kw">media</span>(factor_hog, ing_cor))
<span class="co">#&gt; # A tibble: 1 x 1</span>
<span class="co">#&gt;    media</span>
<span class="co">#&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 35259.</span>
<span class="co"># usamos bootstrap para calcular los errores estándar</span>
<span class="kw">map_dbl</span>(boot_rep_mujer, <span class="op">~</span><span class="kw">media</span>(<span class="dt">w =</span> .<span class="op">$</span>factor_b, <span class="dt">x =</span> .<span class="op">$</span>ing_cor)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()
<span class="co">#&gt; [1] 1789</span></code></pre>
<p>Comparemos con los resultados de <code>srvyr</code>. ¿qué pasa?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(srvyr)
enigh_boot <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>srvyr<span class="op">::</span><span class="kw">group_by</span>(jefa_<span class="dv">50</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>srvyr<span class="op">::</span><span class="kw">summarise</span>(<span class="dt">mean_ingcor =</span> <span class="kw">survey_mean</span>(ing_cor))
<span class="co">#&gt; # A tibble: 2 x 3</span>
<span class="co">#&gt;   jefa_50 mean_ingcor mean_ingcor_se</span>
<span class="co">#&gt;   &lt;lgl&gt;         &lt;dbl&gt;          &lt;dbl&gt;</span>
<span class="co">#&gt; 1 FALSE        40412.           949.</span>
<span class="co">#&gt; 2 TRUE         35259.          1988.</span></code></pre>
<p>Sub-poblaciones como “jefas de familia mayores a 50” se conocen como un dominio, esto es
un subgrupo cuyo tamaño de muestra es aleatorio. Este ejemplo nos recalca la
importancia de considerar el proceso en que se generó la muestra para calcular
los errores estándar bootstrap.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">map_dbl</span>(boot_rep, 
    <span class="cf">function</span>(x){hm &lt;-<span class="st"> </span><span class="kw">filter</span>(x, jefa_<span class="dv">50</span>); <span class="kw">media</span>(<span class="dt">w =</span> hm<span class="op">$</span>factor_b, <span class="dt">x =</span> hm<span class="op">$</span>ing_cor)}) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">sd</span>()
<span class="co">#&gt; [1] 1965</span></code></pre>
<p>Resumiendo:</p>
<ul>
<li><p>El bootstrap de Rao y Wu genera un estimador consistente y aproximadamente
insesgado de la varianza de estadísticos no lineales y para la varianza de un
cuantil.</p></li>
<li><p>Este método supone que la seleccion de UPMs es con reemplazo; hay variaciones
del estimador bootstrap de Rao y Wu que extienden el método que acabamos de
estudiar; sin embargo, es común ignorar este aspecto,
por ejemplo <a href="https://fcsm.sites.usa.gov/files/2014/05/2005FCSM_Mach_Dumais_Robidou_VA.pdf">Mach et al</a> estudian las propiedades del estimador de varianza bootstrap de Rao y Wu cuando
la muestra se seleccionó sin reemplazo.</p></li>
</ul>
<!-- West explica porque únicamente se ignora la variabilidad de las USMs en un 
(deocumento)[http://www.isr.umich.edu/src/smp/asda/first_stage_ve_new.pdf]
-->
</div>
<div id="intervalos-de-confianza" class="section level3">
<h3><span class="header-section-number">6.6.1</span> Intervalos de confianza</h3>
<p>Hasta ahora hemos discutido la idea detrás del bootstrap y como se puede usar
para estimar errores estándar. Comenzamos con el error estándar pues es la
manera más común para describir la precisión de una estadística.</p>
<ul>
<li><p>En términos generales, esperamos que <span class="math inline">\(\bar{x}\)</span> este a una distancia de <span class="math inline">\(\mu_P\)</span>
menor a un error estándar el 68% del tiempo, y a menos de 2 errores estándar el
95% del tiempo.</p></li>
<li><p>Estos porcentajes están basados el teorema central del límite que nos dice que
bajo ciertas condiciones (bastante generales) de <span class="math inline">\(P\)</span> la distribución de
<span class="math inline">\(\bar{x}\)</span> se aproximará a una distribución normal:</p></li>
</ul>
<p><span class="math display">\[\bar{x} \overset{\cdot}{\sim} N(\mu_P,\sigma_P^2/n)\]</span></p>
<p>Algunos ejemplos de como funciona el Teorema del Límite
Central, la idea es ver como se aproxima la distribución muestral de la media
(cuando las observaciones provienen de distintas distribuciones) a una
Normal conforme aumenta el tamaño de muestra. Para esto, aproximamos la
distribución muestral de la media usando simulación.</p>
<p>Vale la pena observar que hay distribuciones que requieren un mayor tamaño
de muestra <span class="math inline">\(n\)</span> para lograr una buena aproximación (por ejemplo la log-normal),
¿a qué se debe esto?</p>
<p>Para la opción de <em>Elecciones</em> tenemos una poblac ión de tamaño <span class="math inline">\(N=143,437\)</span> y el
objetivo es estimar la media del tamaño de la lista nominal de las casillas
(datos de las elecciones presidenciales de 2012). Podemos ver como mejora la aproximación
Normal de la distribución muestral conforme aumenta el tamaño de muestra <span class="math inline">\(n\)</span>;
sin embargo, también sobresale que no es necesario tomar una muestra demasiado
grande (<span class="math inline">\(n = 60\)</span> ya es razonable).</p>
<pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">include_app</span>(<span class="st">&quot;https://tereom.shinyapps.io/15-TLC/&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;1000px&quot;</span>)</code></pre>
<iframe src="https://tereom.shinyapps.io/15-TLC/?showcase=0" width="672" height="1000px">
</iframe>
<p>A pesar de que los errores estándar suelen usarse
para construir intervalos de confianza basados en que las estimaciones tienen
una distribución normal; sin embargo, el bootstrap se puede usar para estimar
la función de distribución de <span class="math inline">\(\hat{\theta}\)</span> por lo que no es necesario hacer
supuestos distribucionales para <span class="math inline">\(\hat{\theta}\)</span> sino que podemos estimarla como
parte del proceso de construir intervalos de confianza.</p>
<p>Para estudiar intervalos de confianza usaremos el siguiente ejemplo:
supongamos que queremos estimar la kurtosis de una base de datos que consta de
799 tiempos de espera entre pulsasiones de un nervio (Cox, Lewis 1976).
<span class="math display">\[\hat{\theta} = t(P_n) =\frac{1/n \sum_{i=1}^n(x_i-\hat{\mu})^3}{\hat{\sigma}^3}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">nerve &lt;-<span class="st"> </span><span class="kw">read_delim</span>(<span class="st">&quot;data/nerve.txt&quot;</span>, <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">escape_double =</span> <span class="ot">FALSE</span>, 
    <span class="dt">col_names =</span> <span class="ot">FALSE</span>, <span class="dt">trim_ws =</span> <span class="ot">TRUE</span>)
<span class="co">#&gt; Parsed with column specification:</span>
<span class="co">#&gt; cols(</span>
<span class="co">#&gt;   X1 = col_double(),</span>
<span class="co">#&gt;   X2 = col_double(),</span>
<span class="co">#&gt;   X3 = col_double(),</span>
<span class="co">#&gt;   X4 = col_double(),</span>
<span class="co">#&gt;   X5 = col_double(),</span>
<span class="co">#&gt;   X6 = col_double()</span>
<span class="co">#&gt; )</span>
nerve_long &lt;-<span class="st"> </span>tidyr<span class="op">::</span><span class="kw">gather</span>(nerve, col, val, X1<span class="op">:</span>X6) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(val))

kurtosis &lt;-<span class="st"> </span><span class="cf">function</span>(x){
    n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
    <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>n <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)) <span class="op">^</span><span class="st"> </span><span class="dv">3</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(x) <span class="op">^</span><span class="st"> </span><span class="dv">3</span> 
}

theta_hat &lt;-<span class="st"> </span><span class="kw">kurtosis</span>(nerve_long<span class="op">$</span>val)
theta_hat
<span class="co">#&gt; [1] 1.76</span>

kurtosis_boot &lt;-<span class="st"> </span><span class="cf">function</span>(x, n){
  x_boot &lt;-<span class="st"> </span><span class="kw">sample</span>(x, n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
  <span class="kw">kurtosis</span>(x_boot)
}
B &lt;-<span class="st"> </span><span class="dv">2000</span>
kurtosis &lt;-<span class="st"> </span><span class="kw">rerun</span>(B, <span class="kw">kurtosis_boot</span>(nerve_long<span class="op">$</span>val, <span class="kw">length</span>(nerve_long<span class="op">$</span>val))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">flatten_dbl</span>()</code></pre>
<ol style="list-style-type: decimal">
<li>Comencemos recordando el <strong>Intervalo Normal</strong>:</li>
</ol>
<p><span class="math display">\[(\hat{\theta}- z^{(1-\alpha)}\cdot \hat{se}, \hat{\theta}-z^{(\alpha)}\cdot \hat{se})\]</span></p>
<p>este intervalo no es preciso cuando <span class="math inline">\(\hat{\theta}\)</span> no se distribuye Normal.</p>
<pre class="sourceCode r"><code class="sourceCode r">li_normal &lt;-<span class="st"> </span><span class="kw">round</span>(theta_hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(kurtosis), <span class="dv">2</span>)
ls_normal &lt;-<span class="st"> </span><span class="kw">round</span>(theta_hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(kurtosis), <span class="dv">2</span>)</code></pre>
<p>Veamos un histograma de las replicaciones bootstrap de <span class="math inline">\(\hat{\theta}*\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r">nerve_kurtosis &lt;-<span class="st"> </span><span class="kw">data_frame</span>(kurtosis)
hist_nerve &lt;-<span class="st"> </span><span class="kw">ggplot</span>(nerve_kurtosis, <span class="kw">aes</span>(<span class="dt">x =</span> kurtosis)) <span class="op">+</span><span class="st"> </span>
<span class="st">        </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">fill =</span> <span class="st">&quot;gray30&quot;</span>) <span class="op">+</span>
<span class="st">            </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">c</span>(li_normal, ls_normal, theta_hat), 
            <span class="dt">color =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">alpha =</span> <span class="fl">0.5</span>)

qq_nerve &lt;-<span class="st"> </span><span class="kw">ggplot</span>(nerve_kurtosis) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> kurtosis), <span class="dt">dparams =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(kurtosis), <span class="dt">sd =</span> <span class="kw">sd</span>(kurtosis))) 

<span class="kw">grid.arrange</span>(hist_nerve, qq_nerve, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">newpage =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-21-1.png" width="816" /></p>
<p>En el ejemplo anterior el supuesto de normalidad parece razonable, veamos
como se comparan los cuantiles de la estimación de la distribución de
<span class="math inline">\(\hat{\theta}\)</span> con los cuantiles de una normal:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">comma</span>(q_kurt &lt;-<span class="st"> </span><span class="kw">quantile</span>(kurtosis, <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.975</span>)))
<span class="kw">comma</span>(<span class="kw">qnorm</span>(<span class="dt">p =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.95</span>, <span class="fl">0.975</span>), <span class="dt">mean =</span> theta_hat, 
  <span class="dt">sd =</span> <span class="kw">sd</span>(kurtosis)))
<span class="co">#&gt;  2.5%    5%   10%   90%   95% 97.5% </span>
<span class="co">#&gt; &quot;1.4&quot; &quot;1.5&quot; &quot;1.5&quot; &quot;1.9&quot; &quot;2.0&quot; &quot;2.0&quot; </span>
<span class="co">#&gt; [1] &quot;1.4&quot; &quot;1.5&quot; &quot;1.6&quot; &quot;2.0&quot; &quot;2.0&quot; &quot;2.1&quot;</span></code></pre>
<p>Esto sugiere usar los cuantiles del histograma bootstrap para definir los
límites de los intervalos de confianza:</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Percentiles</strong>. Denotemos por <span class="math inline">\(G\)</span> la función de distribución acumulada de
<span class="math inline">\(\hat{\theta}^*\)</span> el intervalo percentil de <span class="math inline">\(1-2\alpha\)</span> se define por los
percentiles <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(1-\alpha\)</span> de <span class="math inline">\(G\)</span>
<span class="math display">\[(\theta^*_{\%,inf}, \theta^*_{\%,sup}) = (G^{-1}(\alpha), G^{-1}(1-\alpha))\]</span></li>
</ol>
<p>Por definición <span class="math inline">\(G^{-1}(\alpha)=\hat{\theta}^*(\alpha)\)</span>, esto es, el percentil
<span class="math inline">\(100\cdot \alpha\)</span> de la distribución bootstrap, por lo que podemos escribir el
intervalo bootstrap como
<span class="math display">\[(\theta^*_{\%,inf}, \theta^*_{\%,sup})=(\hat{\theta}^*(\alpha),\hat{\theta}^*(1-\alpha))\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">arrange</span>(nerve_kurtosis, kurtosis)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">stat_ecdf</span>(<span class="kw">aes</span>(<span class="dt">x =</span> kurtosis)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_segment</span>(<span class="dt">data =</span> <span class="kw">data_frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="op">-</span><span class="ot">Inf</span>, <span class="op">-</span><span class="ot">Inf</span>, q_kurt[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>)]), 
        <span class="dt">xend =</span> q_kurt[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="dv">6</span>)], <span class="dt">y =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>, <span class="dv">0</span>, <span class="dv">0</span>), 
        <span class="dt">yend =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>, <span class="fl">0.025</span>, <span class="fl">0.975</span>)), <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">xend =</span> xend, <span class="dt">y =</span> y, 
        <span class="dt">yend =</span> yend), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="fl">0.4</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Cuantiles muestrales&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;ecdf&quot;</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-23-1.png" width="384" /></p>
<p>Las expresiones regulares hacen referencia a la situación bootstrap <em>ideal</em>
donde el número de replicaciones bootstrap es infinito, en la práctica usamos
aproximaciones. Y se procede como sigue:</p>
<div style="caja">
<p>Intervalo percentil:</p>
<ul>
<li><p>Generamos B muestras bootstrap independientes <span class="math inline">\(\textbf{x}^{*1},..., \textbf{x}^{*B}\)</span> y calculamos las replicaciones <span class="math inline">\(\hat{\theta}^{*b}=s(x^{*b}).\)</span></p></li>
<li>Sea <span class="math inline">\(\hat{\theta}^{*}_B(\alpha)\)</span> el percentil <span class="math inline">\(100\cdot\alpha\)</span> de la
distribución empírica de <span class="math inline">\(\hat{\theta}^{*}\)</span>, y <span class="math inline">\(\hat{\theta}^{*}_B(\alpha)\)</span>
el correspondiente al percentil <span class="math inline">\(100\cdot (1-\alpha)\)</span>, escribimos el intervalo
de percentil <span class="math inline">\(1-2\alpha\)</span> como
<span class="math display">\[(\theta^*_{\%,inf}, \theta^*_{\%,sup})\approx(\hat{\theta}^*_B(\alpha),\hat{\theta}^*_B(1-\alpha))\]</span></li>
</ul>
</div>
<pre class="sourceCode r"><code class="sourceCode r">ls_per &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">quantile</span>(kurtosis, <span class="dt">prob =</span> <span class="fl">0.975</span>), <span class="dv">2</span>)
li_per &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">quantile</span>(kurtosis, <span class="dt">prob =</span> <span class="fl">0.025</span>), <span class="dv">2</span>)
stringr<span class="op">::</span><span class="kw">str_c</span>(li_normal, ls_normal, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)
stringr<span class="op">::</span><span class="kw">str_c</span>(li_per, ls_per, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>)
<span class="co">#&gt; [1] &quot;1.44,2.07&quot;</span>
<span class="co">#&gt; [1] &quot;1.43,2.05&quot;</span></code></pre>
<p>Si la distribución de <span class="math inline">\(\hat{\theta}^*\)</span> es aproximadamente normal, entonces
los intervalos normales y de percentiles serán similares. El teorema del
límite central nos dice que conforme <span class="math inline">\(n\)</span> se acerca a infinito el histograma
bootstrap adquirirá una forma similar a la normal; sin embargo, cuando el
tamaño de muestra es chico habrá diferencias.</p>
<p>Con el fin de comparar los intervalos creamos un ejemplo de simulación
(ejemplo tomado de Effron y Tibshirani), generamos una muestra de tamaño 10 de una
distribución normal estándar, supongamos que el parámetro de interés es
<span class="math inline">\(e^{\mu}\)</span> donde <span class="math inline">\(\mu\)</span> es la media poblacional.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">137612</span>)
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">10</span>)

boot_sim_exp &lt;-<span class="st"> </span><span class="cf">function</span>(){
  x_boot &lt;-<span class="st"> </span><span class="kw">sample</span>(x, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
  <span class="kw">exp</span>(<span class="kw">mean</span>(x_boot))
}
theta_boot &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">1000</span>, <span class="kw">boot_sim_exp</span>()) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">flatten_dbl</span>()
theta_boot_df &lt;-<span class="st"> </span><span class="kw">data_frame</span>(theta_boot)

hist_emu &lt;-<span class="st"> </span><span class="kw">ggplot</span>(theta_boot_df, <span class="kw">aes</span>(<span class="dt">x =</span> theta_boot)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;gray30&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.08</span>) 
qq_emu &lt;-<span class="st"> </span><span class="kw">ggplot</span>(theta_boot_df) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> theta_boot), 
        <span class="dt">dparams =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(theta_boot), <span class="dt">sd =</span> <span class="kw">sd</span>(theta_boot))) 

<span class="kw">grid.arrange</span>(hist_emu, qq_emu, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">newpage =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-25-1.png" width="816" /></p>
<p>La distribución empírica de <span class="math inline">\(\hat{\theta}^*\)</span> es asimétrica, por lo que no
esperamos que coincidan los intervalos.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Normal</span>
<span class="kw">round</span>(<span class="kw">exp</span>(<span class="kw">mean</span>(x)) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(theta_boot), <span class="dv">2</span>)
<span class="co">#&gt; [1] 0.33</span>
<span class="kw">round</span>(<span class="kw">exp</span>(<span class="kw">mean</span>(x)) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(theta_boot), <span class="dv">2</span>)
<span class="co">#&gt; [1] 1.62</span>

<span class="co">#Percentil</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(theta_boot, <span class="dt">prob =</span> <span class="fl">0.025</span>), <span class="dv">2</span>)
<span class="co">#&gt; 2.5% </span>
<span class="co">#&gt; 0.54</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(theta_boot, <span class="dt">prob =</span> <span class="fl">0.975</span>), <span class="dv">2</span>)
<span class="co">#&gt; 97.5% </span>
<span class="co">#&gt;  1.78</span></code></pre>
<p>La inspección del histograma deja claro que la aproximación normal no es
conveniente en este caso, veamos que ocurre cuando aplicamos la transformación
logarítmica.</p>
<pre class="sourceCode r"><code class="sourceCode r">hist_log &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data_frame</span>(theta_boot), <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log</span>(theta_boot))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;gray30&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.08</span>) 
qq_log &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data_frame</span>(theta_boot)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> <span class="kw">log</span>(theta_boot)), 
        <span class="dt">dparams =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(<span class="kw">log</span>(theta_boot)), <span class="dt">sd =</span> <span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)))) 

<span class="kw">grid.arrange</span>(hist_log, qq_log, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">newpage =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-27-1.png" width="816" /></p>
<p>Y los intervalos se comparan:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Normal</span>
<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>)
<span class="co">#&gt; [1] -0.64</span>
<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>)
<span class="co">#&gt; [1] 0.59</span>

<span class="co">#Percentil</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(<span class="kw">log</span>(theta_boot), <span class="dt">prob =</span> <span class="fl">0.025</span>), <span class="dv">2</span>)
<span class="co">#&gt;  2.5% </span>
<span class="co">#&gt; -0.62</span>
<span class="kw">round</span>(<span class="kw">quantile</span>(<span class="kw">log</span>(theta_boot), <span class="dt">prob =</span> <span class="fl">0.975</span>), <span class="dv">2</span>)
<span class="co">#&gt; 97.5% </span>
<span class="co">#&gt;  0.58</span></code></pre>
<p>La transformación logarítmica convierte la distribución de <span class="math inline">\(\hat{\theta}\)</span> en
normal y por tanto los intervalos de <span class="math inline">\(\hat{\phi}^*=log(\hat{\theta}^*)\)</span> son
similares. La forma normal no es sorprendente pues <span class="math inline">\(\hat{\phi}^*=\bar{x}^*\)</span>.</p>
<p>Si mapeamos los intervalos normales calculados para <span class="math inline">\(log(\hat{\theta}^*)\)</span> de
regreso a la escala de <span class="math inline">\(\theta\)</span> obtenemos intervalos similares a los calculados
para <span class="math inline">\(\hat{\theta}^*\)</span> usando percentiles:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>))
<span class="co">#&gt; [1] 0.527</span>
<span class="kw">exp</span>(<span class="kw">round</span>(<span class="kw">mean</span>(x) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(<span class="kw">log</span>(theta_boot)), <span class="dv">2</span>))
<span class="co">#&gt; [1] 1.8</span></code></pre>
<p>Podemos ver que el método de aplicar una transformación, calcular intervalos
usando la normal y aplicar la transformación inversa para volver a la escala
original genera intervalos de confianza atractivos, el problema con este
método es que requiere que conozcamos la transformación adecuada para cada
parámetro. Por otra parte, podemos pensar en el método del percentil como un
algoritmo que incorpora la transformación de manera automática.</p>
<div class="caja>
<strong>Lema</strong>. Supongamos que la transformación <span class="math inline">\(\hat{\phi}=m(\hat{\theta})\)</span>
normaliza la distribución de <span class="math inline">\(\hat{\theta}\)</span> de manera perfecta,
<span class="math display">\[\hat{\phi} \approx N(\phi, c^2)\]</span>
para alguna desviación estándar <span class="math inline">\(c\)</span>. Entonces el intervalo de percentil basado
en <span class="math inline">\(\hat{\theta}\)</span> es igual a
<span class="math display">\[(m^{-1} (\hat{\phi}-z^{(1-\alpha)}c), m^{-1}(\hat{\phi}-z^{(\alpha)}c))\]</span>
</div>
<p>Existen otras alternativas al método del percentil y cubren otras fallas del
intervalo normal. Por ejemplo, hay ocasiones en que <span class="math inline">\(\hat{\theta}\)</span> tiene una
distribución normal sesgada:
<span class="math display">\[\hat{\theta} \approx N(\theta + sesgo, \hat{se}^2)\]</span></p>
<p>en este caso no existe una transformación <span class="math inline">\(m(\theta)\)</span> que <em>arregle</em> el intervalo.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Intervalos acelerados y corregidos por sesgo</strong>. Esta es una versión mejorada
del intervalo de percentil, la denotamos <span class="math inline">\(BC_{a}\)</span> (bias-corrected and
accelerated).</li>
</ol>
<p>Usaremos un ejemplo de Effron y Tibshirani, los datos constan de los resultados
en dos pruebas espaciales de 26 niños con algún problema neurológico. Supongamos
que queremos calcular un intervalo de confianza de 90% para <span class="math inline">\(\theta=var(A)\)</span>.
El estimador plugin es:
<span class="math display">\[\hat{\theta}=\sum_{i=1}^n(A_i-\bar{A})^2/n\]</span>
notemos que el estimador <em>plug-in</em> es ligeramente menor que el estimador
usual insesgado:
<span class="math display">\[\hat{\theta}=\sum_{i=1}^n(A_i-\bar{A})^2/(n-1)\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bootstrap)
<span class="kw">data</span>(spatial)
<span class="kw">ggplot</span>(spatial) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(A, B))</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/spatial-1.png" width="336" /></p>
<pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">sum</span>((spatial<span class="op">$</span>A <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(spatial<span class="op">$</span>A)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(spatial)
<span class="co">#&gt; [1] 172</span>
<span class="kw">sum</span>((spatial<span class="op">$</span>A <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(spatial<span class="op">$</span>A)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">nrow</span>(spatial) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
<span class="co">#&gt; [1] 178</span></code></pre>
<p>El método <span class="math inline">\(BC_{a}\)</span> corrige el sesgo de manera automática, lo cuál es una
de sus prinicipales ventajas comparado con el método del percentil.</p>
<div class="caja>
Los extremos en los intervalos <span class="math inline">\(BC_{a}\)</span> están dados por percentiles de la
distribución bootstrap, los percentiles usados dependen de dos números <span class="math inline">\(\hat{a}\)</span>
y <span class="math inline">\(\hat{z}_0\)</span>, que se denominan la aceleración y la corrección del sesgo:
<span class="math display">\[BC_a : (\hat{\theta}_{inf}, \hat{\theta}_{sup})=(\hat{\theta}^*(\alpha_1), \hat{\theta}^*(\alpha_2))\]</span>
donde
<span class="math display">\[\alpha_1= \Phi\bigg(\hat{z}_0 + \frac{\hat{z}_0 + z^{(\alpha)}}{1- \hat{a}(\hat{z}_0 + z^{(\alpha)})}\bigg)\]</span>
<span class="math display">\[\alpha_2= \Phi\bigg(\hat{z}_0 + \frac{\hat{z}_0 + z^{(1-\alpha)}}{1- \hat{a}(\hat{z}_0 + z^{(1-\alpha)})}\bigg)\]</span>
y <span class="math inline">\(\Phi\)</span> es la función de distribución acumulada de la distribución normal estándar
y <span class="math inline">\(z^{\alpha}\)</span> es el percentil <span class="math inline">\(100 \cdot \alpha\)</span> de una distribución normal
estándar.
</div>
<p>Notemos que si <span class="math inline">\(\hat{a}\)</span> y <span class="math inline">\(\hat{z}_0\)</span> son cero entonces <span class="math inline">\(\alpha_1=\alpha\)</span> y
y <span class="math inline">\(\alpha_2=1-\alpha\)</span>, obteniendo así los intervalos de percentiles.
El valor de la corrección por sesgo <span class="math inline">\(\hat{z}_0\)</span> se obtiene de la
propoción de de replicaciones bootstrap menores a la estimación original
<span class="math inline">\(\hat{\theta}\)</span>,</p>
<p><span class="math display">\[\Phi^{-1}\bigg(\frac{\#\{\hat{\theta}^*(b) &lt; \hat{\theta} \} }{B} \bigg)\]</span></p>
<p>a grandes razgos <span class="math inline">\(\hat{z}_0\)</span> mide la mediana del sesgo de <span class="math inline">\(\hat{\theta}^*\)</span>, esto
es, la discrepancia entre la mediana de <span class="math inline">\(\hat{\theta}^*\)</span> y <span class="math inline">\(\hat{\theta}\)</span> en
unidades normales.</p>
<p>Por su parte la aceleración <span class="math inline">\(\hat{a}\)</span> se refiere a la tasa de cambio del error
estándar de <span class="math inline">\(\hat{\theta}\)</span> respecto al verdadero valor del parámetro <span class="math inline">\(\theta\)</span>.
La aproximación estándar usual <span class="math inline">\(\hat{\theta} \approx N(\theta, se^2)\)</span> supone que
el error estándar de <span class="math inline">\(\hat{\theta}\)</span> es el mismo para toda <span class="math inline">\(\hat{\theta}\)</span>, esto
puede ser poco realista, en nuestro ejemplo, donde <span class="math inline">\(\hat{\theta}\)</span> es la varianza
si los datos provienen de una normal <span class="math inline">\(se(\hat{\theta})\)</span> depende de <span class="math inline">\(\theta\)</span>.
Una manera de calcular <span class="math inline">\(\hat{a}\)</span> es</p>
<p><span class="math display">\[\hat{a}=\frac{\sum_{i=1}^n (\hat{\theta}(\cdot) - \hat{\theta}(i))^3}{6\{\sum_{i=1}^n (\hat{\theta}(\cdot) - \hat{\theta}(i))^2\}^{3/2}}\]</span></p>
<p>Los intervalos <span class="math inline">\(BC_{a}\)</span> tienen 2 ventajas teóricas: 1) Respetan transformaciones,
esto nos dice que los extremos del intervalo se transforman de manera adecuada
si cambiamos el parámetro de interés por una función del mismo, 2) su precisión,
los intervalos <span class="math inline">\(BC_{a}\)</span> tienen precisión de segundo orden, esto es, los errores
de cobertura se van a cero a una tasa de 1/n (los intervalos estándar y de
percentiles tienen precisión de primer orden).</p>
<p>Los intervalos <span class="math inline">\(BC_{a}\)</span> están implementados en el paquete boot (boot.ci) y
en el paquete bootstrap (bcanon). La desventaja de los intervalos <span class="math inline">\(BC_{a}\)</span> es
que requieron intenso cómputo estadístico, de acuerdo a Effron y Tibshirani al
menos <span class="math inline">\(B= 1000\)</span> replicaciones son necesairas para reducir el error de muestreo.
Ante esto surgen los intervalos ABC (approximate bootstrap confidence intervals),
que es un método para aproximar <span class="math inline">\(BC_{a}\)</span> analíticamente (usando expansiones de
Taylor).</p>
<p>Usando la implementación del paquete bootstrap:</p>
<pre class="sourceCode r"><code class="sourceCode r">var_sesgada &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x)
<span class="kw">bcanon</span>(<span class="dt">x =</span> spatial[, <span class="dv">1</span>], <span class="dt">nboot =</span> <span class="dv">2000</span>, <span class="dt">theta =</span> var_sesgada)
<span class="co">#&gt; $confpoints</span>
<span class="co">#&gt;      alpha bca point</span>
<span class="co">#&gt; [1,] 0.025       104</span>
<span class="co">#&gt; [2,] 0.050       115</span>
<span class="co">#&gt; [3,] 0.100       127</span>
<span class="co">#&gt; [4,] 0.160       138</span>
<span class="co">#&gt; [5,] 0.840       228</span>
<span class="co">#&gt; [6,] 0.900       243</span>
<span class="co">#&gt; [7,] 0.950       266</span>
<span class="co">#&gt; [8,] 0.975       282</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $z0</span>
<span class="co">#&gt; [1] 0.147</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $acc</span>
<span class="co">#&gt; [1] 0.0612</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $u</span>
<span class="co">#&gt;  [1] 164 177 175 178 172 172 175 172 176 173 169 168 155 142 178 178 178</span>
<span class="co">#&gt; [18] 151 178 177 166 173 177 178 178 173</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $call</span>
<span class="co">#&gt; bcanon(x = spatial[, 1], nboot = 2000, theta = var_sesgada)</span>

b_var &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">1000</span>, <span class="kw">var_sesgada</span>(<span class="kw">sample</span>(spatial[, <span class="dv">1</span>], <span class="dt">size =</span> <span class="kw">length</span>(spatial[, <span class="dv">1</span>]), <span class="dt">replace =</span> <span class="ot">TRUE</span>))) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">flatten_dbl</span>()

<span class="kw">qplot</span>(b_var) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>)
<span class="co">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r">
<span class="kw">ggplot</span>(<span class="kw">data_frame</span>(b_var)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">stat_qq</span>(<span class="kw">aes</span>(<span class="dt">sample =</span> b_var), 
        <span class="dt">dparams =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(b_var), <span class="dt">sd =</span> <span class="kw">sd</span>(b_var))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_abline</span>()</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-30-2.png" width="672" /></p>
<p><img src="../imagenes/manicule2.jpg" /> Comapara el intervalo anterior con los intervalos
normal y de percentiles.</p>
<p>Otros intervalos basados en bootstrap incluyen los intervalos pivotales y los
intervalos bootstrap-t. Sin embargo, BC y ABC son mejores alternativas.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Intervalos pivotales</strong>. Sea <span class="math inline">\(\theta=s(P)\)</span> y <span class="math inline">\(\hat{\theta}=s(P_n)\)</span> definimos
el pivote <span class="math inline">\(R=\hat{\theta}-\theta\)</span>. Sea <span class="math inline">\(H(r)\)</span> la función de distribución
acumulada del pivote:
<span class="math display">\[H(r) = P(R&lt;r)\]</span></li>
</ol>
<p>Definimos <span class="math inline">\(C_n^*=(a,b)\)</span> donde:
<span class="math display">\[a=\hat{\theta}-H^{-1}(1-\alpha), b=\hat{\theta}-H^{-1}(\alpha)\]</span>
<span class="math inline">\(C_n^*\)</span> es un intervalo de confianza de <span class="math inline">\(1-2\alpha\)</span> para <span class="math inline">\(\theta\)</span>; sin
embargo, <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> dependen de la distribución desconocida <span class="math inline">\(H\)</span>, la podemos
estimar usando bootstrap:
<span class="math display">\[\hat{H}(r)=\frac{1}{B}\sum_{b=1}^B I(R^*_b \le r)\]</span>
y obtenemos
<span class="math display">\[C_n=(2\hat{\theta} - \hat{\theta}^*_{1-\alpha}, 2\hat{\theta} + \hat{\theta}^*_{1-\alpha})\]</span></p>
</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references">
<div id="ref-RaoWu">
<p>Rao, J. N. K., and C. F. J. Wu. 1988. “Resampling Inference with Complex Survey Data.” <em>Journal of the American Statistical Association</em> 83 (401). Taylor &amp; Francis:231–41. <a href="https://doi.org/10.1080/01621459.1988.10478591" class="uri">https://doi.org/10.1080/01621459.1988.10478591</a>.</p>
</div>
<div id="ref-enigh">
<p>INEGI. 2014. “Encuesta Nacional de Ingresos Y Gastos de Los Hogares (Enigh-2014). Diseño Muestral.” <a href="http://internet.contenidos.inegi.org.mx/contenidos/Productos/prod_serv/contenidos/espanol/bvinegi/productos/nueva_estruc/702825070359.pdf" class="uri">http://internet.contenidos.inegi.org.mx/contenidos/Productos/prod_serv/contenidos/espanol/bvinegi/productos/nueva_estruc/702825070359.pdf</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="variacion-en-distribuciones-bootstrap.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bootstrap-en-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tereom/est-computacional-2018/edit/master/05-bootstrap_no_parametrico.Rmd",
"text": "Edit"
},
"download": ["est-computacional-2018.pdf", "est-computacional-2018.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
