<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>10.7 Muestreador de Gibbs | Estadística Computacional</title>
  <meta name="description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="10.7 Muestreador de Gibbs | Estadística Computacional />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  <meta name="github-repo" content="tereom/est-computacional-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.7 Muestreador de Gibbs | Estadística Computacional />
  
  <meta name="twitter:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  

<meta name="author" content="María Teresa Ortiz">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="metropolis.html">
<link rel="next" href="jags.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/d3-3.5.6/d3.min.js"></script>
<link href="libs/profvis-0.3.5/profvis.css" rel="stylesheet" />
<script src="libs/profvis-0.3.5/profvis.js"></script>
<link href="libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="libs/highlight-6.2.0/highlight.js"></script>
<script src="libs/profvis-binding-0.3.5/profvis.js"></script>
<script src="libs/plotly-binding-4.8.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.39.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.39.2/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
<link rel="stylesheet" href="css/font-awesome.min.css" type="text/css" />
<link rel="stylesheet" href="css/cajas.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Computacional</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html"><i class="fa fa-check"></i>Temario</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#calificacion"><i class="fa fa-check"></i>Calificación</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#otros-recursos"><i class="fa fa-check"></i>Otros recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html"><i class="fa fa-check"></i><b>1</b> Introducción a visualización</a><ul>
<li class="chapter" data-level="" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html#el-cuarteto-de-ascombe"><i class="fa fa-check"></i>El cuarteto de Ascombe</a></li>
<li class="chapter" data-level="1.1" data-path="introduccion.html"><a href="introduccion.html"><i class="fa fa-check"></i><b>1.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-de-datos-en-la-estadistica"><i class="fa fa-check"></i>Visualización de datos en la estadística</a></li>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>1.2</b> Teoría de visualización de datos</a><ul>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#principios-generales-del-diseno-analitico"><i class="fa fa-check"></i>Principios generales del diseño analítico</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tecnicas-de-visualizacion"><i class="fa fa-check"></i>Técnicas de visualización</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#indicadores-de-calidad-grafica"><i class="fa fa-check"></i>Indicadores de calidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#factor-de-engano-chartjunk-y-pies"><i class="fa fa-check"></i>Factor de engaño, chartjunk y pies</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#series-de-tiempo-y-promedio-de-45"><i class="fa fa-check"></i>Series de tiempo y promedio de 45</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#pequenos-multiplos-y-densidad-grafica"><i class="fa fa-check"></i>Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tinta-de-datos"><i class="fa fa-check"></i>Tinta de datos</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#percepcion-de-escala"><i class="fa fa-check"></i>Percepción de escala</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#minard"><i class="fa fa-check"></i>Minard</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduccion-a-r-y-al-paquete-ggplot2.html"><a href="introduccion-a-r-y-al-paquete-ggplot2.html"><i class="fa fa-check"></i><b>2</b> Introducción a R y al paquete ggplot2</a><ul>
<li class="chapter" data-level="2.1" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html"><i class="fa fa-check"></i><b>2.1</b> R: primeros pasos</a><ul>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#r-en-analisis-de-datos"><i class="fa fa-check"></i>R en análisis de datos</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#paquetes-y-el-tidyverse"><i class="fa fa-check"></i>Paquetes y el Tidyverse</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#recursos"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html"><i class="fa fa-check"></i><b>2.2</b> Visualización con ggplot2</a><ul>
<li class="chapter" data-level="" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html#recursos-1"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-agrupacion-de-datos.html"><a href="manipulacion-y-agrupacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y agrupación de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html"><i class="fa fa-check"></i><b>3.1</b> Transformación de datos</a><ul>
<li><a href="transformacion-de-datos.html#separa-aplica-combina-split-apply-combine">Separa-aplica-combina (<em>split-apply-combine</em>)</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ejemplos-y-lectura-de-datos"><i class="fa fa-check"></i>Ejemplos y lectura de datos</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#filtrar"><i class="fa fa-check"></i>Filtrar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#seleccionar"><i class="fa fa-check"></i>Seleccionar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ordenar"><i class="fa fa-check"></i>Ordenar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#mutar"><i class="fa fa-check"></i>Mutar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#summarise-y-resumenes-por-grupo"><i class="fa fa-check"></i>Summarise y resúmenes por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#operador-pipeline"><i class="fa fa-check"></i>Operador pipeline</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#variables-por-grupo"><i class="fa fa-check"></i>Variables por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#verbos-de-dos-tablas"><i class="fa fa-check"></i>Verbos de dos tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="datos-limpios.html"><a href="datos-limpios.html"><i class="fa fa-check"></i><b>3.2</b> Datos limpios</a><ul>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#limpieza-bases-de-datos"><i class="fa fa-check"></i>Limpieza bases de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#los-encabezados-de-las-columanas-son-valores"><i class="fa fa-check"></i>Los encabezados de las columanas son valores</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-columna-asociada-a-mas-de-una-variable"><i class="fa fa-check"></i>Una columna asociada a más de una variable</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#variables-almacenadas-en-filas-y-columnas"><i class="fa fa-check"></i>Variables almacenadas en filas y columnas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#mas-de-un-tipo-de-observacion-en-una-misma-tabla"><i class="fa fa-check"></i>Mas de un tipo de observación en una misma tabla</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-misma-unidad-observacional-esta-almacenada-en-multiples-tablas"><i class="fa fa-check"></i>Una misma unidad observacional está almacenada en múltiples tablas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#otras-consideraciones"><i class="fa fa-check"></i>Otras consideraciones</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#recursos-adicionales"><i class="fa fa-check"></i>Recursos adicionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="temas-selectos-de-r.html"><a href="temas-selectos-de-r.html"><i class="fa fa-check"></i><b>4</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="4.1" data-path="funciones.html"><a href="funciones.html"><i class="fa fa-check"></i><b>4.1</b> Funciones</a><ul>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#estructura-de-una-funcion"><i class="fa fa-check"></i>Estructura de una función</a></li>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#observaciones-del-uso-de-funciones"><i class="fa fa-check"></i>Observaciones del uso de funciones</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="vectores.html"><a href="vectores.html"><i class="fa fa-check"></i><b>4.2</b> Vectores</a><ul>
<li class="chapter" data-level="" data-path="vectores.html"><a href="vectores.html#propiedades"><i class="fa fa-check"></i>Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="iteracion.html"><a href="iteracion.html"><i class="fa fa-check"></i><b>4.3</b> Iteración</a></li>
<li class="chapter" data-level="4.4" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html"><i class="fa fa-check"></i><b>4.4</b> Rendimiento en R</a><ul>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#diagnosticar"><i class="fa fa-check"></i>Diagnosticar</a></li>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#estrategias-para-mejorar-desempeno"><i class="fa fa-check"></i>Estrategias para mejorar desempeño</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduccion-a-probabilidad.html"><a href="introduccion-a-probabilidad.html"><i class="fa fa-check"></i><b>5</b> Introducción a probabilidad</a><ul>
<li class="chapter" data-level="5.1" data-path="probabilidad-como-extension-a-proporcion.html"><a href="probabilidad-como-extension-a-proporcion.html"><i class="fa fa-check"></i><b>5.1</b> Probabilidad como extensión a proporción</a></li>
<li class="chapter" data-level="5.2" data-path="interpretacion-frecuentista-de-probabilidad.html"><a href="interpretacion-frecuentista-de-probabilidad.html"><i class="fa fa-check"></i><b>5.2</b> Interpretación frecuentista de probabilidad</a></li>
<li class="chapter" data-level="5.3" data-path="simulacion-para-el-calculo-de-probabilidades.html"><a href="simulacion-para-el-calculo-de-probabilidades.html"><i class="fa fa-check"></i><b>5.3</b> Simulación para el cálculo de probabilidades</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html"><i class="fa fa-check"></i><b>5.4</b> Probabilidad: definición matemática</a><ul>
<li class="chapter" data-level="5.4.1" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html#propiedades-de-la-funcion-de-probabilidad"><i class="fa fa-check"></i><b>5.4.1</b> Propiedades de la función de probabilidad:</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>5.5</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bootstrap-no-parametrico.html"><a href="bootstrap-no-parametrico.html"><i class="fa fa-check"></i><b>6</b> Bootstrap no paramétrico</a><ul>
<li class="chapter" data-level="6.1" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html"><i class="fa fa-check"></i><b>6.1</b> El principio del plug-in</a><ul>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#muestras-aleatorias"><i class="fa fa-check"></i>Muestras aleatorias</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#funcion-de-distribucion-empirica"><i class="fa fa-check"></i>Función de distribución empírica</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#parametros-y-estadisticas"><i class="fa fa-check"></i>Parámetros y estadísticas</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#distribuciones-muestrales-y-errores-estandar"><i class="fa fa-check"></i>Distribuciones muestrales y errores estándar</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html"><i class="fa fa-check"></i><b>6.2</b> El estimador bootstrap del error estándar</a><ul>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#variacion-en-distribuciones-bootstrap"><i class="fa fa-check"></i>Variación en distribuciones bootstrap</a></li>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#mas-alla-de-muestras-aleatorias-simples"><i class="fa fa-check"></i>Más alla de muestras aleatorias simples</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>6.3</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="6.4" data-path="bootstrap-en-r.html"><a href="bootstrap-en-r.html"><i class="fa fa-check"></i><b>6.4</b> Bootstrap en R</a></li>
<li class="chapter" data-level="6.5" data-path="conclusiones-y-observaciones.html"><a href="conclusiones-y-observaciones.html"><i class="fa fa-check"></i><b>6.5</b> Conclusiones y observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="teoria-basica-de-simulacion.html"><a href="teoria-basica-de-simulacion.html"><i class="fa fa-check"></i><b>7</b> Teoría básica de simulación</a><ul>
<li class="chapter" data-level="7.1" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html"><i class="fa fa-check"></i><b>7.1</b> Números pseudoaleatorios</a><ul>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#generadores-congruenciales-y-mersenne-twister"><i class="fa fa-check"></i>Generadores congruenciales y Mersenne-Twister</a></li>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#pruebas-de-aleatoriedad"><i class="fa fa-check"></i>Pruebas de aleatoriedad</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html"><i class="fa fa-check"></i><b>7.2</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-discretas-importantes"><i class="fa fa-check"></i>Familias discretas importantes</a></li>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-continuas-importantes"><i class="fa fa-check"></i>Familias Continuas importantes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html"><i class="fa fa-check"></i><b>7.3</b> Simulación de variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aletaorias-discretas"><i class="fa fa-check"></i>Variables aletaorias discretas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i>Variables aleatorias continuas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo-1"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html"><i class="fa fa-check"></i><b>8</b> Simulación de modelos</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html#para-que-simular-de-un-modelo"><i class="fa fa-check"></i>¿Para qué simular de un modelo?</a></li>
<li class="chapter" data-level="8.1" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html"><i class="fa fa-check"></i><b>8.1</b> Distribuciones multivariadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#regla-de-bayes"><i class="fa fa-check"></i>Regla de Bayes</a></li>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#independencia"><i class="fa fa-check"></i>Independencia</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-graficos-y-simulacion-predictiva.html"><a href="modelos-graficos-y-simulacion-predictiva.html"><i class="fa fa-check"></i><b>8.2</b> Modelos gráficos y simulación predictiva</a></li>
<li class="chapter" data-level="8.3" data-path="inferencia-visual.html"><a href="inferencia-visual.html"><i class="fa fa-check"></i><b>8.3</b> Inferencia visual</a><ul>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia"><i class="fa fa-check"></i>Inferencia</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#protocolos-de-inferencia-visual"><i class="fa fa-check"></i>Protocolos de inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#pruebas-de-hipotesis-tipicas"><i class="fa fa-check"></i>Pruebas de hipótesis típicas</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia-visual-1"><i class="fa fa-check"></i>Inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#mas-alla-que-permutacion"><i class="fa fa-check"></i>Más allá que permutación</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#otras-consideraciones-1"><i class="fa fa-check"></i>Otras consideraciones</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><a href="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><i class="fa fa-check"></i><b>8.4</b> Simulación para cálculo de tamaño de muestra/poder estadístico</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inferencia-parametrica.html"><a href="inferencia-parametrica.html"><i class="fa fa-check"></i><b>9</b> Inferencia paramétrica</a><ul>
<li class="chapter" data-level="9.1" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html"><i class="fa fa-check"></i><b>9.1</b> Máxima verosimilitud</a><ul>
<li class="chapter" data-level="" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html#propiedades-de-los-estimadores-de-maxima-verosimilitud"><i class="fa fa-check"></i>Propiedades de los estimadores de máxima verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="bootstrap-parametrico.html"><a href="bootstrap-parametrico.html"><i class="fa fa-check"></i><b>9.2</b> Bootstrap paramétrico</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="analisis-bayesiano.html"><a href="analisis-bayesiano.html"><i class="fa fa-check"></i><b>10</b> Análisis bayesiano</a><ul>
<li class="chapter" data-level="10.1" data-path="probabilidad-subjetiva.html"><a href="probabilidad-subjetiva.html"><i class="fa fa-check"></i><b>10.1</b> Probabilidad subjetiva</a></li>
<li class="chapter" data-level="10.2" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html"><i class="fa fa-check"></i><b>10.2</b> Regla de Bayes e inferencia bayesiana</a><ul>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#regla-de-bayes-en-modelos-y-datos"><i class="fa fa-check"></i>Regla de Bayes en modelos y datos</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#objetivos-de-la-inferencia"><i class="fa fa-check"></i>Objetivos de la inferencia</a></li>
<li class="chapter" data-level="" data-path="regla-de-bayes-e-inferencia-bayesiana.html"><a href="regla-de-bayes-e-inferencia-bayesiana.html#calculo-de-la-distribucion-posterior"><i class="fa fa-check"></i>Cálculo de la distribución posterior</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html"><i class="fa fa-check"></i><b>10.3</b> Distribuciones conjugadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-conjugadas.html"><a href="distribuciones-conjugadas.html#ejemplo-bernoulli"><i class="fa fa-check"></i>Ejemplo: Bernoulli</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="aproximacion-por-cuadricula.html"><a href="aproximacion-por-cuadricula.html"><i class="fa fa-check"></i><b>10.4</b> Aproximación por cuadrícula</a></li>
<li class="chapter" data-level="10.5" data-path="mcmc.html"><a href="mcmc.html"><i class="fa fa-check"></i><b>10.5</b> MCMC</a><ul>
<li class="chapter" data-level="" data-path="mcmc.html"><a href="mcmc.html#introduccion-metropolis"><i class="fa fa-check"></i>Introducción Metrópolis</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="metropolis.html"><a href="metropolis.html"><i class="fa fa-check"></i><b>10.6</b> Metrópolis</a><ul>
<li class="chapter" data-level="" data-path="metropolis.html"><a href="metropolis.html#inferencia-de-dos-proporciones-binomiales"><i class="fa fa-check"></i>Inferencia de dos proporciones binomiales</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html"><i class="fa fa-check"></i><b>10.7</b> Muestreador de Gibbs</a><ul>
<li class="chapter" data-level="" data-path="muestreador-de-gibbs.html"><a href="muestreador-de-gibbs.html#conclusiones-y-observaciones-metropolis-y-gibbs"><i class="fa fa-check"></i>Conclusiones y observaciones Metrópolis y Gibbs</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="jags.html"><a href="jags.html"><i class="fa fa-check"></i><b>10.8</b> JAGS</a><ul>
<li class="chapter" data-level="" data-path="jags.html"><a href="jags.html#ejemplo-normal-1"><i class="fa fa-check"></i>Ejemplo normal</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="diagnosticos.html"><a href="diagnosticos.html"><i class="fa fa-check"></i><b>10.9</b> Diagnósticos</a><ul>
<li class="chapter" data-level="" data-path="diagnosticos.html"><a href="diagnosticos.html#recomendaciones-generales"><i class="fa fa-check"></i>Recomendaciones generales</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html"><i class="fa fa-check"></i><b>10.10</b> HMC y Stan</a><ul>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#muestreo-hmc"><i class="fa fa-check"></i>Muestreo HMC</a></li>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#iniciales"><i class="fa fa-check"></i>Iniciales</a></li>
<li class="chapter" data-level="" data-path="hmc-y-stan.html"><a href="hmc-y-stan.html#recursos-adicionales-de-stan"><i class="fa fa-check"></i>Recursos adicionales de Stan</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html"><i class="fa fa-check"></i><b>10.11</b> Modelos jerárquicos</a><ul>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#modelo-jerarquico-una-moneda"><i class="fa fa-check"></i>Modelo jerárquico una moneda</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#multiples-monedas-de-una-misma-fabrica"><i class="fa fa-check"></i>Multiples monedas de una misma fábrica</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#ejemplo-estimacion-de-tasas-de-mortalidad"><i class="fa fa-check"></i>Ejemplo: estimación de tasas de mortalidad</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos.html"><a href="modelos-jerarquicos.html#ejemplo-conteo-rapido"><i class="fa fa-check"></i>Ejemplo: conteo rápido</a></li>
</ul></li>
<li class="chapter" data-level="10.12" data-path="flujo-de-trabajo-para-el-analisis-bayesiano.html"><a href="flujo-de-trabajo-para-el-analisis-bayesiano.html"><i class="fa fa-check"></i><b>10.12</b> Flujo de trabajo para el análisis bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a><ul>
<li class="chapter" data-level="" data-path="transformacion-de-datos-1.html"><a href="transformacion-de-datos-1.html"><i class="fa fa-check"></i>2-Transformación de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios-1.html"><a href="datos-limpios-1.html"><i class="fa fa-check"></i>3-Datos Limpios</a></li>
<li class="chapter" data-level="" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i>4-Probabilidad</a></li>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i>5-Bootstrap</a><ul>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html#solucion"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html"><i class="fa fa-check"></i>6-Cobertura de intervalos de confianza</a><ul>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html#solucion-1"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-1.html"><a href="simulacion-de-modelos-1.html"><i class="fa fa-check"></i>7-Simulación de modelos</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-de-regresion.html"><a href="simulacion-de-modelos-de-regresion.html"><i class="fa fa-check"></i>8-Simulación de modelos de regresión</a></li>
<li class="chapter" data-level="" data-path="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><a href="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><i class="fa fa-check"></i>9-Inferencia gráfica, tamaño de muestra, bootstrap paramétrico.</a><ul>
<li class="chapter" data-level="" data-path="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><a href="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html#solucion-2"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="familias-conjugadas.html"><a href="familias-conjugadas.html"><i class="fa fa-check"></i>10-Familias conjugadas</a></li>
<li class="chapter" data-level="" data-path="metropolis-2.html"><a href="metropolis-2.html"><i class="fa fa-check"></i>11-Metropolis</a><ul>
<li class="chapter" data-level="" data-path="metropolis-2.html"><a href="metropolis-2.html#solucion-3"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="mcmc-convergencia.html"><a href="mcmc-convergencia.html"><i class="fa fa-check"></i>12-MCMC convergencia</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html"><i class="fa fa-check"></i>13-Modelos jerárquicos</a><ul>
<li class="chapter" data-level="" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html#inferencia-grafica-1"><i class="fa fa-check"></i>1. Inferencia gráfica</a></li>
<li class="chapter" data-level="10.12.1" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html#simulacion-para-el-calculo-de-tamanos-de-muestra"><i class="fa fa-check"></i><b>10.12.1</b> 2. Simulación para el cálculo de tamaños de muestra</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html#mcmc-1"><i class="fa fa-check"></i>3. MCMC</a></li>
<li class="chapter" data-level="" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html#modelos-jerarquicos-y-evaluacion-de-ajuste"><i class="fa fa-check"></i>4. Modelos jerárquicos y evaluación de ajuste</a></li>
<li class="chapter" data-level="10.12.2" data-path="modelos-jerarquicos-1.html"><a href="modelos-jerarquicos-1.html#implementacion-1"><i class="fa fa-check"></i><b>10.12.2</b> Implementación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="muestreador-de-gibbs" class="section level2">
<h2><span class="header-section-number">10.7</span> Muestreador de Gibbs</h2>
<p>El algoritmo de Metrópolis es muy general y se puede aplicar a una gran variedad
de problemas. Sin embargo, afinar los parámetros de la distribución propuesta
para que el algoritmo funcione correctamente puede ser complicado. Por otra
parte, el muestredor de Gibbs no necesita de una distribución propuesta.</p>
<p><strong>Para implementar un muestreador de Gibbs se necesita ser capaz de generar
muestras de la distribución posterior condicional a cada uno de los
parámetros individuales.</strong> Esto es, el muestreador de Gibbs permite generar
muestras de la posterior:
<span class="math display">\[p(\theta_1,...,\theta_p|x)\]</span>
siempre y cuando podamos generar valores de todas las distribuciones
condicionales:
<span class="math display">\[p(\theta_k,|\theta_1,...,\theta_{k-1},\theta_{k+1},...,\theta_p,x)\]</span></p>
<p>El proceso del muestreador de Gibbs es una caminata aleatoria a lo largo del
espacio de parámetros. La caminata inicia en un punto arbitrario y en cada
tiempo el siguiente paso depende únicamente de la posición actual. Por tanto
el muestredor de Gibbs es un proceso cadena de Markov vía Monte Carlo. La
diferencia entre Gibbs y Metrópolis radica en como se deciden los pasos.</p>
<div class="caja">
<p><strong>Muestreador Gibbs</strong></p>
<p>En cada punto de la caminata se selecciona uno de los
componentes del vector de parámetros (típicamente se cicla en orden):</p>
<ol style="list-style-type: decimal">
<li><p>Supongamos que se selecciona el parámetro <span class="math inline">\(\theta_k\)</span>, entonces obtenemos un
nuevo valor para este parámetro generando una simulación de la distribución
condicional
<span class="math display">\[p(\theta_k,|\theta_1,...,\theta_{k-1},\theta_{k+1},...,\theta_p,x)\]</span></p></li>
<li><p>El nuevo valor <span class="math inline">\(\theta_k\)</span> junto con los valores que aun no cambian
<span class="math inline">\(\theta_1,...,\theta_{k-1},\theta_{k+1},...,\theta_p\)</span> constituyen la nueva
posición en la caminata aleatoria.</p></li>
<li><p>Seleccionamos una nueva componente (<span class="math inline">\(\theta_{k+1}\)</span>) y repetimos el proceso.</p></li>
</ol>
</div>
<p>El muestreador de Gibbs es útil cuando no podemos determinar de manera analítica
la distribución conjunta y no se puede simular directamente de ella, pero si
podemos determinar todas las distribuciones condicionales y simular de ellas.</p>
<p>Ejemplificaremos el muestreador de Gibbs con el ejemplo de las proporciones, a
pesar de no ser necesario en este caso.</p>
<p>Comenzamos identificando las distribuciones condicionales posteriores para cada
parámetro:</p>
<p><span class="math display">\[p(\theta_1|\theta_2,x) = p(\theta_1,\theta_2|x) / p(\theta_2|x)\]</span>
<span class="math display">\[= \frac{p(\theta_1,\theta_2|x)} {\int p(\theta_1,\theta_2|x) d\theta_1}\]</span></p>
<p>Usando iniciales <span class="math inline">\(beta(a_1, b_1)\)</span> y <span class="math inline">\(beta(a_2,b_2)\)</span>, obtenemos:</p>
<p><span class="math display">\[p(\theta_1|\theta_2,x) = \frac{beta(\theta_1|z_1 + a_1, N_1 - z_1 + b_1) beta(\theta_2|z_2 + a_2, N_2 - z_2 + b_2)}{\int beta(\theta_1|z_1 + a_1, N_1 - z_1 + b_1) beta(\theta_2|z_2 + a_2, N_2 - z_2 + b_2) d\theta_1}\]</span>
<span class="math display">\[= \frac{beta(\theta_1|z_1 + a_1, N_1 - z_1 + b_1) beta(\theta_2|z_2 + a_2, N_2 - z_2 + b_2)}{beta(\theta_2|z_2 + a_2, N_2 - z_2 + b_2)}\]</span>
<span class="math display">\[=beta(\theta_1|z_1 + a_1, N_1 - z_1 + b_1)\]</span></p>
<p>Debido a que la posterior es el producto de dos distribuciones Beta
independientes es claro que <span class="math inline">\(p(\theta_1|\theta_2,x)=p(\theta_1|x)\)</span>.</p>
<p>Una vez que determinamos las distribuciones condicionales, simplemente hay que
encontrar una manera de obtener muestras de estas, en R podemos usar la
función <span class="math inline">\(rbeta\)</span>.</p>
<p><img src="imagenes/pasos_gibbs.png" width="600px"/></p>
<pre class="sourceCode r"><code class="sourceCode r">pasos &lt;-<span class="st"> </span><span class="dv">12000</span>
camino &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> pasos, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="co"># vector que guardará las simulaciones</span>
camino[<span class="dv">1</span>, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="fl">0.1</span> <span class="co"># valor inicial</span>
camino[<span class="dv">1</span>, <span class="dv">2</span>] &lt;-<span class="st"> </span><span class="fl">0.1</span>

<span class="co"># Generamos la caminata aleatoria</span>
<span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>pasos){
  <span class="cf">if</span>(j <span class="op">%%</span><span class="st"> </span><span class="dv">2</span>){
    camino[j, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1</span>, z_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>a_<span class="dv">1</span>, N_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>z_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>b_<span class="dv">1</span>)
    camino[j, <span class="dv">2</span>] &lt;-<span class="st"> </span>camino[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">2</span>]
  }
  <span class="cf">else</span>{
    camino[j, <span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">rbeta</span>(<span class="dv">1</span>, z_<span class="dv">2</span> <span class="op">+</span><span class="st"> </span>a_<span class="dv">2</span>, N_<span class="dv">2</span> <span class="op">-</span><span class="st"> </span>z_<span class="dv">2</span> <span class="op">+</span><span class="st"> </span>b_<span class="dv">2</span>)
    camino[j, <span class="dv">1</span>] &lt;-<span class="st"> </span>camino[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">1</span>]
  }
}

caminata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">pasos =</span> <span class="dv">1</span><span class="op">:</span>pasos, <span class="dt">theta_1 =</span> camino[, <span class="dv">1</span>], 
  <span class="dt">theta_2 =</span> camino[, <span class="dv">2</span>])

<span class="kw">ggplot</span>(caminata[<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>, ], <span class="kw">aes</span>(<span class="dt">x =</span> theta_<span class="dv">1</span>, <span class="dt">y =</span> theta_<span class="dv">2</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">0.8</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_path</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="kw">expression</span>(theta[<span class="dv">1</span>]), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="kw">expression</span>(theta[<span class="dv">2</span>]), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">coord_fixed</span>()</code></pre>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r">caminata_g &lt;-<span class="st"> </span><span class="kw">filter</span>(caminata, pasos <span class="op">%%</span><span class="st"> </span><span class="dv">2</span> <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(parametro, val, theta_<span class="dv">1</span>, theta_<span class="dv">2</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pasos =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6000</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(pasos)

<span class="kw">ggplot</span>(caminata_g[<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>, ], <span class="kw">aes</span>(<span class="dt">x =</span> pasos, <span class="dt">y =</span> val)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_path</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>parametro, <span class="dt">ncol =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;&quot;</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</code></pre>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-34-1.png" width="816" /></p>
<p>Si comparamos los resultados del muestreador de Gibbs con los de Metrópolis
notamos que las estimaciones son muy cercanas</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Metropolis</span>
caminata_m <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(pasos <span class="op">&gt;</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># eliminamos el calentamiento</span>
<span class="st">  </span><span class="kw">group_by</span>(parametro) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">media =</span> <span class="kw">mean</span>(val),
    <span class="dt">mediana =</span> <span class="kw">median</span>(val),
    <span class="dt">std =</span> <span class="kw">sd</span>(val)
    )
<span class="co">#&gt; # A tibble: 2 x 4</span>
<span class="co">#&gt;   parametro media mediana   std</span>
<span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1 theta_1   0.614   0.620 0.127</span>
<span class="co">#&gt; 2 theta_2   0.378   0.370 0.134</span>

<span class="co"># Gibbs</span>
caminata_g <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(pasos <span class="op">&gt;</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(parametro) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">media =</span> <span class="kw">mean</span>(val),
    <span class="dt">mediana =</span> <span class="kw">median</span>(val),
    <span class="dt">std =</span> <span class="kw">sd</span>(val)
    )
<span class="co">#&gt; # A tibble: 2 x 4</span>
<span class="co">#&gt;   parametro media mediana   std</span>
<span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt; 1 theta_1   0.614   0.621 0.129</span>
<span class="co">#&gt; 2 theta_2   0.384   0.378 0.129</span></code></pre>
<p>También podemos comparar los sesgos de las dos monedas, esta es una pregunta
más interesante.</p>
<pre class="sourceCode r"><code class="sourceCode r">caminata &lt;-<span class="st"> </span>caminata <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dif =</span> theta_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>theta_<span class="dv">2</span>)

<span class="kw">ggplot</span>(caminata, <span class="kw">aes</span>(<span class="dt">x =</span> dif)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;gray&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)
<span class="co">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></code></pre>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-36-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>La principal ventaja del muestreador de Gibbs sobre el algoritmo de Metrópolis
es que no hay necesidad de seleccionar una distribución propuesta y no hay que
lidiar con lo ineficiente de rechazar valores. A cambio, debemos ser capaces
de derivar las probabilidades condicionales de cada parámetro y de generar
muestras de estas.</p>
<div id="ejemplo-normal" class="section level4 unnumbered">
<h4>Ejemplo: Normal</h4>
<p>Retomemos el caso de observaciones normales, supongamos que tengo una muestra
<span class="math inline">\(x_1,...,x_N\)</span> de observaciones independientes e identicamente distribuidas,
con <span class="math inline">\(x_i \sim N(\mu, \sigma^2)\)</span>, veremos el caso de media desconocida, varianza
desconocida y de ambas desconocidas.</p>
<p><strong>Normal con media desconocida</strong>. Supongamos que <span class="math inline">\(\sigma^2\)</span> es conocida, por lo
que nuestro parámetro de interés es únicamente <span class="math inline">\(\mu\)</span> entonces si describo mi
conocimiento inicial de <span class="math inline">\(\mu\)</span> a través de una distribución normal:
<span class="math display">\[\mu \sim N(m, \tau^2)\]</span>
resulta en una distribución posterior:
<span class="math display">\[\mu|x \sim N\bigg(\frac{\sigma^2}{\sigma^2 + N\tau^2}m + \frac{N\tau^2}{\sigma^2 + N \tau^2}\bar{x}, \frac{\sigma^2 \tau^2}{\sigma^2 + N\tau^2}\bigg)\]</span></p>
<p><strong>Normal con varianza desconocida</strong>. Supongamos que <span class="math inline">\(\mu\)</span> es conocida, por lo
que nuestro parámetro de interés es únicamente <span class="math inline">\(\sigma^2\)</span>. En este caso una
distribución conveniente para describir nuestro conocimiento inicial es
la distribución <em>Gamma Inversa</em>.</p>
<p>La distribución Gamma Inversa es una distribución continua con dos parámetros
y que toma valores en los positivos. Como su nombre lo indica, esta distribución
corresponde al recírpoco de una variable cuya distribución es Gamma, recordemos
que si <span class="math inline">\(x\sim Gamma(\alpha, \beta)\)</span> entonces:</p>
<p><span class="math display">\[p(x)=\frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}e^{-x/\beta}\]</span></p>
<p>donde <span class="math inline">\(x&gt;0\)</span>. Ahora si <span class="math inline">\(y\)</span> es la variable aleatoria recírpoco de <span class="math inline">\(x\)</span> entonces:</p>
<p><span class="math display">\[p(y)=\frac{\beta^\alpha}{\Gamma(\alpha)}y^{-\alpha - 1} exp{-\beta/y}\]</span></p>
<p>con media
<span class="math display">\[\frac{\beta}{\alpha-1}\]</span>
y varianza
<span class="math display">\[\frac{\beta^2}{(\alpha-1)^2(\alpha-2)}.\]</span></p>
<p>Debido a la relación entre las distribuciones Gamma y Gamma Inversa, podemos
utilizar la función rgamma de R para generar valores con distribución gamma
inversa.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1. simulamos valores porvenientes de una distribución gamma</span>
x_gamma &lt;-<span class="st"> </span><span class="kw">rgamma</span>(<span class="dv">2000</span>, <span class="dt">shape =</span> <span class="dv">5</span>, <span class="dt">rate =</span> <span class="dv">1</span>)
<span class="co"># 2. invertimos los valores simulados</span>
x_igamma &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span>x_gamma

<span class="co"># También podemos usar las funciones de MCMCpack</span>
<span class="kw">library</span>(MCMCpack)
x_igamma &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x_igamma)

<span class="kw">ggplot</span>(x_igamma, <span class="kw">aes</span>(<span class="dt">x =</span> x_igamma)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span> ..density..), <span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">fill =</span> <span class="st">&quot;gray&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dinvgamma, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">shape =</span> <span class="dv">5</span>, <span class="dt">scale =</span> <span class="dv">1</span>), 
    <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)  </code></pre>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-37-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>Volviendo al problema de inferir acerca del parámetros <span class="math inline">\(\sigma^2\)</span>, si resumimos
nuestro conocimiento inicial a través de una distribución Gamma Inversa tenemos
<span class="math display">\[p(\sigma^2)=\frac{\beta^\alpha}{\Gamma(\alpha)}\frac{1}{(\sigma^2)^{\alpha + 1}} e^{-\beta/\sigma^2}\]</span></p>
<p>la verosimiltud:
<span class="math display">\[p(x|\mu, \sigma^2)=\frac{1}{(2\pi\sigma^2)^{N/2}}exp\left(-\frac{1}{2\sigma^2}\sum_{j=1}^{N}(x_j-\mu)^2\right)\]</span></p>
<p>y calculamos la posterior:</p>
<p><span class="math display">\[p(\sigma^2) \propto p(x|\mu,\sigma^2)p(\sigma^2)\]</span></p>
<p>obtenemos que <span class="math inline">\(\sigma^2|x \sim GI(N/2+\alpha, \beta + 1/2 \sum(x_i - \mu)^2)\)</span>.</p>
<p>Por tanto tenemos que la inicial Gamma con verosimilitud Normal es una familia
conjugada.</p>
</div>
<div id="ejemplo-normal-con-media-y-varianza-desconocidas" class="section level4 unnumbered">
<h4>Ejemplo: Normal con media y varianza desconocidas</h4>
<p>Sea <span class="math inline">\(\theta=(\mu, \sigma^2)\)</span> especificamos la siguiente inicial para <span class="math inline">\(\theta\)</span>:
<span class="math display">\[p(\theta) = N(\mu|m, \tau^2)\cdot IG(\sigma^2|\alpha, \beta)\]</span>
suponemos hiperparámetros <span class="math inline">\(m,\tau^2, \alpha, \beta\)</span> conocidos. Entonces, la
distribución posterior es:
<span class="math display">\[ p(\theta|x) \propto p(x|\theta) p(\theta)\]</span>
<span class="math display">\[= \frac{1}{(\sigma^2)^{N/2}}
  exp\bigg(-\frac{1}{2\sigma^2}\sum_{i=1}^N (x_i-\mu)^2 \bigg)
  exp\bigg(-\frac{1}{2\tau^2}(\mu-m)^2)\bigg) 
  \frac{1}{(\sigma^2)^{\alpha +1}}
  exp\bigg(-\frac{\beta}{\sigma^2}\bigg)\]</span></p>
<p>en esta última distribución no reconocemos el núcleo de niguna distribución
conocida (existe una distribución <a href="https://en.wikipedia.org/wiki/Normal-inverse-gamma_distribution">normal-gamma inversa</a>)
pero si nos concenteramos únicamente en los términos que involucran
a <span class="math inline">\(\mu\)</span> tenemos:</p>
<p><span class="math display">\[exp\left(-\frac{1}{2}\left( \mu^2 \left( \frac{N}{\sigma^2} + 
\frac{1}{\tau^2} \right) 
- 2\mu\left(\frac{\sum_{i= 1}^n x_i}{\sigma^2} + \frac{m}{\tau^2}\right) \right)\right)\]</span></p>
<p>esta expresión depende de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span>, sin embargo condicional a <span class="math inline">\(\sigma^2\)</span> observamos el núcleo de una distribución normal,</p>
<p><span class="math display">\[\mu|\sigma^2,x \sim N\left(\frac{n\tau^2}{n\tau^2 + \sigma^2}\bar{x} +  \frac{\sigma^2}{N\tau^2 + \sigma^2}m, \frac{\tau^2\sigma^2}{n\tau^2 + \sigma^2} \right)\]</span>
Si nos fijamos únicamente en los tárminos que involucran a <span class="math inline">\(\sigma^2\)</span> tenemos:</p>
<p><span class="math display">\[\frac{1}{(\sigma^2)^{N/2+\alpha+1}}exp\left(- \frac{1}{\sigma^2}
\left(\sum_{i=1}^N \frac{(x_i-\mu)^2}{2} + \beta \right) \right)\]</span></p>
<p>y tenemos</p>
<p><span class="math display">\[\sigma^2|\mu,x \sim GI\left(\frac{N}{2} + \alpha, \sum_{i=1}^n \frac{(x_i-\mu)^2}{2} + \beta \right)\]</span>
Obtenemos así las densidades condicionales completas <span class="math inline">\(p(\mu|\sigma^2, x)\)</span> y
<span class="math inline">\(p(\sigma^2|\mu, x)\)</span> cuyas distribuciones conocemos y de las cuales podemos
simular.</p>
<p>Implementaremos un muestreador de Gibbs.</p>
<p>Comenzamos definiendo las distrbuciones iniciales:</p>
<ul>
<li><p><span class="math inline">\(\mu \sim N(1.5, 16)\)</span>, esto es <span class="math inline">\(m = 1.5\)</span> y <span class="math inline">\(\tau^2 = 16\)</span>.</p></li>
<li><p><span class="math inline">\(\sigma^2 \sim GI(3, 3)\)</span>, esto es <span class="math inline">\(\alpha = \beta = 3\)</span>.</p></li>
</ul>
<p>Ahora supongamos que observamos 20 realizaciones provenientes de la distribución
de interés:</p>
<pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">50</span> <span class="co"># Observamos 20 realizaciones</span>
<span class="kw">set.seed</span>(<span class="dv">122</span>)
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dv">2</span>, <span class="dv">2</span>) 
x
<span class="co">#&gt;  [1]  4.6214  0.2483  2.3990  2.9319 -1.6041  4.8975  2.5977  2.7236</span>
<span class="co">#&gt;  [9] -0.0139  1.4860  1.7357  0.3167  2.5485 -2.9252 -2.3068  4.3184</span>
<span class="co">#&gt; [17]  3.3795  3.7605  0.1133  3.4381  0.9243  0.9547 -0.1058  2.2030</span>
<span class="co">#&gt; [25]  5.7270  1.9608 -0.1566  2.3452  3.0661  5.9045  4.8227  3.2027</span>
<span class="co">#&gt; [33]  0.1720  5.1609  1.0602  5.2037  2.7455  2.0678  2.2082 -2.0367</span>
<span class="co">#&gt; [41]  0.6840 -1.2170 -0.6882  1.6067  4.7513  2.3466  1.1214 -1.1906</span>
<span class="co">#&gt; [49]  0.5114  5.6304</span></code></pre>
<p>Escribimos el muestreador de Gibbs.</p>
<pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="fl">1.5</span>; tau2 &lt;-<span class="st"> </span><span class="dv">16</span>; alpha &lt;-<span class="st"> </span><span class="dv">3</span>; beta &lt;-<span class="st"> </span><span class="dv">3</span> <span class="co"># parámetros de iniciales</span>

pasos &lt;-<span class="st"> </span><span class="dv">20000</span>
camino &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> pasos <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="co"># vector guardará las simulaciones</span>
camino[<span class="dv">1</span>, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">0</span> <span class="co"># valor inicial media</span>

<span class="co"># Generamos la caminata aleatoria</span>
<span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>(pasos <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)){
  <span class="co"># sigma^2</span>
  mu &lt;-<span class="st"> </span>camino[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">1</span>]
  a &lt;-<span class="st"> </span>N <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>alpha
  b &lt;-<span class="st"> </span><span class="kw">sum</span>((x  <span class="op">-</span><span class="st"> </span>mu) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>beta
  camino[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">2</span>] &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw">rgamma</span>(<span class="dv">1</span>, <span class="dt">shape =</span> a, <span class="dt">rate =</span> b) <span class="co"># Actualizar sigma2</span>
  
  <span class="co"># mu</span>
  sigma2 &lt;-<span class="st"> </span>camino[j <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dv">2</span>]
  media &lt;-<span class="st"> </span>(N <span class="op">*</span><span class="st"> </span>tau2 <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(x) <span class="op">+</span><span class="st"> </span>sigma2 <span class="op">*</span><span class="st"> </span>m) <span class="op">/</span><span class="st"> </span>(N <span class="op">*</span><span class="st"> </span>tau2 <span class="op">+</span><span class="st"> </span>sigma2)
  var &lt;-<span class="st"> </span>sigma2 <span class="op">*</span><span class="st"> </span>tau2 <span class="op">/</span><span class="st"> </span>(N <span class="op">*</span><span class="st"> </span>tau2 <span class="op">+</span><span class="st"> </span>sigma2)
  camino[j, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, media, <span class="dt">sd =</span> <span class="kw">sqrt</span>(var)) <span class="co"># actualizar mu</span>
}

caminata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">pasos =</span> <span class="dv">1</span><span class="op">:</span>pasos, <span class="dt">mu =</span> camino[<span class="dv">1</span><span class="op">:</span>pasos, <span class="dv">1</span>], 
  <span class="dt">sigma2 =</span> camino[<span class="dv">1</span><span class="op">:</span>pasos, <span class="dv">2</span>])

caminata_g &lt;-<span class="st"> </span>caminata <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(parametro, val, mu, sigma2) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(pasos)

<span class="kw">ggplot</span>(<span class="kw">filter</span>(caminata_g, pasos <span class="op">&gt;</span><span class="st"> </span><span class="dv">15000</span>), <span class="kw">aes</span>(<span class="dt">x =</span> pasos, <span class="dt">y =</span> val)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_path</span>(<span class="dt">alpha =</span> <span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>parametro, <span class="dt">ncol =</span> <span class="dv">1</span>, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="st">&quot;&quot;</span>)</code></pre>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">filter</span>(caminata_g, pasos <span class="op">&gt;</span><span class="st"> </span><span class="dv">5000</span>), <span class="kw">aes</span>(<span class="dt">x =</span> val)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;gray&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>parametro, <span class="dt">ncol =</span> <span class="dv">1</span>, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) 
<span class="co">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></code></pre>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-40-1.png" width="384" /></p>
<p>Algunos resúmenes de la posterior:</p>
<pre class="sourceCode r"><code class="sourceCode r">caminata_g <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(pasos <span class="op">&gt;</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># eliminamos la etapa de calentamiento</span>
<span class="st">  </span><span class="kw">group_by</span>(parametro) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="kw">mean</span>(val), 
    <span class="kw">sd</span>(val), 
    <span class="kw">median</span>(val)
    )
<span class="co">#&gt; # A tibble: 2 x 4</span>
<span class="co">#&gt;   parametro `mean(val)` `sd(val)` `median(val)`</span>
<span class="co">#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;</span>
<span class="co">#&gt; 1 mu               1.91     0.305          1.91</span>
<span class="co">#&gt; 2 sigma2           4.74     0.933          4.62</span></code></pre>
<p><strong>Predicción</strong>. Para predecir el valor de una realización futura <span class="math inline">\(y\)</span> recordemos
que:</p>
<p><span class="math display">\[p(y) =\int p(y|\theta)p(\theta|x)d\theta\]</span></p>
<p>Por tanto podemos aproximar la distribución predictiva posterior como:</p>
<pre class="sourceCode r"><code class="sourceCode r">caminata_f &lt;-<span class="st"> </span><span class="kw">filter</span>(caminata, pasos <span class="op">&gt;</span><span class="st"> </span><span class="dv">5000</span>)

caminata_f<span class="op">$</span>y_sims &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(caminata_f), caminata_f<span class="op">$</span>mu, caminata_f<span class="op">$</span>sigma2)

<span class="kw">ggplot</span>(caminata_f, <span class="kw">aes</span>(<span class="dt">x =</span> y_sims)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">fill =</span> <span class="st">&quot;gray&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(y_sims)), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)
<span class="co">#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</span></code></pre>
<p><img src="09-analisis_bayesiano_files/figure-html/unnamed-chunk-42-1.png" width="384" /></p>
<p><img src="imagenes/manicule2.jpg" /> ¿Cuál es la probabilidad de que una
observación futura sea mayor a 8?</p>
<p>En estadística bayesiana es común parametrizar la distribución Normal en
términos de precisión (el inverso de la varianza). Si parametrizamos de esta
manera <span class="math inline">\(\nu = 1/\sigma^2\)</span> podemos repetir el proceso anterior con la
diferencia de utilizar la distribución Gamma en lugar de Gamma inversa.</p>
</div>
<div id="conclusiones-y-observaciones-metropolis-y-gibbs" class="section level3 unnumbered">
<h3>Conclusiones y observaciones Metrópolis y Gibbs</h3>
<ul>
<li><p>Una generalización del algoritmo de Metrópolis es Metrópolis-Hastings.</p>
El algoritmo de Metropolis es como sigue:
<ol style="list-style-type: decimal">
<li>Generamos un punto inicial tal que <span class="math inline">\(p(\theta)&gt;0\)</span>.</li>
<li>Para <span class="math inline">\(t = 1,2,...\)</span>
<ul>
<li>Se propone un nuevo valor <span class="math inline">\(\theta_{propuesto}\)</span> con una distribución
propuesta <span class="math inline">\(g(\theta_{propuesta}|\theta_{actual})\)</span> es común que <span class="math inline">\(g(\theta_{propuesta}|\theta_{actual})\)</span> sea una normal centrada en
<span class="math inline">\(\theta_{actual}\)</span>.</li>
</ul></li>
<li>Calculamos
<span class="math display">\[p_{mover}=min\bigg( \frac{p(\theta_{propuesta})}{p(\theta_{actual})},1\bigg)\]</span>
y aceptamos <span class="math display">\[\theta_{propuesta}\]</span> con probabilidad <span class="math inline">\(p_{mover}\)</span>. Es así que el algorito requiere que podamos calcular el cociente en <span class="math inline">\(p_{mover}\)</span>
para todo <span class="math inline">\(\theta_{actual}\)</span> y <span class="math inline">\(\theta_{propuesta}\)</span>, así como simular de la
distribución propuesta <span class="math inline">\(g(\theta_{propuesta}|\theta_{actual})\)</span>, adicionalmente
debemos poder generar valores uniformes para decidir si aceptar/rechazar.
En el caso de <strong>Metropolis</strong> un requerimiento adicional es que la distribución
propuesta <span class="math inline">\(g(\theta_{a}|\theta_b)\)</span> debe ser simétrica, es decir <span class="math inline">\(g(\theta_{a}|\theta_b) = g(\theta_{b}|\theta_a)\)</span> para todo <span class="math inline">\(\theta_{a}\)</span>,
<span class="math inline">\(\theta_{b}\)</span>.</li>
</ol>
<p><strong>Metropolis-Hastings</strong> generaliza Metropolis, eliminando la restricción de
simetría en la distribución propuesta <span class="math inline">\(g(\theta_{a}|\theta_b)\)</span>, sin embargo para corregir por
esta asimetría debemos calcular <span class="math inline">\(p_{mover}\)</span> como sigue:
<span class="math display">\[p_{mover}=min\bigg( \frac{p(\theta_{propuesta})/g(\theta_{propuesta}|\theta_{actual})}{p(\theta_{actual})/g(\theta_{actual}|\theta_{propuesta})},1\bigg)\]</span>
La generalización de Metrópolis-Hastings puede resultar en algoritmos más
veloces.</p></li>
<li><p>Se puede ver Gibbs como una generalización de Metropolis, cuando estamos
actualizando un componente de los parámetros, la distribución propuesta es
la distribución posterior para ese parámetro, por tanto siempre es aceptado.</p></li>
<li><p>En el caso de modelos complicados se utilizan combinaciones de Gibbs y
Metropolis. Cuando se consideran estos dos algoritmos Gibbs es un método más
simple y es la primera opción para modelos condicionalmente conjugados. Sí solo
podemos simular de un subconjunto de las distribuciones condicionales
posteriores, entonces podemos usar Gibbs siempre que se pueda y Metropolis
unidimensional para el resto, o de manera más general separamos en bloques, un
bloque se actualiza con Gibbs y otro con Metrópolis.</p></li>
<li><p>El algoritmo de Gibbs puede <em>atorarse</em> cuando hay correlación alta entre los
parámetros, reparametrizar puede ayudar, o se pueden usar otros algoritmos que
veremos más adelante.</p></li>
</ul>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="metropolis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="jags.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tereom/est-computacional-2018/edit/master/09-analisis_bayesiano.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["est-computacional-2018.pdf", "est-computacional-2018.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
