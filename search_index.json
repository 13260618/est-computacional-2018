[
["index.html", "Estadística Computacional Temario", " Estadística Computacional Teresa Ortiz 2018-07-23 Temario Notas Manipulación y visualización de datos Introducción a R. Visualización de datos. Manipulación y limpieza de datos. Temas selectos de programación en R. Inferencia y remuestreo Repaso de probabilidad. Muestreo y probabilidad. Inferencia. El principio del plug-in. Bootstrap Cálculo de errores estándar e intervalos de confianza. Estructuras de datos complejos. Introducción a modelos probabilísticos. Modelos de probabilidad y simulación Variables aleatorias y modelos probabilísticos. Familias importantes: discretas y continuas. Teoría básica de simulación El generador uniforme de números aleatorios. El método de la transformación inversa. Simulación de variables aleatorias discretas con soporte finito. Otras variables aleatorias. Simulación para modelos gráficos Modelos probabilíticos gráficos. Simulación (e.g. ANOVA, regresión simple). Inferencia paramétrica y remuestreo Modelos paramétricos. Bootsrap paramétrico. Inferencia de gráficas Métodos computacionales e inferencia Bayesiana Inferencia bayesiana. Métodos diretos Familias conjugadas. Aproximación por cuadrícula. Aceptación y rechazo. MCMC Cadenas de Markov. Metropolis-Hastings. Muestreador de Gibbs. Diagnósticos de convergencia. Calificación Tareas 20% (se envían por correo con título: EstComp-TareaXX), exámen parcial (proyecto y exámen en clase) 40%, Examen final 40%. Software https://www.r-project.org https://www.rstudio.com Referencias principales "],
["r-para-analisis-de-datos.html", "Sección 1 R para análisis de datos", " Sección 1 R para análisis de datos Este es el primer de 2 juegos de notas introductorias a R con un enfoque en análisis de datos. A diferencia de otros recursos, no se pretende dar una introducción general a R sino mostrar las herramientas más importantes para comenzar a utilizar R en análisis de datos. En este primer juego se cubre la sección de visualización. Más adelante aprenderemos a usar R para manipulación de datos y modelación. Estas notas siguen material e ideas de Hadley Wickham y en particular el libro R for Data Science. Las notas están ordenadas como sigue: El ambiente y el lenguaje R Introducción a R para análisis de datos: paquetes, vectores y data frames Datos faltantes Lectura de datos y guardar datos Visualización: gráficas con ggplot2 "],
["el-ambiente-y-el-lenguaje-r.html", "1.1 El ambiente y el lenguaje R", " 1.1 El ambiente y el lenguaje R ¿Qué es R? R es un lenguaje de programación y un ambiente de cómputo estadístico R es software libre (no dice qué puedes o no hacer con el software), de código abierto (todo el código de R se puede inspeccionar - y se inspecciona). Cuando instalamos R, instala la base de R. Mucha de la funcionalidad adicional está en paquetes (conjunto de funciones y datos documentados) que la comunidad contribuye. ¿Cómo entender R? Hay una sesión de R corriendo. La consola de R es la interfaz entre R y nosotros. En la sesión hay objetos. Todo en R es un objeto: vectores, tablas, funciones, etc. Operamos aplicando funciones a los objetos y creando nuevos objetos. ¿Por qué R? R funciona en casi todas las plataformas (Mac, Windows, Linux e incluso en Playstation 3). R es un lenguaje de programación completo, permite desarrollo de DSLs. R promueve la investigación reproducible. R está actualizado gracias a que tiene una activa comunidad. Solo en CRAN hay cerca de 10,000 paquetes (funcionalidad adicional de R creadas creada por la comunidad). R se puede combinar con otras herramientas. R tiene capacidades gráficas muy sofisticadas. R es popular (Revolutions blog). Investigación reproducible en R Un estándar mínimo para el análisis de datos es la reproducibilidad: debe ser posible reproducir el análisis en todos sus pasos y en cualquier momento. Para ello los pasos del análisis deben estar documentados apropiadamente, de manera que las decisiones importantes puedan ser entendidas claramente. Estos dos principios generalmente implican que debemos trabajar escribiendo código, más que usando interfaces gráficas de point and click. Esto permite crear programas reproducibles que son fácilmente documentados, y tiene otras consecuencias positivas como la facilidad de comunicación (compartir código), la posibilidad de trabajar con versiones que documenten la historia del desarrollo, respaldos fáciles del trabajo, e incluso el uso de lenguajes de programación más flexibles que integren nuestro trabajo en procesos de producción de reportes o monitoreo. Los scripts de R son oportunos para llevar a cabo análisis reproducibles, pero hay más herramientas que nos ayudan a documentar y compartir nuestro trabajo: Los paquetes rmarkdown y knitr se utilizan para generar documentos en formato pdf, html o word que integran texto, código de R y resultados producidos por el código. Packrat: Sistema para administrar dependencias de paquetes en R. Otras herramientas externas a R, por ejemplo Docker Organizar los análisis para ser reproducibles no es trivial pero es una buena práctica que te agradecerán los que consulten o utilicen tu trabajo (incluído tu yo del futuro), puedes leer más recomendaciones para lograr análisis reproducibles en initial steps toward reproducible research. También es conveniente usar un controlador de versiones este es un buen tutorial para Git y Github con R. 1.1.1 Descargar R y RStudio Para comenzar se debe descargar R, esta descarga incluye R básico y un editor de textos para escribir código. Después de descargar R se recomienda descargar RStudio (gratis y libre). Rstudio es un ambiente de desarrollo integrado para R: incluye una consola, un editor de texto y un conjunto de herramientas para administrar el espacio de trabajo cuando se utiliza R. Algunos shortcuts útiles: En el editor command/ctrl + enter: enviar código a la consola ctrl + 2: mover el cursor a la consola En la consola flecha hacia arriba: recuperar comandos pasados ctrl + flecha hacia arriba: búsqueda en los comandos ctrl + 1: mover el cursor al editor 1.1.2 Paquetes y el Tidyverse La mejor manera de usar R para análisis de datos es aprovechando la gran cantidad de paquetes que aportan funcionalidad adicional. Desde Rstudio podemos instalar paquetes (Tools - &gt; Install packages o usar la función install.packages(&quot;nombre_paquete&quot;)). Una vez instalados, podemos cargarlos a nuestra sesión de R mediante library. Por ejemplo, para cargar el paquete readr hacemos: # print(read_csv) # Error in print(read_csv) : object &#39;read_csv&#39; not found library(tidyverse) print(read_csv) ## function (file, col_names = TRUE, col_types = NULL, locale = default_locale(), ## na = c(&quot;&quot;, &quot;NA&quot;), quoted_na = TRUE, quote = &quot;\\&quot;&quot;, comment = &quot;&quot;, ## trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000, ## n_max), progress = show_progress()) ## { ## tokenizer &lt;- tokenizer_csv(na = na, quoted_na = TRUE, quote = quote, ## comment = comment, trim_ws = trim_ws) ## read_delimited(file, tokenizer, col_names = col_names, col_types = col_types, ## locale = locale, skip = skip, comment = comment, n_max = n_max, ## guess_max = guess_max, progress = progress) ## } ## &lt;bytecode: 0x52c41a0&gt; ## &lt;environment: namespace:readr&gt; read_csv es una función que aporta el paquete readr, que a su vez está incluido en el tidyverse. Los paquetes se instalan una sola vez, sin embargo, se deben cargar (ejecutar library(tidyverse)) en cada sesión de R que los ocupemos. En estas notas utilizaremos la colección de paquetes incluídos en el tidyverse. Estos paquetes de R están diseñados para ciencia de datos, y para funcionar juntos como parte de un flujo de trabajo. La siguiente imagen tomada de Why the tidyverse (Joseph Rickert) indica que paquetes del tidyverse se utilizan para cada etapa del análisis de datos. knitr::include_graphics(&quot;imagenes/tidyverse.png&quot;) 1.1.3 Software estadístico Estructuras de datos y operaciones vectorizadas Valores faltantes Ambiente interactivo 1.1.3.1 Estructuras de datos En R se puede trabajar con distintas estructuras de datos, algunas son de una sola dimensión y otras permiten más, como indica el diagrama de abajo: nosotros trabajaremos principalmente con vectores y data frames. 1.1.3.2 Vectores y data frames Comenzamos viendo algunas operaciones básicas con vectores. a &lt;- c(5, 2, 4.1, 7, 9.2) a ## [1] 5.0 2.0 4.1 7.0 9.2 a[1] ## [1] 5 a[2] ## [1] 2 a[2:4] ## [1] 2.0 4.1 7.0 Las operaciones básicas con vectores son componente a componente: b &lt;- a + 10 b ## [1] 15.0 12.0 14.1 17.0 19.2 d &lt;- sqrt(a) d ## [1] 2.236068 1.414214 2.024846 2.645751 3.033150 a + d ## [1] 7.236068 3.414214 6.124846 9.645751 12.233150 10 * a ## [1] 50 20 41 70 92 a * d ## [1] 11.180340 2.828427 8.301867 18.520259 27.904982 Y podemos crear secuencias como sigue: ejemplo_1 &lt;- 1:10 ejemplo_1 ## [1] 1 2 3 4 5 6 7 8 9 10 ejemplo_2 &lt;- seq(0, 1, 0.25) ejemplo_2 ## [1] 0.00 0.25 0.50 0.75 1.00 Para calcular características de vectores usamos funciones: # media del vector mean(a) ## [1] 5.46 # suma de sus componentes sum(a) ## [1] 27.3 # longitud del vector length(a) ## [1] 5 También podemos construir vectores de caracteres: frutas &lt;- c(&#39;manzana&#39;, &#39;manzana&#39;, &#39;pera&#39;, &#39;plátano&#39;, &#39;fresa&#39;) frutas ## [1] &quot;manzana&quot; &quot;manzana&quot; &quot;pera&quot; &quot;plátano&quot; &quot;fresa&quot; Podemos juntar vectores del mismo tamaño en tablas, que se llaman data.frame. Por ejemplo: tabla &lt;- data_frame(n = 1:5, valor = a, fruta = frutas) # la función data_frame de tibble es más conveniente que data.frame de R base. tabla ## # A tibble: 5 x 3 ## n valor fruta ## &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 5 manzana ## 2 2 2 manzana ## 3 3 4.1 pera ## 4 4 7 plátano ## 5 5 9.2 fresa Los data frames son estructuras rectangulares donde cada columna es del mismo tipo (e.g. categórica o factor, numérica, caracter) pero columnas distintas pueden tener diferentes tipos. library(ggplot2) head(diamonds) ## # A tibble: 6 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 La instrucción str nos describe el tipo de variables en el data.frame: str(diamonds) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 53940 obs. of 10 variables: ## $ carat : num 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ... ## $ cut : Ord.factor w/ 5 levels &quot;Fair&quot;&lt;&quot;Good&quot;&lt;..: 5 4 2 4 2 3 3 3 1 3 ... ## $ color : Ord.factor w/ 7 levels &quot;D&quot;&lt;&quot;E&quot;&lt;&quot;F&quot;&lt;&quot;G&quot;&lt;..: 2 2 2 6 7 7 6 5 2 5 ... ## $ clarity: Ord.factor w/ 8 levels &quot;I1&quot;&lt;&quot;SI2&quot;&lt;&quot;SI1&quot;&lt;..: 2 3 5 4 2 6 7 3 4 5 ... ## $ depth : num 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ... ## $ table : num 55 61 65 58 58 57 57 55 61 61 ... ## $ price : int 326 326 327 334 335 336 336 337 337 338 ... ## $ x : num 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ... ## $ y : num 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ... ## $ z : num 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ... Para lograr una programación eficiente en R es importante conocer las técnicas de indexar data frames: # extraemos los primeros cinco renglones diamonds[1:5, ] ## # A tibble: 5 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 # extraemos los primeros cinco renglones y las columnas 2,4,6 diamonds[1:5, c(2, 4, 6)] ## # A tibble: 5 x 3 ## cut clarity table ## &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; ## 1 Ideal SI2 55 ## 2 Premium SI1 61 ## 3 Good VS1 65 ## 4 Premium VS2 58 ## 5 Good SI2 58 # también podemos extraer columnase usando $: extraemos la columna x head(diamonds$x) ## [1] 3.95 3.89 4.05 4.20 4.34 3.94 # ¿Que extraemos con las siguientes 2 instrucciones? diamonds[diamonds$x == diamonds$y, ] ## # A tibble: 17 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.3 Ideal H VVS2 62.5 54 567 4.3 4.3 2.7 ## 2 0.27 Very Good F VVS1 62 55 591 4.16 4.16 2.59 ## 3 1 Very Good H VS2 63.3 53 5139 0 0 0 ## 4 1.14 Fair G VS1 57.5 67 6381 0 0 0 ## 5 1 Premium E VS2 60 60 6600 6.43 6.43 3.89 ## 6 1 Premium E VS2 60 60 6720 6.43 6.43 3.89 ## 7 1.22 Premium G SI2 62.4 61 6969 6.79 6.79 4.23 ## 8 1.56 Ideal G VS2 62.2 54 12800 0 0 0 ## 9 1.2 Premium D VVS1 62.1 59 15686 0 0 0 ## 10 2.25 Premium H SI2 62.8 59 18034 0 0 0 ## 11 0.32 Ideal D VVS2 62.1 54 858 4.4 4.4 2.74 ## 12 0.42 Ideal H VVS1 62.8 57 1108 4.79 4.79 3.01 ## 13 0.61 Premium G SI1 60.8 60 1255 5.42 5.42 3.31 ## 14 0.48 Ideal F VS2 62.4 54 1279 5.03 5.03 3.15 ## 15 0.51 Premium F SI1 61.4 59 1421 5.13 5.13 3.16 ## 16 0.71 Good F SI2 64.1 60 2130 0 0 0 ## 17 0.71 Good F SI2 64.1 60 2130 0 0 0 diamonds[-(1:53929), c(&quot;carat&quot;, &quot;price&quot;)] ## # A tibble: 11 x 2 ## carat price ## &lt;dbl&gt; &lt;int&gt; ## 1 0.71 2756 ## 2 0.71 2756 ## 3 0.71 2756 ## 4 0.7 2757 ## 5 0.7 2757 ## 6 0.72 2757 ## 7 0.72 2757 ## 8 0.72 2757 ## 9 0.7 2757 ## 10 0.86 2757 ## 11 0.75 2757 como vemos arriba para indexar los data frames tenemos que indicar filas y columnas, en el lado izquierdo de los corchetes se indica (con un vector) que filas queremos extraer, y en el lado derecho se indican las columnas: diamonds[filas, columnas]. También vale la pena notar que diamonds$x regresa la columna x como vector, es decir, diamonds$x es de una sola dimensión. 1.1.4 Datos faltantes En R los datos faltantes se expresan como NA, ¿qué regresan las siguientes expresiones? 5 + NA NA / 2 sum(c(5, 4, NA)) mean(c(5, 4, NA)) NA &lt; 3 NA == 3 NA == NA Las expresiones anteriores regresan NA, el hecho que la media de un vector que incluye NAs o su suma regrese NAs se debe a que el default en R es propagar los valores faltantes, esto es, si deconozco el valor de una de las componentes de un vector, también desconozco la suma del mismo; sin embargo, muchas funciones tienen un argumento na.rm para removerlos, sum(c(5, 4, NA), na.rm = TRUE) ## [1] 9 mean(c(5, 4, NA), na.rm = TRUE) ## [1] 4.5 El manejo de datos faltantes en R utiliza una lógica ternaria (como SQL): NA == NA ## [1] NA La expresión anterior puede resultar confusa, una manera de pensar en esto es considerar los NA como no sé, por ejemplo si no se la edad de Juan y no se la edad de Esteban, la pregunta a ¿Juan tiene la misma edad que Esteban? es no sé (NA). edad_Juan &lt;- NA edad_Esteban &lt;- NA edad_Juan == edad_Esteban ## [1] NA edad_Jose &lt;- 32 # Juan es menor que José? edad_Juan &lt; edad_Jose ## [1] NA 1.1.4.1 Ambiente interactivo Documentación y ayuda ?mean o help() Las heurísticas minimizan las salidas cuando prefieres no verlas a &lt;- 10 a ## [1] 10 (a &lt;- 15) ## [1] 15 Herramientas sencillas y flexibles para graficación qplot(carat, price, data = diamonds, colour = clarity) 1.1.5 Lenguaje de programación 1.1.5.1 Funciones y reglas de búsqueda lexica (lexical scoping rules) Las funciones son una base importante de la programación en R. Veamos un ejemplo: wtd_mean &lt;- function(x, wt = rep(1, length(x))) { sum(x * wt) / sum(wt) } wtd_mean(1:10) ## [1] 5.5 wtd_mean(1:10, 10:1) ## [1] 4 Las funciones de R tienen tres partes: El cuerpo, el código dentro de la función body(wtd_mean) ## { ## sum(x * wt)/sum(wt) ## } Los formales, la lista de argumentos que controlan como puedes llamar a la función formals(wtd_mean) ## $x ## ## ## $wt ## rep(1, length(x)) El ambiente, el mapeo de la ubicación de las variables de la función environment(wtd_mean) ## &lt;environment: R_GlobalEnv&gt; environment(qplot) ## &lt;environment: namespace:ggplot2&gt; Veamos mas ejemplos, ¿qué regresan las siguientes funciones? # 1 x &lt;- 5 f &lt;- function(){ y &lt;- 10 c(x = x, y = y) } rm(x, f) # 2 x &lt;- 5 g &lt;- function(){ x &lt;- 20 y &lt;- 10 c(x = x, y = y) } # 3 x &lt;- 5 h &lt;- function(){ y &lt;- 10 i &lt;- function(){ z &lt;- 20 c(x = x, y = y, z = z) } i() } # 4 ¿qué ocurre si la corremos por segunda vez? j &lt;- function(){ if (!exists(&quot;a&quot;)){ a &lt;- 5 } else{ a &lt;- a + 1 } print(a) } x &lt;- 0 y &lt;- 10 # 5 ¿qué regresa k()? ¿y k()()? k &lt;- function(){ x &lt;- 1 function(){ y &lt;- 2 x + y } } Las reglas de búsqueda determinan como se busca el valor de una variable libre en una función. A nivel lenguaje R usa lexical scoping, una alternativa es dynamic scoping. En R (lexical scoping) los valores de los símbolos se basan en como se anidan las funciones cuando fueron creadas y no en como son llamadas. Esto es, en R no importa como son las llamadas a una función para saber como se va a buscar el valor de una variable. Una consecuencia de las reglas de búsqueda es que todos los objetos deben ser guardados en memoria. 1.1.6 Recursos Buscar ayuda: Google, StackOverflow. Para aprender más sobre un paquete o una función pueden visitar Rdocumentation.org. La referencia principal de estas notas es el libro R for Data Science de Hadley Wickham. Para aprender los comandos básicos de R Try R y Datacamp cuentan con excelentes cursos interactivos. Para aprender programación avanzada en R, el libro gratuito Advanced R de Hadley Wickham es una buena referencia. En particular es conveniente leer la guía de estilo (para todos: principiantes, intermedios y avanzados). Para mantenerse al tanto de las noticias de la comunidad de R pueden visitar R-bloggers. Más del tidyverse: Why the tidyverse "],
["visualizacion.html", "1.2 Visualización", " 1.2 Visualización Utilizaremos el paquete ggplot2 y cubriremos los siguientes puntos: Gráfica de dispersión Páneles Distintos tipos de gráficas 1.2.0.1 Gráficas de dispersión # install.packages(&quot;ggplot2&quot;) # sólo se hace una vez library(tidyverse) # Cargamos el paquete en nuestra sesión Usaremos el conjunto de datos mpg que se incluye en R, puedes encontrar información de esta base de datos tecleando ?mpg. # ?mpg glimpse(mpg) ## Observations: 234 ## Variables: 11 ## $ manufacturer &lt;chr&gt; &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;audi&quot;, &quot;... ## $ model &lt;chr&gt; &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4&quot;, &quot;a4 qua... ## $ displ &lt;dbl&gt; 1.8, 1.8, 2.0, 2.0, 2.8, 2.8, 3.1, 1.8, 1.8, 2.0,... ## $ year &lt;int&gt; 1999, 1999, 2008, 2008, 1999, 1999, 2008, 1999, 1... ## $ cyl &lt;int&gt; 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6... ## $ trans &lt;chr&gt; &quot;auto(l5)&quot;, &quot;manual(m5)&quot;, &quot;manual(m6)&quot;, &quot;auto(av)... ## $ drv &lt;chr&gt; &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;4&quot;, &quot;4&quot;, &quot;4&quot;,... ## $ cty &lt;int&gt; 18, 21, 20, 21, 16, 18, 18, 18, 16, 20, 19, 15, 1... ## $ hwy &lt;int&gt; 29, 29, 31, 30, 26, 26, 27, 26, 25, 28, 27, 25, 2... ## $ fl &lt;chr&gt; &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;, &quot;p&quot;,... ## $ class &lt;chr&gt; &quot;compact&quot;, &quot;compact&quot;, &quot;compact&quot;, &quot;compact&quot;, &quot;comp... Y comencemos con nuestra primera gráfica: ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) En ggplot2 se inicia una gráfica con la instrucción ggplot(), debemos especificar explicitamente que base de datos usamos, este es el primer argumento en la función ggplot. Una vez que creamos la base añadimos capas, y dentro de aes() escribimos las variables que queremos graficar y el atributo de la gráfica al que queremos mapearlas. La función geom_point() añade una capa de puntos, hay muchas funciones geometrías incluídas en ggplot2: geom_line(), geom_boxplot(), geom_histogram,… Cada una acepta distintos argumentos para mapear las variables en los datos a características estéticas de la gráfica. En el ejemplo de arriba mapeamos displ al eje x, hwy al eje y, pero geom_point() nos permite representar más variables usando la forma, color y/o tamaño del punto. Esta flexibilidad nos permite entender o descubrir patrones más interesantes en los datos. ggplot(mpg) + geom_point(aes(x = displ, y = hwy, color = class)) Experimenta con los aesthetics color (color), tamaño (size) y forma (shape).             ¿Qué diferencia hay entre las variables categóricas y las continuas?             ¿Qué ocurre cuando combinas varios aesthetics? El mapeo de las propiedades estéticas se denomina escalamiento y depende del tipo de variable, las variables discretas (por ejemplo, genero, escolaridad, país) se mapean a distintas escalas que las variables continuas (variables numéricas como edad, estatura, etc.), los defaults para algunos atributos son (estos se pueden modificar):   Discreta Continua Color (color) |Arcoiris de colores |Gradiente de colores Tamaño (size) |Escala discreta de tamaños |Mapeo lineal entre el área y el valor Forma (shape) |Distintas formas |No aplica Transparencia (alpha`) No aplica Mapeo lineal a la transparencia Los geoms controlan el tipo de gráfica p &lt;- ggplot(mpg, aes(x = displ, y = hwy)) p + geom_line() # en este caso no es una buena gráfica ¿Qué problema tiene la siguiente gráfica? p &lt;- ggplot(mpg, aes(x = cty, y = hwy)) p + geom_point() p + geom_jitter() ¿Cómo podemos mejorar la siguiente gráfica? ggplot(mpg, aes(x = class, y = hwy)) + geom_point() Intentemos reodenar los niveles de la variable clase ggplot(mpg, aes(x = reorder(class, hwy), y = hwy)) + geom_point() Podemos probar otros geoms. ggplot(mpg, aes(x = reorder(class, hwy), y = hwy)) + geom_jitter() ggplot(mpg, aes(x = reorder(class, hwy), y = hwy)) + geom_boxplot() También podemos usar más de un geom! ggplot(mpg, aes(x = reorder(class, hwy), y = hwy)) + geom_jitter() + geom_boxplot() Lee la ayuda de reorder y repite las gráficas anteriores ordenando por la mediana de hwy.             ¿Cómo harías para graficar los puntos encima de las cajas de boxplot? 1.2.0.2 Paneles Veamos ahora como hacer páneles de gráficas, la idea es hacer varios múltiplos de una gráfica donde cada múltiplo representa un subconjunto de los datos, es una práctica muy útil para explorar relaciones condicionales. En ggplot podemos usar facet_wrap() para hacer paneles dividiendo los datos de acuerdo a las categorías de una sola variable ggplot(mpg, aes(x = displ, y = hwy)) + geom_jitter() + facet_wrap(~ cyl) También podemos hacer una cuadrícula de 2 dimensiones usando facet_grid(filas~columnas) ggplot(mpg, aes(x = displ, y = hwy)) + geom_jitter() + facet_grid(.~ class) ggplot(mpg, aes(x = displ, y = hwy)) + geom_jitter() + facet_grid(drv ~ class) Los páneles pueden ser muy útiles para entender relaciones en nuestros datos. En la siguiente gráfica es difícil entender si existe una relación entre radiación solar y ozono data(airquality) ggplot(airquality, aes(x = Solar.R, y = Ozone)) + geom_point() ## Warning: Removed 42 rows containing missing values (geom_point). Veamos que ocurre si realizamos páneles separando por velocidad del viento library(Hmisc) airquality$Wind.cat &lt;- cut2(airquality$Wind, g = 3) ggplot(airquality, aes(x = Solar.R, y = Ozone)) + geom_point() + facet_wrap(~ Wind.cat) Podemos agregar un suavizador (loess) para ver mejor la relación de las variables en cada panel. ggplot(airquality, aes(x = Solar.R, y = Ozone)) + geom_point() + facet_wrap(~ Wind.cat) + geom_smooth(span = 3) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Escribe algunas preguntas que puedan contestar con estos datos. En ocasiones es necesario realizar transformaciones u obtener subconjuntos de los datos para poder responder preguntas de nuestro interés. library(babynames) glimpse(babynames) ## Observations: 1,858,689 ## Variables: 5 ## $ year &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 188... ## $ sex &lt;chr&gt; &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F&quot;, &quot;F... ## $ name &lt;chr&gt; &quot;Mary&quot;, &quot;Anna&quot;, &quot;Emma&quot;, &quot;Elizabeth&quot;, &quot;Minnie&quot;, &quot;Margaret&quot;... ## $ n &lt;int&gt; 7065, 2604, 2003, 1939, 1746, 1578, 1472, 1414, 1320, 128... ## $ prop &lt;dbl&gt; 0.072384329, 0.026679234, 0.020521700, 0.019865989, 0.017... Supongamos que queremos ver la tendencia del nombre “John”, para ello debemos generar un subconjunto de la base de datos. babynames_John &lt;- babynames[babynames$name == &quot;John&quot;, ] ggplot(babynames_John, aes(x = year, y = prop)) + geom_point() ggplot(babynames_John, aes(x = year, y = prop, color = sex)) + geom_line() La preparación de los datos es un aspecto muy importante del análisis y suele ser la fase que lleva más tiempo. Es por ello que el siguiente tema se enfocará en herramientas para hacer transformaciones de manera eficiente. Tarea. Explora la base de datos gapminder, estos datos están incluidos en el paquete del mismo nombre, para acceder a ellos basta con cargar el paquete: # install.packages(&quot;gapminder&quot;) library(gapminder) gapminder ## # A tibble: 1,704 x 6 ## country continent year lifeExp pop gdpPercap ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan Asia 1952 28.8 8425333 779. ## 2 Afghanistan Asia 1957 30.3 9240934 821. ## 3 Afghanistan Asia 1962 32.0 10267083 853. ## 4 Afghanistan Asia 1967 34.0 11537966 836. ## 5 Afghanistan Asia 1972 36.1 13079460 740. ## 6 Afghanistan Asia 1977 38.4 14880372 786. ## 7 Afghanistan Asia 1982 39.9 12881816 978. ## 8 Afghanistan Asia 1987 40.8 13867957 852. ## 9 Afghanistan Asia 1992 41.7 16317921 649. ## 10 Afghanistan Asia 1997 41.8 22227415 635. ## # ... with 1,694 more rows             realiza al menos 3 gráficas y explica las relaciones que encuentres. Debes usar lo que revisamos en estas notas: al menos una de las gráficas debe ser de páneles, realiza una gráfica con datos de México, y (opcional)si lo consideras interesante, puedes crear una variable categórica utilizando la función cut2 del paquete Hmisc. 1.2.1 Recursos Google, stackoverflow. Para aprender más de ggplot pueden ver la documentación con ejemplos en la página de ggplot2. Otro recurso muy útil es el acordeón de ggplot. "],
["manipulacion-y-agrupacion-de-datos.html", "Sección 2 Manipulación y agrupación de datos", " Sección 2 Manipulación y agrupación de datos En estas notas continuamos con la introducción a R para análisis de datos, en particular mostraremos herramientas de manipulación de datos. Trataremos los siguientes puntos: Reestructura de datos y el principio de los datos limpios. Estrategia divide-aplica-combina. Es sabido que limpieza y preparación de datos ocupan gran parte del tiempo del análisis de datos: (Dasu y Johnson, 2003 y NYT’s ‘Janitor Work’ Is Key Hurdle to Insights, es por ello que vale la pena dedicar un tiempo a aprender técnicas que faciliten estas tareas, y entender que estructura en los datos es más conveniente para trabajar. "],
["datos-limpios.html", "2.1 Datos limpios", " 2.1 Datos limpios Una vez que importamos datos a R es conveniente limpiarlos, esto implica almacenarlos de una manera consisistente que nos permita enfocarnos en responder preguntas de los datos en lugar de estar luchando con los datos. Entonces, datos limpios son datos que facilitan las tareas del análisis de datos: Manipulación: Manipulación de variables como agregar, filtrar, reordenar, transformar. Visualización: Resúmenes de datos usando gráficas, análisis exploratorio, o presentación de resultados. Modelación: Ajustar modelos es sencillo si los datos están en la forma correcta. Los principios de datos limpios (Tidy Data de Hadley Wickham) proveen una manera estándar de organizar la información: Cada variable forma una columna. Cada observación forma un renglón. Cada tipo de unidad observacional forma una tabla. Vale la pena notar que los principios de los datos limpios se pueden ver como teoría de algebra relacional para estadísticos, estos principios equivalen a la tercera forma normal de Codd con enfoque en una sola tabla de datos en lugar de muchas conectadas en bases de datos relacionales. Veamos un ejemplo: La mayor parte de las bases de datos en estadística tienen forma rectangular, ¿cuántas variables tiene la siguiente tabla? tratamientoA tratamientoB Juan Aguirre - 2 Ana Bernal 16 11 José López 3 1 La tabla anterior también se puede estructurar de la siguiente manera: Juan Aguirre Ana Bernal José López tratamientoA - 16 3 tratamientoB 2 11 1 Si vemos los principios (cada variable forma una columna, cada observación forma un renglón, cada tipo de unidad observacional forma una tabla), ¿las tablas anteriores cumplen los principios? Para responder la pregunta identifiquemos primero cuáles son las variables y cuáles las observaciones de esta pequeña base. Las variables son: persona/nombre, tratamiento y resultado. Entonces, siguiendo los principios de datos limpios obtenemos la siguiente estructura: nombre tratamiento resultado Juan Aguirre a - Ana Bernal a 16 José López a 3 Juan Aguirre b 2 Ana Bernal b 11 José López b 1 "],
["limpieza-bases-de-datos.html", "2.2 Limpieza bases de datos", " 2.2 Limpieza bases de datos Los principios de los datos limpios parecen obvios pero la mayor parte de los datos no los cumplen debido a: La mayor parte de la gente no está familiarizada con los principios y es difícil derivarlos por uno mismo. Los datos suelen estar organizados para facilitar otros aspectos que no son análisis, por ejemplo, la captura. Algunos de los problemas más comunes en las bases de datos que no están limpias son: Los encabezados de las columnas son valores y no nombres de variables. Más de una variable por columna. Las variables están organizadas tanto en filas como en columnas. Más de un tipo de observación en una tabla. Una misma unidad observacional está almacenada en múltiples tablas. La mayor parte de estos problemas se pueden arreglar con pocas herramientas, a continuación veremos como limpiar datos usando 2 funciones del paquete tidyr: gather: recibe múltiples columnas y las junta en pares de valores y nombres, convierte los datos anchos en largos. spread: recibe 2 columnas y las separa, haciendo los datos más anchos. Repasaremos los problemas más comunes que se encuentran en conjuntos de datos sucios y mostraremos como se puede manipular la tabla de datos (usando las funciones gather y spread) con el fin de estructurarla para que cumpla los principios de datos limpios. 2.2.1 Los encabezados de las columnas son valores Usaremos ejemplos para entender los conceptos más facilmente. La primer base de datos está basada en una encuesta de Pew Research que investiga la relación entre ingreso y afiliación religiosa. ¿Cuáles son las variables en estos datos? pew &lt;- read_delim(&quot;http://stat405.had.co.nz/data/pew.txt&quot;, &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) pew ## # A tibble: 18 x 11 ## religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Agnostic 27 34 60 81 76 137 ## 2 Atheist 12 27 37 52 35 70 ## 3 Buddhist 27 21 30 34 33 58 ## 4 Catholic 418 617 732 670 638 1116 ## 5 Don’t k… 15 14 15 11 10 35 ## 6 Evangel… 575 869 1064 982 881 1486 ## 7 Hindu 1 9 7 9 11 34 ## 8 Histori… 228 244 236 238 197 223 ## 9 Jehovah… 20 27 24 24 21 30 ## 10 Jewish 19 19 25 25 30 95 ## 11 Mainlin… 289 495 619 655 651 1107 ## 12 Mormon 29 40 48 51 56 112 ## 13 Muslim 6 7 9 10 9 23 ## 14 Orthodox 13 17 23 32 32 47 ## 15 Other C… 9 7 11 13 13 14 ## 16 Other F… 20 33 40 46 49 63 ## 17 Other W… 5 2 3 4 2 7 ## 18 Unaffil… 217 299 374 365 341 528 ## # ... with 4 more variables: `$75-100k` &lt;int&gt;, `$100-150k` &lt;int&gt;, ## # `&gt;150k` &lt;int&gt;, `Don&#39;t know/refused` &lt;int&gt; Esta base de datos tiene 3 variables: religión, ingreso y frecuencia. Para limpiarla es necesario apilar las columnas (alargar los datos). Notemos que al alargar los datos desapareceran las columnas que se agrupan y dan lugar a dos nuveas columnas: la correspondiente a clave y la correspondiente a valor. Entonces, para alargar una base de datos usamos la función gather que recibe los argumentos: data: base de datos que vamos a reestructurar. key: nombre de la nueva variable que contiene lo que fueron los nombres de columnas que apilamos. value: nombre de la variable que almacenará los valores que corresponden a cada key. …: lo último que especificamos son las columnas que vamos a apilar, la notación para seleccionarlas es la misma que usamos con select(). pew_tidy &lt;- gather(data = pew, income, frequency, -religion) pew_tidy ## # A tibble: 180 x 3 ## religion income frequency ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Agnostic &lt;$10k 27 ## 2 Atheist &lt;$10k 12 ## 3 Buddhist &lt;$10k 27 ## 4 Catholic &lt;$10k 418 ## 5 Don’t know/refused &lt;$10k 15 ## 6 Evangelical Prot &lt;$10k 575 ## 7 Hindu &lt;$10k 1 ## 8 Historically Black Prot &lt;$10k 228 ## 9 Jehovah&#39;s Witness &lt;$10k 20 ## 10 Jewish &lt;$10k 19 ## # ... with 170 more rows Observemos que en la tabla ancha teníamos bajo la columna &lt;$10k, en el renglón correspondiente a Agnostic un valor de 27, y podemos ver que este valor en la tabla larga se almacena bajo la columna frecuencia y corresponde a religión Agnostic, income &lt;$10k. También es importante ver que en este ejemplo especificamos las columnas a apilar identificando la que no vamos a alargar con un signo negativo: es decir apila todas las columnas menos religión. La nueva estructura de la base de datos nos permite, por ejemplo, hacer fácilmente una gráfica donde podemos comparar las diferencias en las frecuencias. Nota: En esta sección no explicaremos las funciones de graficación pues estas se cubren en las notas introductorias a R. En esta parte nos queremos concentrar en como limpiar datos y ejemplificar lo sencillo que es trabajar con datos limpios, esto es, una vez que los datos fueron reestructurados es fácil construir gráficas y resúmenes. ggplot(pew_tidy, aes(x = income, y = frequency, color = religion, group = religion)) + geom_line() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) Podemos hacer gráficas más interesantes si creamos nuevas variables: by_religion &lt;- group_by(pew_tidy, religion) pew_tidy_2 &lt;- pew_tidy %&gt;% filter(income != &quot;Don&#39;t know/refused&quot;) %&gt;% group_by(religion) %&gt;% mutate(percent = frequency / sum(frequency)) %&gt;% filter(sum(frequency) &gt; 1000) head(pew_tidy_2) ## # A tibble: 6 x 4 ## # Groups: religion [5] ## religion income frequency percent ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Catholic &lt;$10k 418 0.0637 ## 2 Evangelical Prot &lt;$10k 575 0.0724 ## 3 Historically Black Prot &lt;$10k 228 0.138 ## 4 Mainline Prot &lt;$10k 289 0.0471 ## 5 Unaffiliated &lt;$10k 217 0.0698 ## 6 Catholic $10-20k 617 0.0940 ggplot(pew_tidy_2, aes(x = income, y = percent, group = religion)) + facet_wrap(~ religion, nrow = 1) + geom_bar(stat = &quot;identity&quot;, fill = &quot;darkgray&quot;) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) En el código de arriba utilizamos las funciones group_by, filter y mutate que estudiaremos más adelante. Por ahora concentremonos en gather y spread. Otro ejemplo, veamos los datos de Billboard, aquí se registra la fecha en la que una canción entra por primera vez al top 100 de Billboard. billboard &lt;- read_csv(&quot;data/billboard.csv&quot;) billboard ## # A tibble: 317 x 81 ## year artist track time date.entered wk1 wk2 wk3 wk4 wk5 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;tim&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2000 2 Pac Baby… 04:22 2000-02-26 87 82 72 77 87 ## 2 2000 2Ge+h… The … 03:15 2000-09-02 91 87 92 NA NA ## 3 2000 3 Doo… Kryp… 03:53 2000-04-08 81 70 68 67 66 ## 4 2000 3 Doo… Loser 04:24 2000-10-21 76 76 72 69 67 ## 5 2000 504 B… Wobb… 03:35 2000-04-15 57 34 25 17 17 ## 6 2000 98^0 Give… 03:24 2000-08-19 51 39 34 26 26 ## 7 2000 A*Tee… Danc… 03:44 2000-07-08 97 97 96 95 100 ## 8 2000 Aaliy… I Do… 04:15 2000-01-29 84 62 51 41 38 ## 9 2000 Aaliy… Try … 04:03 2000-03-18 59 53 38 28 21 ## 10 2000 Adams… Open… 05:30 2000-08-26 76 76 74 69 68 ## # ... with 307 more rows, and 71 more variables: wk6 &lt;int&gt;, wk7 &lt;int&gt;, ## # wk8 &lt;int&gt;, wk9 &lt;int&gt;, wk10 &lt;int&gt;, wk11 &lt;int&gt;, wk12 &lt;int&gt;, wk13 &lt;int&gt;, ## # wk14 &lt;int&gt;, wk15 &lt;int&gt;, wk16 &lt;int&gt;, wk17 &lt;int&gt;, wk18 &lt;int&gt;, ## # wk19 &lt;int&gt;, wk20 &lt;int&gt;, wk21 &lt;int&gt;, wk22 &lt;int&gt;, wk23 &lt;int&gt;, ## # wk24 &lt;int&gt;, wk25 &lt;int&gt;, wk26 &lt;int&gt;, wk27 &lt;int&gt;, wk28 &lt;int&gt;, ## # wk29 &lt;int&gt;, wk30 &lt;int&gt;, wk31 &lt;int&gt;, wk32 &lt;int&gt;, wk33 &lt;int&gt;, ## # wk34 &lt;int&gt;, wk35 &lt;int&gt;, wk36 &lt;int&gt;, wk37 &lt;int&gt;, wk38 &lt;int&gt;, ## # wk39 &lt;int&gt;, wk40 &lt;int&gt;, wk41 &lt;int&gt;, wk42 &lt;int&gt;, wk43 &lt;int&gt;, ## # wk44 &lt;int&gt;, wk45 &lt;int&gt;, wk46 &lt;int&gt;, wk47 &lt;int&gt;, wk48 &lt;int&gt;, ## # wk49 &lt;int&gt;, wk50 &lt;int&gt;, wk51 &lt;int&gt;, wk52 &lt;int&gt;, wk53 &lt;int&gt;, ## # wk54 &lt;int&gt;, wk55 &lt;int&gt;, wk56 &lt;int&gt;, wk57 &lt;int&gt;, wk58 &lt;int&gt;, ## # wk59 &lt;int&gt;, wk60 &lt;int&gt;, wk61 &lt;int&gt;, wk62 &lt;int&gt;, wk63 &lt;int&gt;, ## # wk64 &lt;int&gt;, wk65 &lt;int&gt;, wk66 &lt;chr&gt;, wk67 &lt;chr&gt;, wk68 &lt;chr&gt;, ## # wk69 &lt;chr&gt;, wk70 &lt;chr&gt;, wk71 &lt;chr&gt;, wk72 &lt;chr&gt;, wk73 &lt;chr&gt;, ## # wk74 &lt;chr&gt;, wk75 &lt;chr&gt;, wk76 &lt;chr&gt; Notemos que el rank en cada semana (una vez que entró a la lista) está guardado en 75 columnas wk1 a wk75, este tipo de almacenamiento no es limpio pero puede ser útil al momento de ingresar la información. Para tener datos limpios apilamos las semanas de manera que sea una sola columna (nuevamente alargamos los datos): billboard_long &lt;- gather(billboard, week, rank, wk1:wk76, na.rm = TRUE) billboard_long ## # A tibble: 5,307 x 7 ## year artist track time date.entered week rank ## * &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;tim&gt; &lt;date&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2000 2 Pac Baby Don&#39;t Cry (Kee… 04:22 2000-02-26 wk1 87 ## 2 2000 2Ge+her The Hardest Part Of… 03:15 2000-09-02 wk1 91 ## 3 2000 3 Doors Down Kryptonite 03:53 2000-04-08 wk1 81 ## 4 2000 3 Doors Down Loser 04:24 2000-10-21 wk1 76 ## 5 2000 504 Boyz Wobble Wobble 03:35 2000-04-15 wk1 57 ## 6 2000 98^0 Give Me Just One Ni… 03:24 2000-08-19 wk1 51 ## 7 2000 A*Teens Dancing Queen 03:44 2000-07-08 wk1 97 ## 8 2000 Aaliyah I Don&#39;t Wanna 04:15 2000-01-29 wk1 84 ## 9 2000 Aaliyah Try Again 04:03 2000-03-18 wk1 59 ## 10 2000 Adams, Yolan… Open My Heart 05:30 2000-08-26 wk1 76 ## # ... with 5,297 more rows Notemos que en esta ocasión especificamos las columnas que vamos a apilar indicando el nombre de la primera de ellas seguido de : y por último el nombre de la última variable a apilar. Por otra parte, la instrucción na.rm = TRUE se utiliza para eliminar los renglones con valores faltantes en la columna de value (rank), esto es, eliminamos aquellas observaciones que tenían NA en la columnas wknum de la tabla ancha. Ahora realizamos una limpieza adicional creando mejores variables de fecha. billboard_tidy &lt;- billboard_long %&gt;% mutate( week = parse_number(week), date = date.entered + 7 * (week - 1), rank = as.numeric(rank) ) %&gt;% select(-date.entered) billboard_tidy ## # A tibble: 5,307 x 7 ## year artist track time week rank date ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;tim&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 2000 2 Pac Baby Don&#39;t Cry (Keep… 04:22 1 87 2000-02-26 ## 2 2000 2Ge+her The Hardest Part Of … 03:15 1 91 2000-09-02 ## 3 2000 3 Doors Down Kryptonite 03:53 1 81 2000-04-08 ## 4 2000 3 Doors Down Loser 04:24 1 76 2000-10-21 ## 5 2000 504 Boyz Wobble Wobble 03:35 1 57 2000-04-15 ## 6 2000 98^0 Give Me Just One Nig… 03:24 1 51 2000-08-19 ## 7 2000 A*Teens Dancing Queen 03:44 1 97 2000-07-08 ## 8 2000 Aaliyah I Don&#39;t Wanna 04:15 1 84 2000-01-29 ## 9 2000 Aaliyah Try Again 04:03 1 59 2000-03-18 ## 10 2000 Adams, Yolanda Open My Heart 05:30 1 76 2000-08-26 ## # ... with 5,297 more rows Nuevamente, podemos hacer gráficas facilmente. tracks &lt;- filter(billboard_tidy, track %in% c(&quot;Higher&quot;, &quot;Amazed&quot;, &quot;Kryptonite&quot;, &quot;Breathe&quot;, &quot;With Arms Wide Open&quot;)) ggplot(tracks, aes(x = date, y = rank)) + geom_line() + facet_wrap(~track, nrow = 1) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) 2.2.2 Una columna asociada a más de una variable La siguiente base de datos proviene de la Organización Mundial de la Salud y contiene el número de casos confirmados de tuberculosis por país y año, la información esta por grupo demográfico de acuerdo a sexo (m, f), y edad (0-4, 5-14, etc). Los datos están disponibles en http://www.who.int/tb/country/data/download/en/. tb &lt;- read_csv(&quot;data/tb.csv&quot;) tb ## # A tibble: 5,769 x 22 ## iso2 year new_sp_m04 new_sp_m514 new_sp_m014 new_sp_m1524 new_sp_m2534 ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 AD 1989 NA NA NA NA ## 2 2 AD 1990 NA NA NA NA ## 3 3 AD 1991 NA NA NA NA ## 4 4 AD 1992 NA NA NA NA ## 5 5 AD 1993 NA NA NA NA ## 6 6 AD 1994 NA NA NA NA ## 7 7 AD 1996 NA NA 0 0 ## 8 8 AD 1997 NA NA 0 0 ## 9 9 AD 1998 NA NA 0 0 ## 10 10 AD 1999 NA NA 0 0 ## # ... with 5,759 more rows, and 15 more variables: new_sp_m3544 &lt;int&gt;, ## # new_sp_m4554 &lt;int&gt;, new_sp_m5564 &lt;int&gt;, new_sp_m65 &lt;int&gt;, ## # new_sp_mu &lt;int&gt;, new_sp_f04 &lt;int&gt;, new_sp_f514 &lt;int&gt;, ## # new_sp_f014 &lt;int&gt;, new_sp_f1524 &lt;int&gt;, new_sp_f2534 &lt;int&gt;, ## # new_sp_f3544 &lt;int&gt;, new_sp_f4554 &lt;int&gt;, new_sp_f5564 &lt;int&gt;, ## # new_sp_f65 &lt;int&gt;, new_sp_fu &lt;int&gt; De manera similar a los ejemplos anteriores, utiliza la función gather para apilar las columnas correspondientes a sexo-edad.             Piensa en como podemos separar la “variable” sexo-edad en dos columnas. Ahora separaremos las variables sexo y edad de la columna demo, para ello debemos pasar a la función separate(), esta recibe como parámetros: el nombre de la base de datos, el nombre de la variable que deseamos separar en más de una, la posición de donde deseamos “cortar” (hay más opciones para especificar como separar, ver ?separate). El default es separar valores en todos los lugares que encuentre un caracter que no es alfanumérico (espacio, guión,…). tb_tidy &lt;- separate(tb_long, demo, c(&quot;sex&quot;, &quot;age&quot;), 8) tb_tidy ## # A tibble: 41,247 x 5 ## iso2 year sex age n ## * &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 1 AD new_sp_m 04 1989 ## 2 2 AD new_sp_m 04 1990 ## 3 3 AD new_sp_m 04 1991 ## 4 4 AD new_sp_m 04 1992 ## 5 5 AD new_sp_m 04 1993 ## 6 6 AD new_sp_m 04 1994 ## 7 7 AD new_sp_m 04 1996 ## 8 8 AD new_sp_m 04 1997 ## 9 9 AD new_sp_m 04 1998 ## 10 10 AD new_sp_m 04 1999 ## # ... with 41,237 more rows table(tb_tidy$sex) ## ## new_sp_f new_sp_m ## 17831 23416 # creamos un mejor código de genero tb_tidy &lt;- mutate(tb_tidy, sex = substr(sex, 8, 8)) table(tb_tidy$sex) ## ## f m ## 17831 23416 2.2.3 Variables almacenadas en filas y columnas El problema más difícil es cuando las variables están tanto en filas como en columnas, veamos una base de datos de clima en Cuernavaca. ¿Cuáles son las variables en estos datos? clima &lt;- read_delim(&quot;data/clima.txt&quot;, &quot;\\t&quot;, escape_double = FALSE, trim_ws = TRUE) Estos datos tienen variables en columnas individuales (id, año, mes), en múltiples columnas (día, d1-d31) y en filas (tmin, tmax). Comencemos por apilar las columnas. clima_long &lt;- gather(clima, day, value, d1:d31, na.rm = TRUE) clima_long ## # A tibble: 66 x 6 ## id year month element day value ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 MX000017004 2010 12 TMAX d1 299 ## 2 MX000017004 2010 12 TMIN d1 138 ## 3 MX000017004 2010 2 TMAX d2 273 ## 4 MX000017004 2010 2 TMIN d2 144 ## 5 MX000017004 2010 11 TMAX d2 313 ## 6 MX000017004 2010 11 TMIN d2 163 ## 7 MX000017004 2010 2 TMAX d3 241 ## 8 MX000017004 2010 2 TMIN d3 144 ## 9 MX000017004 2010 7 TMAX d3 286 ## 10 MX000017004 2010 7 TMIN d3 175 ## # ... with 56 more rows Podemos crear algunas variables adicionales. clima_vars &lt;- clima_long %&gt;% mutate(day = parse_number(day), value = as.numeric(value) / 10) %&gt;% select(id, year, month, day, element, value) %&gt;% arrange(id, year, month, day) clima_vars ## # A tibble: 66 x 6 ## id year month day element value ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 MX000017004 2010 1 30 TMAX 27.8 ## 2 MX000017004 2010 1 30 TMIN 14.5 ## 3 MX000017004 2010 2 2 TMAX 27.3 ## 4 MX000017004 2010 2 2 TMIN 14.4 ## 5 MX000017004 2010 2 3 TMAX 24.1 ## 6 MX000017004 2010 2 3 TMIN 14.4 ## 7 MX000017004 2010 2 11 TMAX 29.7 ## 8 MX000017004 2010 2 11 TMIN 13.4 ## 9 MX000017004 2010 2 23 TMAX 29.9 ## 10 MX000017004 2010 2 23 TMIN 10.7 ## # ... with 56 more rows Finalmente, la columna element no es una variable, sino que almacena el nombre de dos variables, la operación que debemos aplicar (spread) es el inverso de apilar (gather): clima_tidy &lt;- spread(clima_vars, element, value) clima_tidy ## # A tibble: 33 x 6 ## id year month day TMAX TMIN ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MX000017004 2010 1 30 27.8 14.5 ## 2 MX000017004 2010 2 2 27.3 14.4 ## 3 MX000017004 2010 2 3 24.1 14.4 ## 4 MX000017004 2010 2 11 29.7 13.4 ## 5 MX000017004 2010 2 23 29.9 10.7 ## 6 MX000017004 2010 3 5 32.1 14.2 ## 7 MX000017004 2010 3 10 34.5 16.8 ## 8 MX000017004 2010 3 16 31.1 17.6 ## 9 MX000017004 2010 4 27 36.3 16.7 ## 10 MX000017004 2010 5 27 33.2 18.2 ## # ... with 23 more rows Ahora es inmediato no solo hacer gráficas sino también ajustar un modelo. # ajustamos un modelo lineal donde la variable respuesta es temperatura # máxima, y la variable explicativa es el mes clima_lm &lt;- lm(TMAX ~ factor(month), data = clima_tidy) summary(clima_lm) ## ## Call: ## lm(formula = TMAX ~ factor(month), data = clima_tidy) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.65 -0.92 -0.02 1.05 3.18 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 27.8000 1.8610 14.938 5.34e-13 *** ## factor(month)2 -0.0500 2.0807 -0.024 0.98104 ## factor(month)3 4.7667 2.1489 2.218 0.03717 * ## factor(month)4 8.5000 2.6319 3.230 0.00385 ** ## factor(month)5 5.4000 2.6319 2.052 0.05228 . ## factor(month)6 1.2500 2.2793 0.548 0.58892 ## factor(month)7 1.4500 2.2793 0.636 0.53123 ## factor(month)8 0.4714 1.9895 0.237 0.81488 ## factor(month)10 1.1000 2.0386 0.540 0.59491 ## factor(month)11 0.3200 2.0386 0.157 0.87670 ## factor(month)12 1.0500 2.2793 0.461 0.64955 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.861 on 22 degrees of freedom ## Multiple R-squared: 0.6182, Adjusted R-squared: 0.4447 ## F-statistic: 3.563 on 10 and 22 DF, p-value: 0.006196 2.2.4 Mas de un tipo de observación en una misma tabla En ocasiones las bases de datos involucran valores en diferentes niveles, en diferentes tipos de unidad observacional. En la limpieza de datos, cada unidad observacional debe estar almacenada en su propia tabla (esto esta ligado a normalización de una base de datos), es importante para evitar inconsistencias en los datos. ¿Cuáles son las unidades observacionales de los datos de billboard? billboard_tidy ## # A tibble: 5,307 x 7 ## year artist track time week rank date ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;tim&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; ## 1 2000 2 Pac Baby Don&#39;t Cry (Keep… 04:22 1 87 2000-02-26 ## 2 2000 2Ge+her The Hardest Part Of … 03:15 1 91 2000-09-02 ## 3 2000 3 Doors Down Kryptonite 03:53 1 81 2000-04-08 ## 4 2000 3 Doors Down Loser 04:24 1 76 2000-10-21 ## 5 2000 504 Boyz Wobble Wobble 03:35 1 57 2000-04-15 ## 6 2000 98^0 Give Me Just One Nig… 03:24 1 51 2000-08-19 ## 7 2000 A*Teens Dancing Queen 03:44 1 97 2000-07-08 ## 8 2000 Aaliyah I Don&#39;t Wanna 04:15 1 84 2000-01-29 ## 9 2000 Aaliyah Try Again 04:03 1 59 2000-03-18 ## 10 2000 Adams, Yolanda Open My Heart 05:30 1 76 2000-08-26 ## # ... with 5,297 more rows Separemos esta base de datos en dos: la tabla canción que almacena artista, nombre de la canción y duración; la tabla rank que almacena el ranking de la canción en cada semana. song &lt;- billboard_tidy %&gt;% select(artist, track, year, time) %&gt;% unique() %&gt;% arrange(artist) %&gt;% mutate(song_id = row_number(artist)) song ## # A tibble: 317 x 5 ## artist track year time song_id ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;time&gt; &lt;int&gt; ## 1 2 Pac Baby Don&#39;t Cry (Keep... 2000 04:22 1 ## 2 2Ge+her The Hardest Part Of ... 2000 03:15 2 ## 3 3 Doors Down Kryptonite 2000 03:53 3 ## 4 3 Doors Down Loser 2000 04:24 4 ## 5 504 Boyz Wobble Wobble 2000 03:35 5 ## 6 98^0 Give Me Just One Nig... 2000 03:24 6 ## 7 A*Teens Dancing Queen 2000 03:44 7 ## 8 Aaliyah I Don&#39;t Wanna 2000 04:15 8 ## 9 Aaliyah Try Again 2000 04:03 9 ## 10 Adams, Yolanda Open My Heart 2000 05:30 10 ## # ... with 307 more rows rank &lt;- billboard_tidy %&gt;% left_join(song, c(&quot;artist&quot;, &quot;track&quot;, &quot;year&quot;, &quot;time&quot;)) %&gt;% select(song_id, date, week, rank) %&gt;% arrange(song_id, date) %&gt;% tbl_df rank ## # A tibble: 5,307 x 4 ## song_id date week rank ## &lt;int&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2000-02-26 1 87 ## 2 1 2000-03-04 2 82 ## 3 1 2000-03-11 3 72 ## 4 1 2000-03-18 4 77 ## 5 1 2000-03-25 5 87 ## 6 1 2000-04-01 6 94 ## 7 1 2000-04-08 7 99 ## 8 2 2000-09-02 1 91 ## 9 2 2000-09-09 2 87 ## 10 2 2000-09-16 3 92 ## # ... with 5,297 more rows 2.2.5 Una misma unidad observacional está almacenada en múltiples tablas También es común que los valores sobre una misma unidad observacional estén separados en muchas tablas o archivos, es común que estas tablas esten divididas de acuerdo a una variable, de tal manera que cada archivo representa a una persona, año o ubicación. Para juntar los archivos hacemos lo siguiente: Leemos los archivos en una lista de tablas. Para cada tabla agregamos una columna que registra el nombre del archivo original. Combinamos las tablas en un solo data frame. Veamos un ejemplo, descarga la carpeta specdata, ésta contiene 332 archivos csv que almacenan información de monitoreo de contaminación en 332 ubicaciones de EUA. Cada archivo contiene información de una unidad de monitoreo y el número de identificación del monitor es el nombre del archivo. Los pasos en R (usando el paquete purrr), primero creamos un vector con los nombres de los archivos en un directorio, eligiendo aquellos que contengan las letras “.csv”. paths &lt;- dir(&quot;data/specdata&quot;, pattern = &quot;\\\\.csv$&quot;, full.names = TRUE) Después le asignamos el nombre del csv al nombre de cada elemento del vector. Este paso se realiza para preservar los nombres de los archivos ya que estos los asignaremos a una variable mas adelante. paths &lt;- set_names(paths, basename(paths)) La función map_df itera sobre cada dirección, lee el csv en dicha dirección y los combina en un data frame. specdata_us &lt;- map_df(paths, ~read_csv(., col_types = &quot;Tddi&quot;), .id = &quot;filename&quot;) # eliminamos la basura del id specdata &lt;- specdata_us %&gt;% mutate(monitor = parse_number(filename)) %&gt;% select(id = ID, monitor, date = Date, sulfate, nitrate) specdata ## # A tibble: 772,087 x 5 ## id monitor date sulfate nitrate ## &lt;int&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2003-01-01 00:00:00 NA NA ## 2 1 1 2003-01-02 00:00:00 NA NA ## 3 1 1 2003-01-03 00:00:00 NA NA ## 4 1 1 2003-01-04 00:00:00 NA NA ## 5 1 1 2003-01-05 00:00:00 NA NA ## 6 1 1 2003-01-06 00:00:00 NA NA ## 7 1 1 2003-01-07 00:00:00 NA NA ## 8 1 1 2003-01-08 00:00:00 NA NA ## 9 1 1 2003-01-09 00:00:00 NA NA ## 10 1 1 2003-01-10 00:00:00 NA NA ## # ... with 772,077 more rows 2.2.6 Otras consideraciones En las buenas prácticas es importante tomar en cuenta los siguientes puntos: Incluir un encabezado con el nombre de las variables. Los nombres de las variables deben ser entendibles (e.g. AgeAtDiagnosis es mejor que AgeDx). En general los datos se deben guardar en un archivo por tabla. Escribir un script con las modificaciones que se hicieron a los datos crudos (reproducibilidad). Otros aspectos importantes en la limpieza de datos son: selección del tipo de variables (por ejemplo fechas), datos faltantes, typos y detección de valores atípicos. "],
["divide-aplica-combina-split-apply-combine.html", "2.3 Divide-aplica-combina (split-apply-combine)", " 2.3 Divide-aplica-combina (split-apply-combine) Muchos problemas de análisis de datos involucran la aplicación de la estrategia divide-aplica-combina, (Hadley Whickam, 2011) esta consiste en romper un problema en pedazos (de acuerdo a una variable de interés), operar sobre cada subconjunto de manera independiente (ej. calcular la media de cada grupo, ordenar observaciones por grupo, estandarizar por grupo) y después unir los pedazos nuevamente. El siguiente diagrama ejemplifiaca el paradigma de divide-aplica-combina: Separa la base de datos original. Aplica funciones a cada subconjunto. Combina los resultados en una nueva base de datos. En esta sección trabajaremos con las siguientes bases de datos para ejemplifcar las funciones de divide-aplica-combina: flights &lt;- read_csv(&quot;data/flights.csv&quot;) flights ## # A tibble: 227,496 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-01 12:00:00 14 0 1400 1500 0 -10 AA ## 2 2011-01-02 12:00:00 14 1 1401 1501 1 -9 AA ## 3 2011-01-03 12:00:00 13 52 1352 1502 -8 -8 AA ## 4 2011-01-04 12:00:00 14 3 1403 1513 3 3 AA ## 5 2011-01-05 12:00:00 14 5 1405 1507 5 -3 AA ## 6 2011-01-06 12:00:00 13 59 1359 1503 -1 -7 AA ## 7 2011-01-07 12:00:00 13 59 1359 1509 -1 -1 AA ## 8 2011-01-08 12:00:00 13 55 1355 1454 -5 -16 AA ## 9 2011-01-09 12:00:00 14 43 1443 1554 43 44 AA ## 10 2011-01-10 12:00:00 14 43 1443 1553 43 43 AA ## # ... with 227,486 more rows, and 6 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; weather &lt;- read_csv(&quot;data/weather.csv&quot;) weather ## # A tibble: 8,723 x 14 ## date hour temp dew_point humidity pressure visibility wind_dir ## &lt;date&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2011-01-01 0 59 28.9 32 29.9 10 NNE ## 2 2011-01-01 1 57.2 28.4 33 29.9 10 NNE ## 3 2011-01-01 2 55.4 28.4 36 29.9 10 NNW ## 4 2011-01-01 3 53.6 28.4 38 29.9 10 North ## 5 2011-01-01 4 NA NA NA 30.0 10 NNW ## 6 2011-01-01 5 NA NA NA 30.0 10 North ## 7 2011-01-01 6 53.1 17.1 24 30.0 10 North ## 8 2011-01-01 7 53.1 16 23 30.1 10 North ## 9 2011-01-01 8 54 18 24 30.1 10 North ## 10 2011-01-01 9 55.4 17.6 23 30.1 10 NNE ## # ... with 8,713 more rows, and 6 more variables: wind_dir2 &lt;int&gt;, ## # wind_speed &lt;dbl&gt;, gust_speed &lt;dbl&gt;, precip &lt;dbl&gt;, conditions &lt;chr&gt;, ## # events &lt;chr&gt; planes &lt;- read_csv(&quot;data/planes.csv&quot;) planes ## # A tibble: 2,853 x 9 ## plane year mfr model no.eng no.seats speed engine type ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 N576AA 1991 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 2 N557AA 1993 MARZ BAR… KITFOX… 1 2 NA Recipr… Fixed win… ## 3 N403AA 1974 RAVEN S55A NA 1 60 None Balloon ## 4 N492AA 1989 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 5 N262AA 1985 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 6 N493AA 1989 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 7 N477AA 1988 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 8 N476AA 1988 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 9 N504AA NA AUTHIER … TIERRA… 1 2 NA Recipr… Fixed win… ## 10 N565AA 1987 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## # ... with 2,843 more rows airports &lt;- read_csv(&quot;data/airports.csv&quot;) airports ## # A tibble: 3,376 x 7 ## iata airport city state country lat long ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00M Thigpen Bay Springs MS USA 32.0 -89.2 ## 2 00R Livingston Municipal Livingston TX USA 30.7 -95.0 ## 3 00V Meadow Lake Colorado Springs CO USA 38.9 -105. ## 4 01G Perry-Warsaw Perry NY USA 42.7 -78.1 ## 5 01J Hilliard Airpark Hilliard FL USA 30.7 -81.9 ## 6 01M Tishomingo County Belmont MS USA 34.5 -88.2 ## 7 02A Gragg-Wade Clanton AL USA 32.9 -86.6 ## 8 02C Capitol Brookfield WI USA 43.1 -88.2 ## 9 02G Columbiana County East Liverpool OH USA 40.7 -80.6 ## 10 03D Memphis Memorial Memphis MO USA 40.4 -92.2 ## # ... with 3,366 more rows Cuando pensamos como implementar la estrategia divide-aplica-combina es natural pensar en iteraciones, por ejemplo utilizar un ciclo for para recorrer cada grupo de interés y aplicar las funciones, sin embargo la aplicación de ciclos for desemboca en código difícil de entender. Adicionalmente, dplyr es mucho más veloz. Estudiaremos las siguientes funciones: filter: obten un subconjunto de las filas de acuerdo a un criterio. select: selecciona columnas de acuerdo al nombre arrange: reordena las filas mutate: agrega nuevas variables summarise: reduce variables a valores (crear nuevas bases de datos con resúmenes de variables de la base original) Estas funciones trabajan de manera similar, el primer argumento que reciben es un data frame (usualmente en formato limpio), los argumentos que siguen indican que operación se va a efectuar y el resultado es un nuevo data frame. Adicionalmente, se pueden usar con group_by que cambia el dominio de cada función, pasando de operar en el conjunto de datos completos a operar en grupos. Veamos con ejemplos. 2.3.0.1 Filtrar Creamos una base de datos de juguete para mostrar el funcionamiento de cada instrucción: df_ej &lt;- tibble(genero = c(&quot;mujer&quot;, &quot;hombre&quot;, &quot;mujer&quot;, &quot;mujer&quot;, &quot;hombre&quot;), estatura = c(1.65, 1.80, 1.70, 1.60, 1.67)) df_ej ## # A tibble: 5 x 2 ## genero estatura ## &lt;chr&gt; &lt;dbl&gt; ## 1 mujer 1.65 ## 2 hombre 1.8 ## 3 mujer 1.7 ## 4 mujer 1.6 ## 5 hombre 1.67 El primer argumento de filter() es el nombre del data frame, los subsecuentes son las expresiones que indican que filas filtrar. filter(df_ej, genero == &quot;mujer&quot;) ## # A tibble: 3 x 2 ## genero estatura ## &lt;chr&gt; &lt;dbl&gt; ## 1 mujer 1.65 ## 2 mujer 1.7 ## 3 mujer 1.6 filter(df_ej, estatura &gt; 1.65 &amp; estatura &lt; 1.75) ## # A tibble: 2 x 2 ## genero estatura ## &lt;chr&gt; &lt;dbl&gt; ## 1 mujer 1.7 ## 2 hombre 1.67 Algunos operadores importantes para filtrar son: x &gt; 1 x &gt;= 1 x &lt; 1 x &lt;= 1 x != 1 x == 1 x %in% (&quot;a&quot;, &quot;b&quot;) Debemos tener cuidado al usar == sqrt(2) ^ 2 == 2 ## [1] FALSE 1/49 * 49 == 1 ## [1] FALSE Los resultados de arriba se deben a que las computadoras usan aritmética de precisión finita: print(1/49 * 49, digits = 20) ## [1] 0.99999999999999988898 Para estos casos es útil usar la función near() near(sqrt(2) ^ 2, 2) ## [1] TRUE near(1 / 49 * 49, 1) ## [1] TRUE Los operadores booleanos también son convenientes para filtrar: # Conjuntos a | b a &amp; b a &amp; !b xor(a, b) El siguiente esquema nos ayuda a entender que hace cada operación: knitr::include_graphics(&quot;imagenes/transform-logical.png&quot;) Encuentra todos los vuelos hacia SFO ó OAK.             Los vuelos con un retraso mayor a una hora.             En los que el retraso de llegada es más del doble que el retraso de salida. 2.3.0.2 Seleccionar Elegir columnas de un conjunto de datos. df_ej ## # A tibble: 5 x 2 ## genero estatura ## &lt;chr&gt; &lt;dbl&gt; ## 1 mujer 1.65 ## 2 hombre 1.8 ## 3 mujer 1.7 ## 4 mujer 1.6 ## 5 hombre 1.67 select(df_ej, genero) ## # A tibble: 5 x 1 ## genero ## &lt;chr&gt; ## 1 mujer ## 2 hombre ## 3 mujer ## 4 mujer ## 5 hombre select(df_ej, -genero) ## # A tibble: 5 x 1 ## estatura ## &lt;dbl&gt; ## 1 1.65 ## 2 1.8 ## 3 1.7 ## 4 1.6 ## 5 1.67 select(df_ej, starts_with(&quot;g&quot;)) select(df_ej, contains(&quot;g&quot;)) Ve la ayuda de select (?select) y escribe tres maneras de seleccionar las variables de retraso (delay). 2.3.0.3 Arreglar Arreglar u ordenar de acuerdo al valor de una o más variables: arrange(df_ej, genero) ## # A tibble: 5 x 2 ## genero estatura ## &lt;chr&gt; &lt;dbl&gt; ## 1 hombre 1.8 ## 2 hombre 1.67 ## 3 mujer 1.65 ## 4 mujer 1.7 ## 5 mujer 1.6 arrange(df_ej, desc(estatura)) ## # A tibble: 5 x 2 ## genero estatura ## &lt;chr&gt; &lt;dbl&gt; ## 1 hombre 1.8 ## 2 mujer 1.7 ## 3 hombre 1.67 ## 4 mujer 1.65 ## 5 mujer 1.6 Ordena los vuelos por fecha de salida y hora.             ¿Cuáles son los vuelos con mayor retraso?             ¿Qué vuelos ganaron más tiempo en el aire? 2.3.0.4 Mutar Mutar consiste en crear nuevas variables aplicando una función a columnas existentes: mutate(df_ej, estatura_cm = estatura * 100) ## # A tibble: 5 x 3 ## genero estatura estatura_cm ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 mujer 1.65 165 ## 2 hombre 1.8 180 ## 3 mujer 1.7 170 ## 4 mujer 1.6 160 ## 5 hombre 1.67 167 mutate(df_ej, estatura_cm = estatura * 100, estatura_in = estatura_cm * 0.3937) ## # A tibble: 5 x 4 ## genero estatura estatura_cm estatura_in ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 mujer 1.65 165 65.0 ## 2 hombre 1.8 180 70.9 ## 3 mujer 1.7 170 66.9 ## 4 mujer 1.6 160 63.0 ## 5 hombre 1.67 167 65.7 Calcula la velocidad en millas por hora a partir de la variable tiempo y la distancia (en millas). ¿Quá vuelo fue el más rápido?             Crea una nueva variable que muestre cuánto tiempo se ganó o perdió durante el vuelo. Hay muchas funciones que podemos usar para crear nuevas variables con mutate(), éstas deben cumplir ser funciones vectorizadas, es decir, reciben un vector de valores y devuelven un vector de la misma dimensión. 2.3.0.5 Summarise y resúmenes por grupo Summarise sirve para crear nuevas bases de datos con resúmenes o agregaciones de los datos originales. summarise(df_ej, promedio = mean(estatura)) ## # A tibble: 1 x 1 ## promedio ## &lt;dbl&gt; ## 1 1.68 Podemos hacer resúmenes por grupo, primero creamos una base de datos agrupada: by_genero &lt;- group_by(df_ej, genero) by_genero ## # A tibble: 5 x 2 ## # Groups: genero [2] ## genero estatura ## &lt;chr&gt; &lt;dbl&gt; ## 1 mujer 1.65 ## 2 hombre 1.8 ## 3 mujer 1.7 ## 4 mujer 1.6 ## 5 hombre 1.67 y después operamos sobre cada grupo, creando un resumen a nivel grupo y uniendo los subconjuntos en una base nueva: summarise(by_genero, promedio = mean(estatura)) ## # A tibble: 2 x 2 ## genero promedio ## &lt;chr&gt; &lt;dbl&gt; ## 1 hombre 1.74 ## 2 mujer 1.65 Calcula el retraso promedio por fecha.             ¿Qué otros resúmenes puedes hacer para explorar el retraso por fecha? Algunas funciones útiles con summarise son min(x), median(x), max(x), quantile(x, p), n(), sum(x), sum(x &gt; 1), mean(x &gt; 1), sd(x). flights$date_only &lt;- as.Date(flights$date) by_date &lt;- group_by(flights, date_only) no_miss &lt;- filter(by_date, !is.na(dep)) delays &lt;- summarise(no_miss, mean_delay = mean(dep_delay), n = n()) 2.3.0.6 Operador pipeline En R cuando uno hace varias operaciones es difícil leer y entender el código: hourly_delay &lt;- filter(summarise(group_by(filter(flights, !is.na(dep_delay)), date_only, hour), delay = mean(dep_delay), n = n()), n &gt; 10) La dificultad radica en que usualmente los parámetros se asignan después del nombre de la función usando (). El operador “Forward Pipe” (%&gt;%) cambia este orden, de manera que un parámetro que precede a la función es enviado (&quot;piped&quot;) a la función:x %&gt;% f(y)se vuelvef(x,y),x %&gt;% f(y) %&gt;% g(z)se vuelveg(f(x, y), z)`. Es así que podemos reescribir el código para poder leer las operaciones que vamos aplicando de izquierda a derecha y de arriba hacia abajo. Veamos como cambia el código anterior: hourly_delay &lt;- flights %&gt;% filter(!is.na(dep_delay)) %&gt;% group_by(date_only, hour) %&gt;% summarise(delay = mean(dep_delay), n = n()) %&gt;% filter(n &gt; 10) podemos leer %&gt;% como “después”. ¿Qué destinos tienen el promedio de retrasos más alto?             ¿Qué vuelos (compañía + vuelo) ocurren diario?             En promedio, ¿Cómo varían a lo largo del día los retrasos de vuelos no cancelados? (pista: hour + minute / 60) 2.3.0.7 Variables por grupo En ocasiones es conveniente crear variables por grupo, por ejemplo estandarizar dentro de cada grupo z = (x - mean(x)) / sd(x). Veamos un ejemplo: planes &lt;- flights %&gt;% filter(!is.na(arr_delay)) %&gt;% group_by(plane) %&gt;% filter(n() &gt; 30) planes %&gt;% mutate(z_delay = (arr_delay - mean(arr_delay)) / sd(arr_delay)) %&gt;% filter(z_delay &gt; 5) ## # A tibble: 1,403 x 16 ## # Groups: plane [856] ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-28 12:00:00 15 16 1516 1916 351 326 CO ## 2 2011-01-27 12:00:00 18 22 1822 1945 234 210 CO ## 3 2011-01-27 12:00:00 21 37 2137 2254 242 219 CO ## 4 2011-01-27 12:00:00 0 11 11 216 168 137 CO ## 5 2011-01-27 12:00:00 22 37 2237 153 227 208 CO ## 6 2011-01-27 12:00:00 21 28 2128 136 231 216 CO ## 7 2011-01-26 12:00:00 11 46 1146 1633 171 193 CO ## 8 2011-01-26 12:00:00 9 49 949 1436 144 180 CO ## 9 2011-01-21 12:00:00 19 11 1911 2352 94 112 CO ## 10 2011-01-20 12:00:00 6 35 635 807 780 775 CO ## # ... with 1,393 more rows, and 8 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt;, ## # date_only &lt;date&gt;, z_delay &lt;dbl&gt; 2.3.0.8 Verbos de dos tablas ¿Cómo mostramos los retrasos de los vuelos en un mapa? Para responder esta pregunta necesitamos unir la base de datos de vuelos con la de aeropuertos. location &lt;- airports %&gt;% select(dest = iata, name = airport, lat, long) flights %&gt;% group_by(dest) %&gt;% filter(!is.na(arr_delay)) %&gt;% summarise( arr_delay = mean(arr_delay), n = n() ) %&gt;% arrange(desc(arr_delay)) %&gt;% left_join(location) ## Joining, by = &quot;dest&quot; ## # A tibble: 116 x 6 ## dest arr_delay n name lat long ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ANC 26.1 124 Ted Stevens Anchorage International 61.2 -150. ## 2 CID 17.8 406 Eastern Iowa 41.9 -91.7 ## 3 DSM 16.0 634 Des Moines International 41.5 -93.7 ## 4 SFO 14.9 2800 San Francisco International 37.6 -122. ## 5 BPT 14.3 3 Southeast Texas Regional 30.0 -94.0 ## 6 GRR 13.7 665 Kent County International 42.9 -85.5 ## 7 DAY 13.7 444 James M Cox Dayton Intl 39.9 -84.2 ## 8 VPS 12.5 864 Eglin Air Force Base 30.5 -86.5 ## 9 ECP 12.4 720 &lt;NA&gt; NA NA ## 10 SAV 12.3 851 Savannah International 32.1 -81.2 ## # ... with 106 more rows Hay varias maneras de unir dos bases de datos y debemos pensar en el obejtivo: x &lt;- tibble(name = c(&quot;John&quot;, &quot;Paul&quot;, &quot;George&quot;, &quot;Ringo&quot;, &quot;Stuart&quot;, &quot;Pete&quot;), instrument = c(&quot;guitar&quot;, &quot;bass&quot;, &quot;guitar&quot;, &quot;drums&quot;, &quot;bass&quot;, &quot;drums&quot;)) y &lt;- tibble(name = c(&quot;John&quot;, &quot;Paul&quot;, &quot;George&quot;, &quot;Ringo&quot;, &quot;Brian&quot;), band = c(&quot;TRUE&quot;, &quot;TRUE&quot;, &quot;TRUE&quot;, &quot;TRUE&quot;, &quot;FALSE&quot;)) x ## # A tibble: 6 x 2 ## name instrument ## &lt;chr&gt; &lt;chr&gt; ## 1 John guitar ## 2 Paul bass ## 3 George guitar ## 4 Ringo drums ## 5 Stuart bass ## 6 Pete drums y ## # A tibble: 5 x 2 ## name band ## &lt;chr&gt; &lt;chr&gt; ## 1 John TRUE ## 2 Paul TRUE ## 3 George TRUE ## 4 Ringo TRUE ## 5 Brian FALSE inner_join(x, y) ## Joining, by = &quot;name&quot; ## # A tibble: 4 x 3 ## name instrument band ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John guitar TRUE ## 2 Paul bass TRUE ## 3 George guitar TRUE ## 4 Ringo drums TRUE left_join(x, y) ## Joining, by = &quot;name&quot; ## # A tibble: 6 x 3 ## name instrument band ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 John guitar TRUE ## 2 Paul bass TRUE ## 3 George guitar TRUE ## 4 Ringo drums TRUE ## 5 Stuart bass &lt;NA&gt; ## 6 Pete drums &lt;NA&gt; semi_join(x, y) ## Joining, by = &quot;name&quot; ## # A tibble: 4 x 2 ## name instrument ## &lt;chr&gt; &lt;chr&gt; ## 1 John guitar ## 2 Paul bass ## 3 George guitar ## 4 Ringo drums anti_join(x, y) ## Joining, by = &quot;name&quot; ## # A tibble: 2 x 2 ## name instrument ## &lt;chr&gt; &lt;chr&gt; ## 1 Stuart bass ## 2 Pete drums Resumamos lo que observamos arriba: Tipo Acción inner Incluye únicamente las filas que aparecen tanto en x como en y left Incluye todas las filas en x y las filas de y que coincidan semi Incluye las filas de x que coincidan con y anti Incluye las filas de x que no coinciden con y Ahora combinamos datos a nivel hora con condiciones climáticas, ¿cuál es el tipo de unión adecuado? hourly_delay &lt;- flights %&gt;% group_by(date_only, hour) %&gt;% filter(!is.na(dep_delay)) %&gt;% summarise( delay = mean(dep_delay), n = n() ) %&gt;% filter(n &gt; 10) delay_weather &lt;- hourly_delay %&gt;% left_join(weather) ## Joining, by = &quot;hour&quot; arrange(delay_weather, -delay) ## # A tibble: 2,091,842 x 17 ## # Groups: date_only [365] ## date_only hour delay n date temp dew_point humidity ## &lt;date&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2011-05-12 23 184. 33 2011-01-02 43 28.9 58 ## 2 2011-05-12 23 184. 33 2011-01-03 39 27 62 ## 3 2011-05-12 23 184. 33 2011-01-04 50 45 83 ## 4 2011-05-12 23 184. 33 2011-01-05 62.6 60.8 94 ## 5 2011-05-12 23 184. 33 2011-01-06 53.1 36 52 ## 6 2011-05-12 23 184. 33 2011-01-07 46.9 36 66 ## 7 2011-05-12 23 184. 33 2011-01-08 50 43 77 ## 8 2011-05-12 23 184. 33 2011-01-09 53.1 30 41 ## 9 2011-05-12 23 184. 33 2011-01-10 41 37 86 ## 10 2011-05-12 23 184. 33 2011-01-11 39.9 32 73 ## # ... with 2,091,832 more rows, and 9 more variables: pressure &lt;dbl&gt;, ## # visibility &lt;dbl&gt;, wind_dir &lt;chr&gt;, wind_dir2 &lt;int&gt;, wind_speed &lt;dbl&gt;, ## # gust_speed &lt;dbl&gt;, precip &lt;dbl&gt;, conditions &lt;chr&gt;, events &lt;chr&gt; ¿Qué condiciones climáticas están asociadas con retrasos en las salidas de Houston?             Explora si los aviones más viejos están asociados a mayores retrasos, responde con una gráfica. "],
["recursos-adicionales.html", "2.4 Recursos adicionales", " 2.4 Recursos adicionales Tidy Data, Hadley Wickham. The Slit-Apply-Combine Strategy for Data Analysis, Hadley Wickham 2011. Data Wrangling Cheat Sheet, RStudio. "]
]
