<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Estadística Computacional</title>
  <meta name="description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Estadística Computacional" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  <meta name="github-repo" content="tereom/est-computacional-2018" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Estadística Computacional" />
  
  <meta name="twitter:description" content="Curso de estadística computacional, Maestría en Ciencia de Datos, ITAM 2018." />
  

<meta name="author" content="María Teresa Ortiz">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="el-principio-del-plug-in.html">
<link rel="next" href="intervalos-de-confianza.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/d3-3.5.6/d3.min.js"></script>
<link href="libs/profvis-0.3.5/profvis.css" rel="stylesheet" />
<script src="libs/profvis-0.3.5/profvis.js"></script>
<link href="libs/highlight-6.2.0/textmate.css" rel="stylesheet" />
<script src="libs/highlight-6.2.0/highlight.js"></script>
<script src="libs/profvis-binding-0.3.5/profvis.js"></script>
<script src="libs/plotly-binding-4.8.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.39.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.39.2/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
<link rel="stylesheet" href="css/font-awesome.min.css" type="text/css" />
<link rel="stylesheet" href="css/cajas.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística Computacional</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Información del curso</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html"><i class="fa fa-check"></i>Temario</a><ul>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#calificacion"><i class="fa fa-check"></i>Calificación</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#software"><i class="fa fa-check"></i>Software</a></li>
<li class="chapter" data-level="" data-path="temario.html"><a href="temario.html#otros-recursos"><i class="fa fa-check"></i>Otros recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html"><i class="fa fa-check"></i><b>1</b> Introducción a visualización</a><ul>
<li class="chapter" data-level="" data-path="introduccion-a-visualizacion.html"><a href="introduccion-a-visualizacion.html#el-cuarteto-de-ascombe"><i class="fa fa-check"></i>El cuarteto de Ascombe</a></li>
<li class="chapter" data-level="1.1" data-path="introduccion.html"><a href="introduccion.html"><i class="fa fa-check"></i><b>1.1</b> Introducción</a><ul>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-de-datos-en-la-estadistica"><i class="fa fa-check"></i>Visualización de datos en la estadística</a></li>
<li class="chapter" data-level="" data-path="introduccion.html"><a href="introduccion.html#visualizacion-popular-de-datos"><i class="fa fa-check"></i>Visualización popular de datos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html"><i class="fa fa-check"></i><b>1.2</b> Teoría de visualización de datos</a><ul>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#principios-generales-del-diseno-analitico"><i class="fa fa-check"></i>Principios generales del diseño analítico</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tecnicas-de-visualizacion"><i class="fa fa-check"></i>Técnicas de visualización</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#indicadores-de-calidad-grafica"><i class="fa fa-check"></i>Indicadores de calidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#factor-de-engano-chartjunk-y-pies"><i class="fa fa-check"></i>Factor de engaño, chartjunk y pies</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#series-de-tiempo-y-promedio-de-45"><i class="fa fa-check"></i>Series de tiempo y promedio de 45</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#pequenos-multiplos-y-densidad-grafica"><i class="fa fa-check"></i>Pequeños múltiplos y densidad gráfica</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#tinta-de-datos"><i class="fa fa-check"></i>Tinta de datos</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#percepcion-de-escala"><i class="fa fa-check"></i>Percepción de escala</a></li>
<li class="chapter" data-level="" data-path="teoria-de-visualizacion-de-datos.html"><a href="teoria-de-visualizacion-de-datos.html#minard"><i class="fa fa-check"></i>Minard</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduccion-a-r-y-al-paquete-ggplot2.html"><a href="introduccion-a-r-y-al-paquete-ggplot2.html"><i class="fa fa-check"></i><b>2</b> Introducción a R y al paquete ggplot2</a><ul>
<li class="chapter" data-level="2.1" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html"><i class="fa fa-check"></i><b>2.1</b> R: primeros pasos</a><ul>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#r-en-analisis-de-datos"><i class="fa fa-check"></i>R en análisis de datos</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#paquetes-y-el-tidyverse"><i class="fa fa-check"></i>Paquetes y el Tidyverse</a></li>
<li class="chapter" data-level="" data-path="r-primeros-pasos.html"><a href="r-primeros-pasos.html#recursos"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html"><i class="fa fa-check"></i><b>2.2</b> Visualización con ggplot2</a><ul>
<li class="chapter" data-level="" data-path="visualizacion-con-ggplot2.html"><a href="visualizacion-con-ggplot2.html#recursos-1"><i class="fa fa-check"></i>Recursos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="manipulacion-y-agrupacion-de-datos.html"><a href="manipulacion-y-agrupacion-de-datos.html"><i class="fa fa-check"></i><b>3</b> Manipulación y agrupación de datos</a><ul>
<li class="chapter" data-level="3.1" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html"><i class="fa fa-check"></i><b>3.1</b> Transformación de datos</a><ul>
<li><a href="transformacion-de-datos.html#separa-aplica-combina-split-apply-combine">Separa-aplica-combina (<em>split-apply-combine</em>)</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ejemplos-y-lectura-de-datos"><i class="fa fa-check"></i>Ejemplos y lectura de datos</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#filtrar"><i class="fa fa-check"></i>Filtrar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#seleccionar"><i class="fa fa-check"></i>Seleccionar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#ordenar"><i class="fa fa-check"></i>Ordenar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#mutar"><i class="fa fa-check"></i>Mutar</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#summarise-y-resumenes-por-grupo"><i class="fa fa-check"></i>Summarise y resúmenes por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#operador-pipeline"><i class="fa fa-check"></i>Operador pipeline</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#variables-por-grupo"><i class="fa fa-check"></i>Variables por grupo</a></li>
<li class="chapter" data-level="" data-path="transformacion-de-datos.html"><a href="transformacion-de-datos.html#verbos-de-dos-tablas"><i class="fa fa-check"></i>Verbos de dos tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="datos-limpios.html"><a href="datos-limpios.html"><i class="fa fa-check"></i><b>3.2</b> Datos limpios</a><ul>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#limpieza-bases-de-datos"><i class="fa fa-check"></i>Limpieza bases de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#los-encabezados-de-las-columanas-son-valores"><i class="fa fa-check"></i>Los encabezados de las columanas son valores</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-columna-asociada-a-mas-de-una-variable"><i class="fa fa-check"></i>Una columna asociada a más de una variable</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#variables-almacenadas-en-filas-y-columnas"><i class="fa fa-check"></i>Variables almacenadas en filas y columnas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#mas-de-un-tipo-de-observacion-en-una-misma-tabla"><i class="fa fa-check"></i>Mas de un tipo de observación en una misma tabla</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#una-misma-unidad-observacional-esta-almacenada-en-multiples-tablas"><i class="fa fa-check"></i>Una misma unidad observacional está almacenada en múltiples tablas</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#otras-consideraciones"><i class="fa fa-check"></i>Otras consideraciones</a></li>
<li class="chapter" data-level="" data-path="datos-limpios.html"><a href="datos-limpios.html#recursos-adicionales"><i class="fa fa-check"></i>Recursos adicionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="temas-selectos-de-r.html"><a href="temas-selectos-de-r.html"><i class="fa fa-check"></i><b>4</b> Temas selectos de R</a><ul>
<li class="chapter" data-level="4.1" data-path="funciones.html"><a href="funciones.html"><i class="fa fa-check"></i><b>4.1</b> Funciones</a><ul>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#estructura-de-una-funcion"><i class="fa fa-check"></i>Estructura de una función</a></li>
<li class="chapter" data-level="" data-path="funciones.html"><a href="funciones.html#observaciones-del-uso-de-funciones"><i class="fa fa-check"></i>Observaciones del uso de funciones</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="vectores.html"><a href="vectores.html"><i class="fa fa-check"></i><b>4.2</b> Vectores</a><ul>
<li class="chapter" data-level="" data-path="vectores.html"><a href="vectores.html#propiedades"><i class="fa fa-check"></i>Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="iteracion.html"><a href="iteracion.html"><i class="fa fa-check"></i><b>4.3</b> Iteración</a></li>
<li class="chapter" data-level="4.4" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html"><i class="fa fa-check"></i><b>4.4</b> Rendimiento en R</a><ul>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#diagnosticar"><i class="fa fa-check"></i>Diagnosticar</a></li>
<li class="chapter" data-level="" data-path="rendimiento-en-r.html"><a href="rendimiento-en-r.html#estrategias-para-mejorar-desempeno"><i class="fa fa-check"></i>Estrategias para mejorar desempeño</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduccion-a-probabilidad.html"><a href="introduccion-a-probabilidad.html"><i class="fa fa-check"></i><b>5</b> Introducción a probabilidad</a><ul>
<li class="chapter" data-level="5.1" data-path="probabilidad-como-extension-a-proporcion.html"><a href="probabilidad-como-extension-a-proporcion.html"><i class="fa fa-check"></i><b>5.1</b> Probabilidad como extensión a proporción</a></li>
<li class="chapter" data-level="5.2" data-path="interpretacion-frecuentista-de-probabilidad.html"><a href="interpretacion-frecuentista-de-probabilidad.html"><i class="fa fa-check"></i><b>5.2</b> Interpretación frecuentista de probabilidad</a></li>
<li class="chapter" data-level="5.3" data-path="simulacion-para-el-calculo-de-probabilidades.html"><a href="simulacion-para-el-calculo-de-probabilidades.html"><i class="fa fa-check"></i><b>5.3</b> Simulación para el cálculo de probabilidades</a></li>
<li class="chapter" data-level="5.4" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html"><i class="fa fa-check"></i><b>5.4</b> Probabilidad: definición matemática</a><ul>
<li class="chapter" data-level="5.4.1" data-path="probabilidad-definicion-matematica.html"><a href="probabilidad-definicion-matematica.html#propiedades-de-la-funcion-de-probabilidad"><i class="fa fa-check"></i><b>5.4.1</b> Propiedades de la función de probabilidad:</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variables-aleatorias.html"><a href="variables-aleatorias.html"><i class="fa fa-check"></i><b>5.5</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="bootstrap-no-parametrico.html"><a href="bootstrap-no-parametrico.html"><i class="fa fa-check"></i><b>6</b> Bootstrap no paramétrico</a><ul>
<li class="chapter" data-level="6.1" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html"><i class="fa fa-check"></i><b>6.1</b> El principio del plug-in</a><ul>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#muestras-aleatorias"><i class="fa fa-check"></i>Muestras aleatorias</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#funcion-de-distribucion-empirica"><i class="fa fa-check"></i>Función de distribución empírica</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#parametros-y-estadisticas"><i class="fa fa-check"></i>Parámetros y estadísticas</a></li>
<li class="chapter" data-level="" data-path="el-principio-del-plug-in.html"><a href="el-principio-del-plug-in.html#distribuciones-muestrales-y-errores-estandar"><i class="fa fa-check"></i>Distribuciones muestrales y errores estándar</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html"><i class="fa fa-check"></i><b>6.2</b> El estimador bootstrap del error estándar</a><ul>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#variacion-en-distribuciones-bootstrap"><i class="fa fa-check"></i>Variación en distribuciones bootstrap</a></li>
<li class="chapter" data-level="" data-path="el-estimador-bootstrap-del-error-estandar.html"><a href="el-estimador-bootstrap-del-error-estandar.html#mas-alla-de-muestras-aleatorias-simples"><i class="fa fa-check"></i>Más alla de muestras aleatorias simples</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>6.3</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="6.4" data-path="bootstrap-en-r.html"><a href="bootstrap-en-r.html"><i class="fa fa-check"></i><b>6.4</b> Bootstrap en R</a></li>
<li class="chapter" data-level="6.5" data-path="conclusiones-y-observaciones.html"><a href="conclusiones-y-observaciones.html"><i class="fa fa-check"></i><b>6.5</b> Conclusiones y observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="teoria-basica-de-simulacion.html"><a href="teoria-basica-de-simulacion.html"><i class="fa fa-check"></i><b>7</b> Teoría básica de simulación</a><ul>
<li class="chapter" data-level="7.1" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html"><i class="fa fa-check"></i><b>7.1</b> Números pseudoaleatorios</a><ul>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#generadores-congruenciales-y-mersenne-twister"><i class="fa fa-check"></i>Generadores congruenciales y Mersenne-Twister</a></li>
<li class="chapter" data-level="" data-path="numeros-pseudoaleatorios.html"><a href="numeros-pseudoaleatorios.html#pruebas-de-aleatoriedad"><i class="fa fa-check"></i>Pruebas de aleatoriedad</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html"><i class="fa fa-check"></i><b>7.2</b> Variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-discretas-importantes"><i class="fa fa-check"></i>Familias discretas importantes</a></li>
<li class="chapter" data-level="" data-path="variables-aleatorias-1.html"><a href="variables-aleatorias-1.html#familias-continuas-importantes"><i class="fa fa-check"></i>Familias Continuas importantes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html"><i class="fa fa-check"></i><b>7.3</b> Simulación de variables aleatorias</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aletaorias-discretas"><i class="fa fa-check"></i>Variables aletaorias discretas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
<li class="chapter" data-level="7.3.1" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>7.3.1</b> Variables aleatorias continuas</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-variables-aleatorias.html"><a href="simulacion-de-variables-aleatorias.html#aceptacion-y-rechazo-1"><i class="fa fa-check"></i>Aceptación y rechazo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html"><i class="fa fa-check"></i><b>8</b> Simulación de modelos</a><ul>
<li class="chapter" data-level="" data-path="simulacion-de-modelos.html"><a href="simulacion-de-modelos.html#para-que-simular-de-un-modelo"><i class="fa fa-check"></i>¿Para qué simular de un modelo?</a></li>
<li class="chapter" data-level="8.1" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html"><i class="fa fa-check"></i><b>8.1</b> Distribuciones multivariadas</a><ul>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#regla-de-bayes"><i class="fa fa-check"></i>Regla de Bayes</a></li>
<li class="chapter" data-level="" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#independencia"><i class="fa fa-check"></i>Independencia</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="modelos-graficos-y-simulacion-predictiva.html"><a href="modelos-graficos-y-simulacion-predictiva.html"><i class="fa fa-check"></i><b>8.2</b> Modelos gráficos y simulación predictiva</a></li>
<li class="chapter" data-level="8.3" data-path="inferencia-visual.html"><a href="inferencia-visual.html"><i class="fa fa-check"></i><b>8.3</b> Inferencia visual</a><ul>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia"><i class="fa fa-check"></i>Inferencia</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#protocolos-de-inferencia-visual"><i class="fa fa-check"></i>Protocolos de inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#pruebas-de-hipotesis-tipicas"><i class="fa fa-check"></i>Pruebas de hipótesis típicas</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#inferencia-visual-1"><i class="fa fa-check"></i>Inferencia visual</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#mas-alla-que-permutacion"><i class="fa fa-check"></i>Más allá que permutación</a></li>
<li class="chapter" data-level="" data-path="inferencia-visual.html"><a href="inferencia-visual.html#otras-consideraciones-1"><i class="fa fa-check"></i>Otras consideraciones</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><a href="simulacion-para-calculo-de-tamano-de-muestrapoder-estadistico.html"><i class="fa fa-check"></i><b>8.4</b> Simulación para cálculo de tamaño de muestra/poder estadístico</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="inferencia-parametrica.html"><a href="inferencia-parametrica.html"><i class="fa fa-check"></i><b>9</b> Inferencia paramétrica</a><ul>
<li class="chapter" data-level="9.1" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html"><i class="fa fa-check"></i><b>9.1</b> Máxima verosimilitud</a><ul>
<li class="chapter" data-level="" data-path="maxima-verosimilitud.html"><a href="maxima-verosimilitud.html#propiedades-de-los-estimadores-de-maxima-verosimilitud"><i class="fa fa-check"></i>Propiedades de los estimadores de máxima verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="bootstrap-parametrico.html"><a href="bootstrap-parametrico.html"><i class="fa fa-check"></i><b>9.2</b> Bootstrap paramétrico</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tareas.html"><a href="tareas.html"><i class="fa fa-check"></i>Tareas</a><ul>
<li class="chapter" data-level="" data-path="transformacion-de-datos-1.html"><a href="transformacion-de-datos-1.html"><i class="fa fa-check"></i>2-Transformación de datos</a></li>
<li class="chapter" data-level="" data-path="datos-limpios-1.html"><a href="datos-limpios-1.html"><i class="fa fa-check"></i>3-Datos Limpios</a></li>
<li class="chapter" data-level="" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i>4-Probabilidad</a></li>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html"><i class="fa fa-check"></i>5-Bootstrap</a><ul>
<li class="chapter" data-level="" data-path="bootstrap.html"><a href="bootstrap.html#solucion"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html"><i class="fa fa-check"></i>6-Cobertura de intervalos de confianza</a><ul>
<li class="chapter" data-level="" data-path="cobertura-de-intervalos-de-confianza.html"><a href="cobertura-de-intervalos-de-confianza.html#solucion-1"><i class="fa fa-check"></i>Solución</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-1.html"><a href="simulacion-de-modelos-1.html"><i class="fa fa-check"></i>7-Simulación de modelos</a></li>
<li class="chapter" data-level="" data-path="simulacion-de-modelos-de-regresion.html"><a href="simulacion-de-modelos-de-regresion.html"><i class="fa fa-check"></i>8-Simulación de modelos de regresión</a></li>
<li class="chapter" data-level="" data-path="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><a href="inferencia-grafica-tamano-de-muestra-bootstrap-parametrico-.html"><i class="fa fa-check"></i>9 - Inferencia gráfica, tamaño de muestra, bootstrap paramétrico.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística Computacional</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="el-estimador-bootstrap-del-error-estandar" class="section level2">
<h2><span class="header-section-number">6.2</span> El estimador bootstrap del error estándar</h2>
<p>Entonces, los pasos para calcular estimador bootstrap del error estándar son:</p>
<p>Tenemos una muestra aleatoria <span class="math inline">\(\textbf{x}=(x_1,x_2,...,x_n)\)</span>
proveniente de una distribución de probabilidad desconocida <span class="math inline">\(P\)</span>,</p>
<ul>
<li><p>Seleccionamos muestras aleatorias con reemplazo de la distribución empírica.</p></li>
<li><p>Calculamos la estadística de interés para cada muestra:
<span class="math display">\[\hat{\theta}=s(\textbf{x})\]</span>
la estimación puede ser la estimación <em>plug-in</em> <span class="math inline">\(t(P_n)\)</span> pero también puede
ser otra.</p></li>
<li><p>La distribución de la estadística es la distribución bootstrap, y el estimador
bootstrap del error estándar es la desviación estándar de la distribución
bootstrap.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">dist_empirica &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">id =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">30</span>, <span class="dt">obs =</span> samples<span class="op">$</span>sims[[<span class="dv">1</span>]])

dist_empirica_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(dist_empirica, <span class="kw">aes</span>(<span class="dt">x =</span> obs)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">fill =</span> <span class="st">&quot;darkgray&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;mu&quot;</span>, <span class="dt">xintercept =</span> <span class="dv">5</span>), <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> samples<span class="op">$</span>x_bar[<span class="dv">1</span>], <span class="dt">color =</span> <span class="st">&quot;x_bar&quot;</span>), 
        <span class="dt">alpha =</span> <span class="fl">0.8</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">xlim</span>(<span class="op">-</span><span class="dv">15</span>, <span class="dv">20</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="st">&quot;Distribución empírica&quot;</span><span class="op">~</span>P[n])) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_colour_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&#39;mu&#39;</span> =<span class="st"> &#39;red&#39;</span>, <span class="st">&#39;x_bar&#39;</span> =<span class="st"> &#39;blue&#39;</span>), <span class="dt">name =</span> <span class="st">&#39;&#39;</span>, 
        <span class="dt">labels =</span> <span class="kw">c</span>(<span class="kw">expression</span>(mu), <span class="kw">expression</span>(<span class="kw">bar</span>(x)))) 
    
samples_boot &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">sample_boot =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(
        <span class="dt">sims_boot =</span> <span class="kw">rerun</span>(<span class="dv">3</span>, <span class="kw">sample</span>(dist_empirica<span class="op">$</span>obs, <span class="dt">replace =</span> <span class="ot">TRUE</span>)), 
        <span class="dt">x_bar_boot =</span> <span class="kw">map_dbl</span>(sims_boot, mean))

muestras_boot_plot &lt;-<span class="st"> </span>samples_boot <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">unnest</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sims_boot)) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">fill =</span> <span class="st">&quot;darkgray&quot;</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> samples<span class="op">$</span>x_bar[<span class="dv">1</span>]), <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>,
            <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x_bar_boot, <span class="dt">xend =</span> x_bar_boot, <span class="dt">y =</span> <span class="dv">0</span>, <span class="dt">yend =</span> <span class="fl">0.8</span>), 
            <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">xlim</span>(<span class="op">-</span><span class="dv">15</span>, <span class="dv">20</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>sample_boot) <span class="op">+</span>
<span class="st">        </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x_bar_boot, <span class="dt">y =</span> <span class="fl">0.95</span>, <span class="dt">label =</span> <span class="st">&quot;bar(x)^&#39;*&#39;&quot;</span>), 
            <span class="dt">parse =</span> <span class="ot">TRUE</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.3</span>, <span class="dt">hjust =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">        </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, <span class="dt">subtitle =</span> <span class="st">&quot;Muestras bootstrap&quot;</span>) 

boot_dist &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">sample =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(
        <span class="dt">sims_boot =</span> <span class="kw">rerun</span>(<span class="dv">10000</span>, <span class="kw">sample</span>(dist_empirica<span class="op">$</span>obs, <span class="dt">replace =</span> <span class="ot">TRUE</span>)), 
        <span class="dt">mu_hat_star =</span> <span class="kw">map_dbl</span>(sims_boot, mean))
boot_muestral_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(boot_dist, <span class="kw">aes</span>(<span class="dt">x =</span> mu_hat_star)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">fill =</span> <span class="st">&quot;darkgray&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;&quot;</span>, 
        <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="st">&quot;Distribución bootstrap de &quot;</span><span class="op">~</span><span class="kw">hat</span>(mu)<span class="op">^</span><span class="st">&#39;*&#39;</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">5</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> samples<span class="op">$</span>x_bar[<span class="dv">1</span>]), <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>, 
        <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>)

(dist_empirica_plot <span class="op">|</span><span class="st"> </span><span class="kw">plot_spacer</span>()) <span class="op">/</span><span class="st"> </span>(muestras_boot_plot <span class="op">|</span><span class="st"> </span>boot_muestral_plot) </code></pre>
<p><img src="imagenes/bootstrap_world.png" /></p>
<p>Describamos la notación y conceptos:</p>
<div class="caja">
<p>Definimos una <strong>muestra bootstrap</strong> como una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> que
se obtiene de la distribución empírica <span class="math inline">\(P_n\)</span> y la denotamos
<span class="math display">\[\textbf{x}^* = (x_1^*,...,x_n^*).\]</span></p>
</div>
<p>La notación de estrella indica que <span class="math inline">\(\textbf{x}^*\)</span> no son los datos <span class="math inline">\(\textbf{x}\)</span>
sino una versión de <strong>remuestreo</strong> de <span class="math inline">\(\textbf{x}\)</span>.</p>
<p>Otra manera de frasearlo: Los datos bootsrtap <span class="math inline">\(x_1^*,...,x_n^*\)</span> son una muestra
aleatoria de tamaño <span class="math inline">\(n\)</span> seleccionada con reemplazo de la población de <span class="math inline">\(n\)</span>
objetos <span class="math inline">\((x_1,...,x_n)\)</span>.</p>
<div class="caja">
<p>A cada muestra bootstrap <span class="math inline">\(\textbf{x}^*\)</span> le corresponde una replicación
<span class="math inline">\(\hat{\theta}^*=s(\textbf{x}^*).\)</span></p>
</div>
<p>el estimador bootstrap de <span class="math inline">\(se_P(\hat{\theta})\)</span> se define como:</p>
<p><span class="math display">\[se_{P_n}(\hat{\theta}^*)\]</span></p>
<p>en otras palabras, la estimación bootstrap de <span class="math inline">\(se_P(\hat{\theta})\)</span> es el error
estándar de <span class="math inline">\(\hat{\theta}\)</span> para conjuntos de datos de tamaño <span class="math inline">\(n\)</span> seleccionados
de manera aleatoria de <span class="math inline">\(P_n\)</span>.</p>
<p>La fórmula <span class="math inline">\(se_{P_n}(\hat{\theta}^*)\)</span> no existe para casi ninguna estimación
diferente de la media, por lo que recurrimos a la técnica computacional
bootstrap:</p>
<div class="caja">
<p><strong>Algoritmo bootstrap para estimar errores estándar</strong></p>
<ol style="list-style-type: decimal">
<li><p>Selecciona <span class="math inline">\(B\)</span> muestras bootstrap independientes:
<span class="math display">\[\textbf{x}^{*1},..., \textbf{x}^{*B}\]</span>.</p></li>
<li><p>Evalúa la replicación bootstrap correspondiente a cada muestra bootstrap:
<span class="math display">\[\hat{\theta}^{*b}=s(\textbf{x}^{*b})\]</span>
para <span class="math inline">\(b=1,2,...,B.\)</span></p></li>
<li><p>Estima el error estándar <span class="math inline">\(se_P(\hat{\theta})\)</span> usando la desviación estándar
muestral de las <span class="math inline">\(B\)</span> replicaciones:
<span class="math display">\[\hat{se}_B = \bigg\{\frac{\sum_{b=1}^B[\hat{\theta}^{*}(b)-\hat{\theta}^*(\cdot)]^2 }{B-1}\bigg\}^{1/2}\]</span></p></li>
</ol>
donde <span class="math display">\[\hat{\theta}^*(\cdot)=\sum_{b=1}^B \theta^{*}(b)/B \]</span>.
</p>
</div>
<p>Notemos que:</p>
<ul>
<li><p>La estimación bootstrap de <span class="math inline">\(se_{P}(\hat{\theta})\)</span>, el error estándar
de una estadística <span class="math inline">\(\hat{\theta}\)</span>, es un estimador <em>plug-in</em> que usa la
función de distribución empírica <span class="math inline">\(P_n\)</span> en lugar de la distribución desconocida
<span class="math inline">\(P\)</span>.</p></li>
<li><p>Conforme el número de replicaciones <span class="math inline">\(B\)</span> aumenta
<span class="math display">\[\hat{se}_B\approx se_{P_n}(\hat{\theta})\]</span>
este hecho equivale a decir que la desviación estándar empírica se acerca a
la desviación estándar poblacional conforme crece el número de muestras. La
<em>población</em> en este caso es la población de valores <span class="math inline">\(\hat{\theta}^*=s(x^*)\)</span>.</p></li>
<li><p>Al estimador de bootstrap ideal <span class="math inline">\(se_{P_n}(\hat{\theta})\)</span> y su aproximación
<span class="math inline">\(\hat{se}_B\)</span> se les denota <strong>estimadores bootstrap no paramétricos</strong> ya que
estan basados en <span class="math inline">\(P_n\)</span>, el estimador no paramétrico de la población <span class="math inline">\(P\)</span>.</p></li>
</ul>
<div id="ejemplo-error-estandar-bootstrap-de-una-media" class="section level4 unnumbered">
<h4>Ejemplo: Error estándar bootstrap de una media</h4>
<pre class="sourceCode r"><code class="sourceCode r">mediaBoot &lt;-<span class="st"> </span><span class="cf">function</span>(x){ 
  <span class="co"># x: variable de interés</span>
  <span class="co"># n: número de replicaciones bootstrap</span>
  n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
  muestra_boot &lt;-<span class="st"> </span><span class="kw">sample</span>(x, <span class="dt">size =</span> n, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
  <span class="kw">mean</span>(muestra_boot) <span class="co"># replicacion bootstrap de theta_gorro</span>
}
thetas_boot &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">10000</span>, <span class="kw">mediaBoot</span>(primaria_muestra<span class="op">$</span>esp_<span class="dv">3</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">flatten_dbl</span>()
<span class="kw">sd</span>(thetas_boot)
<span class="co">#&gt; [1] 3.8618</span></code></pre>
<p>y se compara con <span class="math inline">\(\hat{se}(\bar{x})\)</span> (estimador <em>plug-in</em> del error estándar):</p>
<pre class="sourceCode r"><code class="sourceCode r">se &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">sqrt</span>(<span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(x)
<span class="kw">se</span>(primaria_muestra<span class="op">$</span>esp_<span class="dv">3</span>)
<span class="co">#&gt; [1] 3.8466</span></code></pre>
<p><strong>Nota:</strong> Conforme <span class="math inline">\(B\)</span> aumenta <span class="math inline">\(\hat{se}_{B}(\bar{x})\to \{\sum_{i=1}^n(x_i - \bar{x})^2 / n \}^{1/2}\)</span>,
se demuestra con la ley débil de los grandes números.</p>
<p><img src="imagenes/manicule2.jpg" /> Considera el coeficiente de correlación muestral
entre la calificación de <span class="math inline">\(y=\)</span>esp_3 y la de <span class="math inline">\(z=\)</span>esp_6:
<span class="math inline">\(\hat{corr}(y,z)=0.9\)</span>. ¿Qué tan precisa es esta estimación?</p>
</div>
<div id="variacion-en-distribuciones-bootstrap" class="section level3 unnumbered">
<h3>Variación en distribuciones bootstrap</h3>
<p>En el proceso de estimación bootstrap hay dos fuentes de variación pues:</p>
<ul>
<li><p>La muestra original se selecciona con aleatoriedad de una población.</p></li>
<li><p>Las muestras bootstrap se seleccionan con aleatoriedad de la muestra
original. Esto es: <em>La estimación bootstrap ideal es un resultado asintótico
<span class="math inline">\(B=\infty\)</span>, en esta caso <span class="math inline">\(\hat{se}_B\)</span> iguala la estimación <em>plug-in</em>
<span class="math inline">\(se_{P_n}\)</span>.</em></p></li>
</ul>
<p>En el proceso de <em>bootstrap</em> podemos controlar la variación del sgundo aspecto,
conocida como <strong>implementación de muestreo Monte Carlo</strong>, y la variación
Monte Carlo decrece conforme incrementamos el número de muestras.</p>
<p>Podemos eliminar la variación Monte Carlo si seleccionamos todas las posibles
muestras con reemplazo de tamaño <span class="math inline">\(n\)</span>, hay <span class="math inline">\({2n-1}\choose{n}\)</span> posibles muestras
y si seleccionamos todas obtenemos <span class="math inline">\(\hat{se}_\infty\)</span> (bootstrap ideal), sin
embargo, en la mayor parte de los problemas no es factible proceder así.</p>
<!--
* En la práctica para elegir el tamaño de $B$ debemos considerar que buscamos 
las mismas propiedades para la estimación de un error estándar que para 
cualquier estimación: poco sesgo y desviación estándar chica. El sesgo de la 
estifmación bootstrap del error estándar suele ser bajo y el error estándar está

 Una respuesta aproximada es en términos del coeficiente de variación de 
$\hat{se}_B$, esto es el cociente de la desviación estándar de $\hat{se}_B$ y su 
valor esperado, la variabilidad adicional de parar en $B$ replicaciones en lugar 
de seguir hasta infiniti se refleja en un incremento en el coeficiente de 
variación
-->
<p>Entonces, ¿cuántas muestras bootstrap?</p>
<ol style="list-style-type: decimal">
<li><p>Incluso un número chico de replicaciones bootstrap, digamos <span class="math inline">\(B=25\)</span> es
informativo, y <span class="math inline">\(B=50\)</span> con frecuencia es suficiente para dar una buena
estimación de <span class="math inline">\(se_P(\hat{\theta})\)</span> (<span class="citation">Efron and Tibshirani (<a href="#ref-efron">1993</a>)</span>).</p></li>
<li><p>Cuando se busca estimar error estándar <span class="citation">Hesterberg (<a href="#ref-tim">2015</a>)</span> recomienda <span class="math inline">\(B=1000\)</span> muestras, o
<span class="math inline">\(B=10,000\)</span> muestras dependiendo la presición que se busque.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">seMediaBoot &lt;-<span class="st"> </span><span class="cf">function</span>(x, B){
    thetas_boot &lt;-<span class="st"> </span><span class="kw">rerun</span>(B, <span class="kw">mediaBoot</span>(x)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">flatten_dbl</span>()
    <span class="kw">sd</span>(thetas_boot)
}

B_muestras &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">n_sims =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">400</span>, <span class="dv">1000</span>, <span class="dv">1500</span>, <span class="dv">3000</span>, 
    <span class="dv">5000</span>, <span class="dv">10000</span>, <span class="dv">20000</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">est =</span> <span class="kw">map_dbl</span>(n_sims, <span class="op">~</span><span class="kw">seMediaBoot</span>(<span class="dt">x =</span> primaria_muestra<span class="op">$</span>esp_<span class="dv">3</span>, <span class="dt">B =</span> .)))
B_muestras
<span class="co">#&gt; # A tibble: 12 x 2</span>
<span class="co">#&gt;    n_sims   est</span>
<span class="co">#&gt;     &lt;dbl&gt; &lt;dbl&gt;</span>
<span class="co">#&gt;  1      5  2.44</span>
<span class="co">#&gt;  2     25  3.41</span>
<span class="co">#&gt;  3     50  3.51</span>
<span class="co">#&gt;  4    100  3.91</span>
<span class="co">#&gt;  5    200  3.51</span>
<span class="co">#&gt;  6    400  3.95</span>
<span class="co">#&gt;  7   1000  4.03</span>
<span class="co">#&gt;  8   1500  3.79</span>
<span class="co">#&gt;  9   3000  3.86</span>
<span class="co">#&gt; 10   5000  3.88</span>
<span class="co">#&gt; 11  10000  3.83</span>
<span class="co">#&gt; 12  20000  3.86</span></code></pre>
<div id="ejemplo-componentes-principales-calificaciones-en-examenes" class="section level4 unnumbered">
<h4>Ejemplo componentes principales: calificaciones en exámenes</h4>
<p>Los datos <em>marks</em> (Mardia, Kent y Bibby, 1979) contienen los puntajes de 88
estudiantes en 5 pruebas: mecánica, vectores, álgebra, análisis y estadística.
Cada renglón corresponde a la calificación de un estudiante en cada prueba.</p>
<pre class="sourceCode r"><code class="sourceCode r">marks &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/marks.csv&quot;</span>)
<span class="co">#&gt; Parsed with column specification:</span>
<span class="co">#&gt; cols(</span>
<span class="co">#&gt;   id = col_integer(),</span>
<span class="co">#&gt;   MECH = col_integer(),</span>
<span class="co">#&gt;   VECT = col_integer(),</span>
<span class="co">#&gt;   ALG = col_integer(),</span>
<span class="co">#&gt;   ANL = col_integer(),</span>
<span class="co">#&gt;   STAT = col_integer()</span>
<span class="co">#&gt; )</span>
<span class="kw">glimpse</span>(marks)
<span class="co">#&gt; Observations: 88</span>
<span class="co">#&gt; Variables: 6</span>
<span class="co">#&gt; $ id   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...</span>
<span class="co">#&gt; $ MECH &lt;int&gt; 77, 63, 75, 55, 63, 53, 51, 59, 62, 64, 52, 55, 50, 65, 3...</span>
<span class="co">#&gt; $ VECT &lt;int&gt; 82, 78, 73, 72, 63, 61, 67, 70, 60, 72, 64, 67, 50, 63, 5...</span>
<span class="co">#&gt; $ ALG  &lt;int&gt; 67, 80, 71, 63, 65, 72, 65, 68, 58, 60, 60, 59, 64, 58, 6...</span>
<span class="co">#&gt; $ ANL  &lt;int&gt; 67, 70, 66, 70, 70, 64, 65, 62, 62, 62, 63, 62, 55, 56, 5...</span>
<span class="co">#&gt; $ STAT &lt;int&gt; 81, 81, 81, 68, 63, 73, 68, 56, 70, 45, 54, 44, 63, 37, 7...</span>
marks &lt;-<span class="st"> </span><span class="kw">select</span>(marks, <span class="op">-</span>id)</code></pre>
<p>Entonces un análisis de componentes principales proseguiría como sigue:</p>
<pre class="sourceCode r"><code class="sourceCode r">pc_marks &lt;-<span class="st"> </span><span class="kw">princomp</span>(marks)
<span class="kw">summary</span>(pc_marks)
<span class="co">#&gt; Importance of components:</span>
<span class="co">#&gt;                          Comp.1   Comp.2    Comp.3   Comp.4   Comp.5</span>
<span class="co">#&gt; Standard deviation     26.06114 14.13557 10.127604 9.147061 5.638077</span>
<span class="co">#&gt; Proportion of Variance  0.61912  0.18214  0.093497 0.076269 0.028977</span>
<span class="co">#&gt; Cumulative Proportion   0.61912  0.80126  0.894755 0.971023 1.000000</span>
<span class="kw">loadings</span>(pc_marks)
<span class="co">#&gt; </span>
<span class="co">#&gt; Loadings:</span>
<span class="co">#&gt;      Comp.1 Comp.2 Comp.3 Comp.4 Comp.5</span>
<span class="co">#&gt; MECH  0.505  0.749  0.300  0.296       </span>
<span class="co">#&gt; VECT  0.368  0.207 -0.416 -0.783  0.189</span>
<span class="co">#&gt; ALG   0.346        -0.145        -0.924</span>
<span class="co">#&gt; ANL   0.451 -0.301 -0.597  0.518  0.286</span>
<span class="co">#&gt; STAT  0.535 -0.548  0.600 -0.176  0.151</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                Comp.1 Comp.2 Comp.3 Comp.4 Comp.5</span>
<span class="co">#&gt; SS loadings       1.0    1.0    1.0    1.0    1.0</span>
<span class="co">#&gt; Proportion Var    0.2    0.2    0.2    0.2    0.2</span>
<span class="co">#&gt; Cumulative Var    0.2    0.4    0.6    0.8    1.0</span>
<span class="kw">plot</span>(pc_marks, <span class="dt">type =</span> <span class="st">&quot;lines&quot;</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/pc-1.png" width="384" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">biplot</span>(pc_marks)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Los cálculos de un análisis de componentes principales involucran la matriz de
covarianzas empírica <span class="math inline">\(G\)</span> (estimaciones <em>plug-in</em>)</p>
<p><span class="math display">\[G_{jk} = \frac{1}{88}\sum_{i=1}^88(x_{ij}-\bar{x_j})(x_{ik}-\bar{x_k})\]</span></p>
<p>para <span class="math inline">\(j,k=1,2,3,4,5\)</span>, y donde <span class="math inline">\(\bar{x_j} = \sum_{i=1}^88 x_{ij} / 88\)</span> (la media
de la i-ésima columna).</p>
<pre class="sourceCode r"><code class="sourceCode r">G &lt;-<span class="st"> </span><span class="kw">cov</span>(marks) <span class="op">*</span><span class="st"> </span><span class="dv">87</span> <span class="op">/</span><span class="st"> </span><span class="dv">88</span>
G
<span class="co">#&gt;        MECH    VECT    ALG     ANL    STAT</span>
<span class="co">#&gt; MECH 302.29 125.777 100.43 105.065 116.071</span>
<span class="co">#&gt; VECT 125.78 170.878  84.19  93.597  97.887</span>
<span class="co">#&gt; ALG  100.43  84.190 111.60 110.839 120.486</span>
<span class="co">#&gt; ANL  105.07  93.597 110.84 217.876 153.768</span>
<span class="co">#&gt; STAT 116.07  97.887 120.49 153.768 294.372</span></code></pre>
<p>Los <em>pesos</em> y las <em>componentes principales</em> no son mas que los eigenvalores y
eigenvectores de la matriz de covarianzas <span class="math inline">\(G\)</span>, estos se calculan a través de una
serie de de manipulaciones algebraicas que requieren cálculos del orden de p^3
(cuando G es una matriz de tamaño p<span class="math inline">\(\times\)</span>p).</p>
<pre class="sourceCode r"><code class="sourceCode r">eigen_G &lt;-<span class="st"> </span><span class="kw">eigen</span>(G)
lambda &lt;-<span class="st"> </span>eigen_G<span class="op">$</span>values
v &lt;-<span class="st"> </span>eigen_G<span class="op">$</span>vectors
lambda
<span class="co">#&gt; [1] 679.183 199.814 102.568  83.669  31.788</span>
v
<span class="co">#&gt;          [,1]      [,2]     [,3]       [,4]      [,5]</span>
<span class="co">#&gt; [1,] -0.50545  0.748748  0.29979  0.2961843 -0.079394</span>
<span class="co">#&gt; [2,] -0.36835  0.207403 -0.41559 -0.7828882 -0.188876</span>
<span class="co">#&gt; [3,] -0.34566 -0.075908 -0.14532 -0.0032363  0.923920</span>
<span class="co">#&gt; [4,] -0.45112 -0.300888 -0.59663  0.5181397 -0.285522</span>
<span class="co">#&gt; [5,] -0.53465 -0.547782  0.60028 -0.1757320 -0.151232</span></code></pre>
<ol style="list-style-type: decimal">
<li>Proponemos el siguiente modelo simple para puntajes correlacionados:</li>
</ol>
<p><span class="math display">\[\textbf{x}_i = Q_i \textbf{v}\]</span></p>
<p>donde <span class="math inline">\(\textbf{x}_i\)</span> es la tupla de calificaciones del i-ésimo estudiante,
<span class="math inline">\(Q_i\)</span> es un número que representa la habilidad del estudiante y <span class="math inline">\(\textbf{v}\)</span> es
un vector fijo con 5 números que aplica a todos los estudiantes. Si este modelo
simple fuera cierto, entonces únicamente el <span class="math inline">\(\hat{\lambda}_1\)</span> sería positivo
y <span class="math inline">\(\textbf{v} = \hat{v}_1\)</span>.
Sea <span class="math display">\[\hat{\theta}=\sum_{i=1}^5\hat{\lambda}_i\]</span>
el modelo propuesto es equivalente a <span class="math inline">\(\hat{\theta}=1\)</span>, inculso si el modelo es
correcto, no esperamos que <span class="math inline">\(\hat{\theta}\)</span> sea exactamente uno pues hay ruido en
los datos.</p>
<pre class="sourceCode r"><code class="sourceCode r">theta_hat &lt;-<span class="st"> </span>lambda[<span class="dv">1</span>]<span class="op">/</span><span class="kw">sum</span>(lambda)
theta_hat
<span class="co">#&gt; [1] 0.61912</span></code></pre>
<p>El valor de <span class="math inline">\(\hat{\theta}\)</span> mide el porcentaje de la varianza explicada en la
primer componente principal, ¿qué tan preciso es <span class="math inline">\(\hat{\theta}\)</span>? La complejidad
matemática en el cálculo de <span class="math inline">\(\hat{\theta}\)</span> es irrelevante siempre y cuando
podamos calcular <span class="math inline">\(\hat{\theta}^*\)</span> para una muestra bootstrap, en esta caso una
muestra bootsrtap es una base de datos de 88$$5 <span class="math inline">\(\textbf{X}^*\)</span>, donde las
filas <span class="math inline">\(\textbf{x_i}^*\)</span> de <span class="math inline">\(\textbf{X}^*\)</span> son una muestra aleatoria de tamaño
88 de la verdadera matriz de datos.</p>
<pre class="sourceCode r"><code class="sourceCode r">pc_boot &lt;-<span class="st"> </span><span class="cf">function</span>(){
    muestra_boot &lt;-<span class="st"> </span><span class="kw">sample_n</span>(marks, <span class="dt">size =</span> <span class="dv">88</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)
    G &lt;-<span class="st"> </span><span class="kw">cov</span>(muestra_boot) <span class="op">*</span><span class="st"> </span><span class="dv">87</span> <span class="op">/</span><span class="st"> </span><span class="dv">88</span> 
    eigen_G &lt;-<span class="st"> </span><span class="kw">eigen</span>(G)
    theta_hat &lt;-<span class="st"> </span>eigen_G<span class="op">$</span>values[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(eigen_G<span class="op">$</span>values)
}
B &lt;-<span class="st"> </span><span class="dv">1000</span>
thetas_boot &lt;-<span class="st"> </span><span class="kw">rerun</span>(B, <span class="kw">pc_boot</span>()) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">flatten_dbl</span>()</code></pre>
<p>Veamos un histograma de las replicaciones de <span class="math inline">\(\hat{\theta}\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">data_frame</span>(<span class="dt">theta =</span> thetas_boot)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> theta, <span class="dt">y =</span> ..density..), <span class="dt">binwidth =</span> <span class="fl">0.02</span>, <span class="dt">fill =</span> <span class="st">&quot;gray40&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(theta)), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(<span class="kw">hat</span>(theta)<span class="op">^</span><span class="st">&quot;*&quot;</span>), <span class="dt">y =</span> <span class="st">&quot;&quot;</span>)</code></pre>
<p><img src="05-bootstrap_no_parametrico_files/figure-html/pc_hist-1.png" width="300px" /></p>
<p>Estas tienen un error estándar</p>
<pre class="sourceCode r"><code class="sourceCode r">theta_se &lt;-<span class="st"> </span><span class="kw">sd</span>(thetas_boot)
theta_se
<span class="co">#&gt; [1] 0.048405</span></code></pre>
<p>y media</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(thetas_boot)
<span class="co">#&gt; [1] 0.61904</span></code></pre>
<p>la media de las replicaciones es muy similar a la estimación <span class="math inline">\(\hat{\theta}\)</span>,
esto indica que <span class="math inline">\(\hat{\theta}\)</span> es cercano a insesgado.</p>
<ol start="2" style="list-style-type: decimal">
<li>El eigenvetor <span class="math inline">\(\hat{v}_1\)</span> correspondiente al mayor eigenvalor se conoce
como primera componente de <span class="math inline">\(G\)</span>, supongamos que deseamos resumir la calificación
de los estudiantes mediante un único número, entonces la mejor combinación
lineal de los puntajes es</li>
</ol>
<p><span class="math display">\[y_i = \sum_{k = 1}^5 \hat{v}_{1k}x_{ik}\]</span></p>
<p>esto es, la combinación lineal que utiliza las componentes de <span class="math inline">\(\hat{v}_1\)</span> como
ponderadores. Si queremos un resumen compuesto por dos números <span class="math inline">\((y_i,z_i)\)</span>, la
segunda combinación lineal debería ser:</p>
<p><span class="math display">\[z_i = \sum_{k = 1}^5 \hat{v}_{2k}x_{ik}\]</span></p>
<p><img src="../imagenes/manicule2.jpg" /> Las componentes principales <span class="math inline">\(\hat{v}_1\)</span> y
<span class="math inline">\(\hat{v}_2\)</span> son estadísticos, usa bootstrap para dar una medición de su
variabilidad calculando el error estándar de cada una.</p>
</div>
</div>
<div id="mas-alla-de-muestras-aleatorias-simples" class="section level3 unnumbered">
<h3>Más alla de muestras aleatorias simples</h3>
<p>Introdujimos el bootstrap en el contexto de muestras aleatorias, esto es,
suponiendo que las observaciones son independientes; en este escenario basta con
aproximar la distribución desconocida <span class="math inline">\(P\)</span> usando la dsitribución empírica <span class="math inline">\(P_n\)</span>,
y el cálculo de los estadísticos es inmediato. Hay casos en los que el mecanismo
que generó los datos es más complicado, por ejemplo, cuando tenemos dos
muestras, en diseños de encuestas complejas o en series de
tiempo.</p>
<div id="ejemplo-dos-muestras" class="section level4 unnumbered">
<h4>Ejemplo: Dos muestras</h4>
<p>En el ejemplo de experimentos clínicos de aspirina y ataques de de corazón,
podemos pensar el modelo probabilístico <span class="math inline">\(P\)</span> como compuesto por dos
distribuciones de probabilidad <span class="math inline">\(G\)</span> y <span class="math inline">\(Q\)</span> una correspondiente al grupo control y
otra al grupo de tratamiento, entonces las observaciones de
cada grupo provienen de distribuciones distintas y el método bootstrap debe
tomar en cuenta esto al generar las muestras, en este caso implica seleccionar
muesreas de manera independiente dentro de cada grupo.</p>
</div>
<div id="ejemplo-bootstrap-en-muestreo-de-encuestas" class="section level4 unnumbered">
<h4>Ejemplo: Bootstrap en muestreo de encuestas</h4>
<p>La necesidad de estimaciones confiables junto con el uso eficiente de recursos
conllevan a diseños de muestras complejas. Estos diseños típicamente usan las
siguientes técnicas: muestreo sin reemplazo de una población finita, muestreo
sistemático, estratificación, conglomerados, ajustes a no-respuesta,
postestratificación. Como consecuencia, los valores de la muestra suelen no ser
independientes.</p>
<p>La complejidad de los diseños de encuestas conlleva a que el cálculo de errores
estándar sea muy complicado, para atacar este problema hay dos técnicas básicas:
1) un enfoque analítico usando linearización, 2) métodos de remuestreo como
bootstrap. El incremento en el poder de cómputo ha favorecido los métodos de
remuestreo pues la linearización requiere del desarrollo de una fórmula para
cada estimación y supuestos adicionales para simplificar.</p>
<p>En 1988 <span class="citation">Rao and Wu (<a href="#ref-RaoWu">1988</a>)</span> propusieron un método de bootstrap para diseños
estratificados multietápicos con reemplazo de UPMs que describimos a
continuación.</p>
<p><strong>ENIGH</strong>. Usaremos como ejemplo la Encuesta Nacional de Ingresos y
Gastos de los Hogares, ENIGH 2014 <span class="citation">(INEGI <a href="#ref-enigh">2014</a>)</span>, esta encuesta usa un diseño de
conglomerados estratificado.</p>
<p>Antes de proceder a bootstrap debemos entender como se seleccionaron los datos,
esto es, el <a href="http://www.inegi.org.mx/prod_serv/contenidos/espanol/bvinegi/productos/metodologias/ENIGH/ENIGH2012/702825050597.pdf">diseño de la muestra</a>:</p>
<ol style="list-style-type: decimal">
<li><p>Unidad primaria de muestreo (UPM). Las UPMs están constituidas por
agrupaciones de viviendas. Se les denomina unidades primarias pues corresponden
a la primera etapa de selección, las unidades secundarias (USMs) serían los
hogares.</p></li>
<li><p>Estratificación. Los estratos se construyen en base a estado, ámbito (urbano,
complemento urbano, rural), características sociodemográficas de los habitantes
de las viviendas, características físicas y equipamiento. El proceso de
estratificación resulta en 888 subestratos en todo el ámbito nacional.</p></li>
<li><p>La selección de la muestra es independiente para cada estrato, y una
vez que se obtiene la muestra se calculan los factores de expansión que
reflejan las distintas probabilidades de selección. Después se llevan a cabo
ajustes por no respuesta y por proyección (calibración), esta última
busca que distintos dominios de la muestra coincidan con la proyección de
población de INEGI.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">concentrado_hogar &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/concentradohogar.csv&quot;</span>)
concentrado_hogar
<span class="co">#&gt; # A tibble: 19,479 x 132</span>
<span class="co">#&gt;    folioviv foliohog ubica_geo ageb  tam_loc est_socio est_dis upm  </span>
<span class="co">#&gt;    &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt;     &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;</span>
<span class="co">#&gt;  1 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  2 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  3 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  4 0100008…        1 010010001 028-6       1         4 005     00670</span>
<span class="co">#&gt;  5 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  6 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  7 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  8 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt;  9 0100010…        1 010010001 028-6       1         4 005     00600</span>
<span class="co">#&gt; 10 0100018…        1 010010001 029-0       1         3 004     00570</span>
<span class="co">#&gt; # ... with 19,469 more rows, and 124 more variables: factor_hog &lt;int&gt;,</span>
<span class="co">#&gt; #   clase_hog &lt;int&gt;, sexo_jefe &lt;int&gt;, edad_jefe &lt;int&gt;, educa_jefe &lt;chr&gt;,</span>
<span class="co">#&gt; #   tot_integ &lt;int&gt;, hombres &lt;int&gt;, mujeres &lt;int&gt;, mayores &lt;int&gt;,</span>
<span class="co">#&gt; #   menores &lt;int&gt;, p12_64 &lt;int&gt;, p65mas &lt;int&gt;, ocupados &lt;int&gt;,</span>
<span class="co">#&gt; #   percep_ing &lt;int&gt;, perc_ocupa &lt;int&gt;, ing_total &lt;dbl&gt;, ing_cor &lt;dbl&gt;,</span>
<span class="co">#&gt; #   ing_mon &lt;dbl&gt;, trabajo &lt;dbl&gt;, sueldos &lt;dbl&gt;, horas_extr &lt;dbl&gt;,</span>
<span class="co">#&gt; #   comisiones &lt;dbl&gt;, otra_rem &lt;dbl&gt;, negocio &lt;dbl&gt;, noagrop &lt;dbl&gt;,</span>
<span class="co">#&gt; #   industria &lt;dbl&gt;, comercio &lt;dbl&gt;, servicios &lt;dbl&gt;, agrope &lt;dbl&gt;,</span>
<span class="co">#&gt; #   agricolas &lt;dbl&gt;, pecuarios &lt;dbl&gt;, reproducc &lt;int&gt;, pesca &lt;int&gt;,</span>
<span class="co">#&gt; #   otros_trab &lt;dbl&gt;, rentas &lt;dbl&gt;, utilidad &lt;dbl&gt;, arrenda &lt;dbl&gt;,</span>
<span class="co">#&gt; #   transfer &lt;dbl&gt;, jubilacion &lt;dbl&gt;, becas &lt;dbl&gt;, donativos &lt;dbl&gt;,</span>
<span class="co">#&gt; #   remesas &lt;dbl&gt;, bene_gob &lt;dbl&gt;, otros_ing &lt;dbl&gt;, gasto_nom &lt;dbl&gt;,</span>
<span class="co">#&gt; #   autoconsum &lt;dbl&gt;, remu_espec &lt;dbl&gt;, transf_esp &lt;dbl&gt;,</span>
<span class="co">#&gt; #   transf_hog &lt;dbl&gt;, trans_inst &lt;dbl&gt;, estim_alqu &lt;dbl&gt;,</span>
<span class="co">#&gt; #   percep_tot &lt;dbl&gt;, percep_mon &lt;dbl&gt;, retiro_inv &lt;dbl&gt;, prestamos &lt;dbl&gt;,</span>
<span class="co">#&gt; #   otras_perc &lt;dbl&gt;, erogac_nom &lt;dbl&gt;, gasto_tot &lt;dbl&gt;, gasto_cor &lt;dbl&gt;,</span>
<span class="co">#&gt; #   gasto_mon &lt;dbl&gt;, alimentos &lt;dbl&gt;, ali_dentro &lt;dbl&gt;, cereales &lt;dbl&gt;,</span>
<span class="co">#&gt; #   carnes &lt;dbl&gt;, pescado &lt;dbl&gt;, leche &lt;dbl&gt;, huevo &lt;dbl&gt;, aceites &lt;dbl&gt;,</span>
<span class="co">#&gt; #   tuberculo &lt;dbl&gt;, verduras &lt;dbl&gt;, frutas &lt;dbl&gt;, azucar &lt;dbl&gt;,</span>
<span class="co">#&gt; #   cafe &lt;dbl&gt;, especias &lt;dbl&gt;, otros_alim &lt;dbl&gt;, bebidas &lt;dbl&gt;,</span>
<span class="co">#&gt; #   ali_fuera &lt;dbl&gt;, tabaco &lt;dbl&gt;, vesti_calz &lt;dbl&gt;, vestido &lt;dbl&gt;,</span>
<span class="co">#&gt; #   calzado &lt;dbl&gt;, vivienda &lt;dbl&gt;, alquiler &lt;dbl&gt;, pred_cons &lt;dbl&gt;,</span>
<span class="co">#&gt; #   agua &lt;dbl&gt;, energia &lt;dbl&gt;, limpieza &lt;dbl&gt;, cuidados &lt;dbl&gt;,</span>
<span class="co">#&gt; #   utensilios &lt;dbl&gt;, enseres &lt;dbl&gt;, salud &lt;dbl&gt;, atenc_ambu &lt;dbl&gt;,</span>
<span class="co">#&gt; #   hospital &lt;dbl&gt;, medicinas &lt;dbl&gt;, transporte &lt;dbl&gt;, publico &lt;dbl&gt;,</span>
<span class="co">#&gt; #   foraneo &lt;dbl&gt;, adqui_vehi &lt;dbl&gt;, mantenim &lt;dbl&gt;, refaccion &lt;dbl&gt;, …</span>

<span class="co"># seleccionar variable de ingreso corriente</span>
hogar &lt;-<span class="st"> </span>concentrado_hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">jefe_hombre =</span> sexo_jefe <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(folioviv, foliohog, est_dis, upm, factor_hog, ing_cor, sexo_jefe, edad_jefe) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(est_dis) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(
        <span class="dt">n =</span> <span class="kw">n_distinct</span>(upm), <span class="co"># número de upms por estrato</span>
        <span class="dt">jefa_50 =</span> (sexo_jefe <span class="op">==</span><span class="st"> </span><span class="dv">2</span>) <span class="op">&amp;</span><span class="st"> </span>(edad_jefe <span class="op">&gt;</span><span class="st"> </span><span class="dv">50</span>)
      ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">ungroup</span>()

<span class="kw">head</span>(hogar)
<span class="co">#&gt; # A tibble: 6 x 10</span>
<span class="co">#&gt;   folioviv foliohog est_dis upm   factor_hog ing_cor sexo_jefe edad_jefe</span>
<span class="co">#&gt;   &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;int&gt;   &lt;dbl&gt;     &lt;int&gt;     &lt;int&gt;</span>
<span class="co">#&gt; 1 0100008…        1 005     00670        694  39787.         2        77</span>
<span class="co">#&gt; 2 0100008…        1 005     00670        694  19524.         1        64</span>
<span class="co">#&gt; 3 0100008…        1 005     00670        694  99258.         1        60</span>
<span class="co">#&gt; 4 0100008…        1 005     00670        694  87884.         1        79</span>
<span class="co">#&gt; 5 0100010…        1 005     00600        660  84427.         1        72</span>
<span class="co">#&gt; 6 0100010…        1 005     00600        660 232014.         1        67</span>
<span class="co">#&gt; # ... with 2 more variables: n &lt;int&gt;, jefa_50 &lt;lgl&gt;</span></code></pre>
<p>Para el cálculo de estadísticos debemos usar los factores de expansión, por ejemplo
el ingreso trimestral total sería:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(hogar<span class="op">$</span>factor_hog <span class="op">*</span><span class="st"> </span>hogar<span class="op">$</span>ing_cor <span class="op">/</span><span class="st"> </span><span class="dv">1000</span>)
<span class="co">#&gt; [1] 1257944071</span></code></pre>
<p>y ingreso trimestral medio (miles pesos)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(hogar<span class="op">$</span>factor_hog <span class="op">*</span><span class="st"> </span>hogar<span class="op">$</span>ing_cor <span class="op">/</span><span class="st"> </span><span class="dv">1000</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(hogar<span class="op">$</span>factor_hog)
<span class="co">#&gt; [1] 39.719</span></code></pre>
<p>Veamos ahora como calcular el error estándar siguiendo el bootstrap de Rao y Wu:</p>
<ol style="list-style-type: decimal">
<li>En cada estrato se seleccionan con reemplazo <span class="math inline">\(m_h\)</span> UPMs de las <span class="math inline">\(n_h\)</span> de la
muestra original. Denotamos por <span class="math inline">\(m_{hi}^*\)</span> el número de veces que se seleccionó
la UPM <span class="math inline">\(i\)</span> en el estrato <span class="math inline">\(h\)</span> (de tal manera que <span class="math inline">\(\sum m_{hi}^*=m_h\)</span>). Creamos
una replicación del ponderador correspondiente a la <span class="math inline">\(k\)</span>-ésima unidad (USM) como:</li>
</ol>
<p><span class="math display">\[d_k^*=d_k \bigg[\bigg(1-\sqrt{\frac{m_h}{n_h - 1}}\bigg) + 
\bigg(\sqrt{\frac{m_h}{n_h - 1}}\frac{n_h}{m_h}m_{h}^*\bigg)\bigg]\]</span></p>
<p>donde <span class="math inline">\(d_k\)</span> es el inverso de la probabilidad de selección. Si <span class="math inline">\(m_h&lt;(n_h -1)\)</span>
todos los pesos definidos de esta manera serán no negativos. Calculamos el
peso final <span class="math inline">\(w_k^*\)</span> aplicando a <span class="math inline">\(d_k^*\)</span> los mismos ajustes que se hicieron a los
ponderadores originales.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Calculamos el estadístico de interés <span class="math inline">\(\hat{\theta}\)</span> usando los ponderadores
<span class="math inline">\(w_k^*\)</span> en lugar de los originales <span class="math inline">\(w_k\)</span>.</p></li>
<li><p>Repetimos los pasos 1 y 2 <span class="math inline">\(B\)</span> veces para obtener <span class="math inline">\(\hat{\theta}^{*1},\hat{\theta}^{*2},...,\hat{\theta}^{*B}\)</span>.</p></li>
<li><p>Calculamos el error estándar como:
<span class="math display">\[\hat{se}_B = \bigg\{\frac{\sum_{b=1}^B[\hat{\theta}^*(b)-\hat{\theta}^*(\cdot)]^2 }{B}\bigg\}^{1/2}\]</span></p></li>
</ol>
<p>Podemos elegir cualquier valor de <span class="math inline">\(m_h \geq 1\)</span>, el más sencillo es elegir
<span class="math inline">\(m_h=n_h-1\)</span>, en este caso:
<span class="math display">\[d_k^*=d_k \frac{n_h}{n_h-1}m_{hi}^*\]</span>
en este escenario las unidades que no se incluyen en la muestra tienen
un valor de cero como ponderador. Si elegimos <span class="math inline">\(n_h \ne n_h-1\)</span> las unidades que
no están en la muestra tienen ponderador distinto a cero, si <span class="math inline">\(m_h=n_h\)</span> el
ponderador podría tomar valores negativos.</p>
<p>Implementemos el bootstrap de Rao y Wu a la ENIGH, usaremos <span class="math inline">\(m_h=n_h-1\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># creamos una tabla con los estratos y upms</span>
est_upm &lt;-<span class="st"> </span>hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">distinct</span>(est_dis, upm, n)

hogar_factor &lt;-<span class="st"> </span>est_upm <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">split</span>(.<span class="op">$</span>est_dis) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># dentro de cada estrato tomamos muestra (n_h-1)</span>
<span class="st">    </span><span class="kw">map_df</span>(<span class="op">~</span><span class="kw">sample_n</span>(., <span class="dt">size =</span> <span class="kw">first</span>(.<span class="op">$</span>n) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">add_count</span>(upm) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># calculamos m_hi*</span>
<span class="st">    </span><span class="kw">left_join</span>(hogar, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;est_dis&quot;</span>, <span class="st">&quot;upm&quot;</span>, <span class="st">&quot;n&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">factor_b =</span> factor_hog <span class="op">*</span><span class="st"> </span>nn <span class="op">*</span><span class="st"> </span>n <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))

<span class="co"># unimos los pasos anteriores en una función para replicar en cada muestra bootstrap</span>
svy_boot &lt;-<span class="st"> </span><span class="cf">function</span>(est_upm, hogar){
    m_hi &lt;-<span class="st"> </span>est_upm <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">split</span>(.<span class="op">$</span>est_dis) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">map</span>(<span class="op">~</span><span class="kw">sample</span>(.<span class="op">$</span>upm, <span class="dt">size =</span> <span class="kw">first</span>(.<span class="op">$</span>n) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">flatten_chr</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span>plyr<span class="op">::</span><span class="kw">count</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">select</span>(<span class="dt">upm =</span> x, <span class="dt">m_h =</span> freq)
    m_hi <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">upm =</span> <span class="kw">as.character</span>(upm)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">left_join</span>(hogar, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;upm&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">factor_b =</span> factor_hog <span class="op">*</span><span class="st"> </span>m_h <span class="op">*</span><span class="st"> </span>n <span class="op">/</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
}
<span class="kw">set.seed</span>(<span class="dv">1038984</span>)
boot_rep &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">500</span>, <span class="kw">svy_boot</span>(est_upm, hogar))

<span class="co"># Aplicación a ingreso medio</span>
media &lt;-<span class="st"> </span><span class="cf">function</span>(w, x) <span class="kw">sum</span>(w <span class="op">*</span><span class="st"> </span>x) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(w)

<span class="co"># La media es:</span>
hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarise</span>(<span class="dt">media =</span> <span class="kw">media</span>(factor_hog, ing_cor))
<span class="co">#&gt; # A tibble: 1 x 1</span>
<span class="co">#&gt;    media</span>
<span class="co">#&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 39719.</span></code></pre>
<p>Y el error estándar:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">map_dbl</span>(boot_rep, <span class="op">~</span><span class="kw">media</span>(<span class="dt">w =</span> .<span class="op">$</span>factor_b, <span class="dt">x =</span> .<span class="op">$</span>ing_cor)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()
<span class="co">#&gt; [1] 946.01</span></code></pre>
<p>El método bootstrap está implementado en el paquete <code>survey</code> y más recientemente
en <code>srvyr</code> que es una versión <em>tidy</em> que utiliza las funciones en <code>survey</code>.</p>
<p>Podemos comparar nuestros resultados con la implementación en <code>survey</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1. Definimos el diseño de la encuesta</span>
<span class="kw">library</span>(survey)
<span class="kw">library</span>(srvyr)

enigh_design &lt;-<span class="st"> </span>hogar <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as_survey_design</span>(<span class="dt">ids =</span> upm, <span class="dt">weights =</span> factor_hog, <span class="dt">strata =</span> est_dis)

<span class="co"># 2. Elegimos bootstrap como el método para el cálculo de errores estándar</span>
<span class="kw">set.seed</span>(<span class="dv">7398731</span>)
enigh_boot &lt;-<span class="st"> </span>enigh_design <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as_survey_rep</span>(<span class="dt">type =</span> <span class="st">&quot;subbootstrap&quot;</span>, <span class="dt">replicates =</span> <span class="dv">500</span>)

<span class="co"># 3. Así calculamos la media</span>
enigh_boot <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>srvyr<span class="op">::</span><span class="kw">summarise</span>(<span class="dt">mean_ingcor =</span> <span class="kw">survey_mean</span>(ing_cor))
<span class="co">#&gt; # A tibble: 1 x 2</span>
<span class="co">#&gt;   mean_ingcor mean_ingcor_se</span>
<span class="co">#&gt;         &lt;dbl&gt;          &lt;dbl&gt;</span>
<span class="co">#&gt; 1      39719.          1008.</span>
<span class="co"># cuantiles</span>
<span class="kw">svyquantile</span>(<span class="op">~</span>ing_cor, enigh_boot, <span class="dt">quantiles =</span> <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), <span class="dt">interval.type =</span> <span class="st">&quot;quantile&quot;</span>)
<span class="co">#&gt; Statistic:</span>
<span class="co">#&gt;      ing_cor</span>
<span class="co">#&gt; q0.1   10622</span>
<span class="co">#&gt; q0.2   14775</span>
<span class="co">#&gt; q0.3   18597</span>
<span class="co">#&gt; q0.4   22682</span>
<span class="co">#&gt; q0.5   27186</span>
<span class="co">#&gt; q0.6   32726</span>
<span class="co">#&gt; q0.7   40057</span>
<span class="co">#&gt; q0.8   51990</span>
<span class="co">#&gt; q0.9   76285</span>
<span class="co">#&gt; q1   4150377</span>
<span class="co">#&gt; SE:</span>
<span class="co">#&gt;         ing_cor</span>
<span class="co">#&gt; q0.1     143.90</span>
<span class="co">#&gt; q0.2     165.40</span>
<span class="co">#&gt; q0.3     193.00</span>
<span class="co">#&gt; q0.4     218.38</span>
<span class="co">#&gt; q0.5     239.42</span>
<span class="co">#&gt; q0.6     347.55</span>
<span class="co">#&gt; q0.7     483.52</span>
<span class="co">#&gt; q0.8     768.62</span>
<span class="co">#&gt; q0.9    1322.12</span>
<span class="co">#&gt; q1   1318629.10</span></code></pre>
<p>Supongamos que queremos calcular la media para los hogares con jefe de familia
mujer mayor a 50 años.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Creamos datos con filter y repetimos lo de arriba</span>
hogar_mujer &lt;-<span class="st"> </span><span class="kw">filter</span>(hogar, jefa_<span class="dv">50</span>)
est_upm_mujer &lt;-<span class="st"> </span>hogar_mujer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">distinct</span>(est_dis, upm, n)
<span class="co"># bootstrap</span>
boot_rep_mujer &lt;-<span class="st"> </span><span class="kw">rerun</span>(<span class="dv">500</span>, <span class="kw">svy_boot</span>(est_upm_mujer, hogar_mujer))
<span class="co"># media y error estándar</span>
hogar_mujer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summarise</span>(<span class="dt">media =</span> <span class="kw">media</span>(factor_hog, ing_cor))
<span class="co">#&gt; # A tibble: 1 x 1</span>
<span class="co">#&gt;    media</span>
<span class="co">#&gt;    &lt;dbl&gt;</span>
<span class="co">#&gt; 1 35259.</span>
<span class="co"># usamos bootstrap para calcular los errores estándar</span>
<span class="kw">map_dbl</span>(boot_rep_mujer, <span class="op">~</span><span class="kw">media</span>(<span class="dt">w =</span> .<span class="op">$</span>factor_b, <span class="dt">x =</span> .<span class="op">$</span>ing_cor)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()
<span class="co">#&gt; [1] 1788.6</span></code></pre>
<p>Comparemos con los resultados de <code>srvyr</code>. ¿qué pasa?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(srvyr)
enigh_boot <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>srvyr<span class="op">::</span><span class="kw">group_by</span>(jefa_<span class="dv">50</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>srvyr<span class="op">::</span><span class="kw">summarise</span>(<span class="dt">mean_ingcor =</span> <span class="kw">survey_mean</span>(ing_cor))
<span class="co">#&gt; # A tibble: 2 x 3</span>
<span class="co">#&gt;   jefa_50 mean_ingcor mean_ingcor_se</span>
<span class="co">#&gt;   &lt;lgl&gt;         &lt;dbl&gt;          &lt;dbl&gt;</span>
<span class="co">#&gt; 1 FALSE        40412.           949.</span>
<span class="co">#&gt; 2 TRUE         35259.          1988.</span></code></pre>
<p>Sub-poblaciones como “jefas de familia mayores a 50” se conocen como un dominio,
esto es
un subgrupo cuyo tamaño de muestra es aleatorio. Este ejemplo nos recalca la
importancia de considerar el proceso en que se generó la muestra para calcular
los errores estándar bootstrap.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">map_dbl</span>(boot_rep, 
    <span class="cf">function</span>(x){hm &lt;-<span class="st"> </span><span class="kw">filter</span>(x, jefa_<span class="dv">50</span>); <span class="kw">media</span>(<span class="dt">w =</span> hm<span class="op">$</span>factor_b, <span class="dt">x =</span> hm<span class="op">$</span>ing_cor)}) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">sd</span>()
<span class="co">#&gt; [1] 1965.4</span></code></pre>
<p>Resumiendo:</p>
<ul>
<li><p>El bootstrap de Rao y Wu genera un estimador consistente y aproximadamente
insesgado de la varianza de estadísticos no lineales y para la varianza de un
cuantil.</p></li>
<li><p>Este método supone que la seleccion de UPMs es con reemplazo; hay variaciones
del estimador bootstrap de Rao y Wu que extienden el método que acabamos de
estudiar; sin embargo, es común ignorar este aspecto,
por ejemplo <a href="https://fcsm.sites.usa.gov/files/2014/05/2005FCSM_Mach_Dumais_Robidou_VA.pdf">Mach et al</a> estudian las propiedades del estimador de varianza bootstrap de Rao y Wu cuando
la muestra se seleccionó sin reemplazo.</p></li>
</ul>
<!-- West explica porque únicamente se ignora la variabilidad de las USMs en un 
(deocumento)[http://www.isr.umich.edu/src/smp/asda/first_stage_ve_new.pdf]
-->
</div>
</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references">
<div id="ref-efron">
<p>Efron, Bradley, and Robert J. Tibshirani. 1993. <em>An Introduction to the Bootstrap</em>. Monographs on Statistics and Applied Probability 57. Boca Raton, Florida, USA: Chapman &amp; Hall/CRC.</p>
</div>
<div id="ref-tim">
<p>Hesterberg, Tim C. 2015. “What Teachers Should Know About the Bootstrap: Resampling in the Undergraduate Statistics Curriculum.” <em>The American Statistician</em> 69 (4). Taylor &amp; Francis:371–86. <a href="https://doi.org/10.1080/00031305.2015.1089789" class="uri">https://doi.org/10.1080/00031305.2015.1089789</a>.</p>
</div>
<div id="ref-RaoWu">
<p>Rao, J. N. K., and C. F. J. Wu. 1988. “Resampling Inference with Complex Survey Data.” <em>Journal of the American Statistical Association</em> 83 (401). Taylor &amp; Francis:231–41. <a href="https://doi.org/10.1080/01621459.1988.10478591" class="uri">https://doi.org/10.1080/01621459.1988.10478591</a>.</p>
</div>
<div id="ref-enigh">
<p>INEGI. 2014. “Encuesta Nacional de Ingresos Y Gastos de Los Hogares (Enigh-2014). Diseño Muestral.” <a href="http://internet.contenidos.inegi.org.mx/contenidos/Productos/prod_serv/contenidos/espanol/bvinegi/productos/nueva_estruc/702825070359.pdf" class="uri">http://internet.contenidos.inegi.org.mx/contenidos/Productos/prod_serv/contenidos/espanol/bvinegi/productos/nueva_estruc/702825070359.pdf</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="el-principio-del-plug-in.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intervalos-de-confianza.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tereom/est-computacional-2018/edit/master/05-bootstrap_no_parametrico.Rmd",
"text": "Edit"
},
"download": ["est-computacional-2018.pdf", "est-computacional-2018.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
